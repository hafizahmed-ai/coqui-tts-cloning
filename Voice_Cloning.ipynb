{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anujsahani01/VoiceCloning-coqi-TTS/blob/main/Voice_Cloning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLeMqqomrQw7",
        "outputId": "28c1f2b1-6fa5-4fb6-b271-f3b4af68fb6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.2)\n",
            "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: TTS in /usr/local/lib/python3.10/dist-packages (0.15.6)\n",
            "Requirement already satisfied: cython==0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.29.30)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.0.2+cu118)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa==0.10.0.* in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.0)\n",
            "Requirement already satisfied: inflect==5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (5.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from TTS) (4.65.0)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from TTS) (23.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.10/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: umap-learn==0.5.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Requirement already satisfied: trainer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.28)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.10/dist-packages (from TTS) (0.49.0)\n",
            "Requirement already satisfied: mecab-python3==1.0.6 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.0.6)\n",
            "Requirement already satisfied: unidic-lite==1.0.8 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.0.8)\n",
            "Requirement already satisfied: gruut[de,es,fr]==2.2.3 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.10/dist-packages (from TTS) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.2)\n",
            "Requirement already satisfied: bangla==0.0.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer==0.1.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n",
            "Requirement already satisfied: k-diffusion in /usr/local/lib/python3.10/dist-packages (from TTS) (0.0.15)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from TTS) (0.6.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from TTS) (4.31.0)\n",
            "Requirement already satisfied: encodec in /usr/local/lib/python3.10/dist-packages (from TTS) (0.1.1)\n",
            "Requirement already satisfied: numpy==1.22.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.22.0)\n",
            "Requirement already satisfied: numba==0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.57.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.12.1)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
            "Requirement already satisfied: num2words<1.0.0,>=0.5.10 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.5.12)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (0.9.9)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (4.7.1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.10.0.*->TTS) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.57.0->TTS) (0.40.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.1->TTS) (0.5.10)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->TTS) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->TTS) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->TTS) (1.3.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.3.6)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->TTS) (8.1.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.21.0)\n",
            "Requirement already satisfied: clean-fid in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.1.35)\n",
            "Requirement already satisfied: clip-anytorch in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (2.5.2)\n",
            "Requirement already satisfied: jsonmerge in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (1.9.2)\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.6.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (8.4.0)\n",
            "Requirement already satisfied: resize-right in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.19.3)\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.2.3)\n",
            "Requirement already satisfied: torchsde in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.2.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.2+cu118)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from k-diffusion->TTS) (0.15.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->TTS) (2.8.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->TTS) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->TTS) (2022.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer->TTS) (2.12.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (0.16.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->TTS) (0.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->TTS) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words<1.0.0,>=0.5.10->gruut[de,es,fr]==2.2.3->TTS) (0.6.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.10.0.*->TTS) (1.4.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->TTS) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa==0.10.0.*->TTS) (3.1.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip-anytorch->k-diffusion->TTS) (6.1.1)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->TTS) (4.3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (2023.7.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->k-diffusion->TTS) (1.4.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer->TTS) (0.40.0)\n",
            "Requirement already satisfied: boltons>=20.2.1 in /usr/local/lib/python3.10/dist-packages (from torchsde->k-diffusion->TTS) (23.0.0)\n",
            "Requirement already satisfied: trampoline>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from torchsde->k-diffusion->TTS) (0.1.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (3.1.32)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.28.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->TTS) (1.3.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS) (4.0.10)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (1.3.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->TTS) (0.19.3)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch->k-diffusion->TTS) (0.2.6)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->k-diffusion->TTS) (5.0.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer->TTS) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer->TTS) (3.2.2)\n",
            "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "## Install Coqui TTS\n",
        "! pip install -U pip\n",
        "! pip install TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "014b0G-41SDh",
        "outputId": "c0f6751e-cdb7-4187-bc35-5bed1bd40de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fuBV1mOa1R8k"
      },
      "outputs": [],
      "source": [
        "#Location of original wav files.\n",
        "orig_waves=\"/content/drive/MyDrive/dataset/orignal\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85JrUM43dKrX",
        "outputId": "17e7fc65-9595-44a9-9af2-4af150ef1a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TTS' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/coqui-ai/TTS.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jarVfhro3Bi0",
        "outputId": "2ef35f86-e121-4afd-bb47-736c1728e218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyloudnorm\n",
        "!git clone https://github.com/xiph/rnnoise.git\n",
        "!sudo apt-get install curl autoconf automake libtool python-dev pkg-config sox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5ZiZra7u8cp",
        "outputId": "605c026d-da55-4be6-9ea1-1126842955fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (1.22.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm) (0.18.3)\n",
            "\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mfatal: destination path 'rnnoise' already exists and is not an empty directory.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'python-dev-is-python2' instead of 'python-dev'\n",
            "autoconf is already the newest version (2.69-11.1).\n",
            "automake is already the newest version (1:1.16.1-4ubuntu6).\n",
            "libtool is already the newest version (2.4.6-14).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu4).\n",
            "python-dev-is-python2 is already the newest version (2.7.17-4).\n",
            "curl is already the newest version (7.68.0-1ubuntu2.18).\n",
            "sox is already the newest version (14.4.2+git20190427-2+deb11u2build0.20.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/rnnoise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLNwWJWWu9Gw",
        "outputId": "d424bddf-19e8-433f-979a-4eb1e9507c0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rnnoise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh autogen.sh\n",
        "!sh configure\n",
        "!make clean\n",
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNJCcq3Vu9JR",
        "outputId": "7d5b1037-a71b-4ec0-fd52-88e458731f5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating build configuration files for rnnoise, please wait....\n",
            "libtoolize: putting auxiliary files in '.'.\n",
            "libtoolize: linking file './ltmain.sh'\n",
            "libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.\n",
            "libtoolize: linking file 'm4/libtool.m4'\n",
            "libtoolize: linking file 'm4/ltoptions.m4'\n",
            "libtoolize: linking file 'm4/ltsugar.m4'\n",
            "libtoolize: linking file 'm4/ltversion.m4'\n",
            "libtoolize: linking file 'm4/lt~obsolete.m4'\n",
            "configure.ac:19: installing './compile'\n",
            "configure.ac:22: installing './missing'\n",
            "Makefile.am: installing './depcomp'\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking whether gcc understands -c and -o together... yes\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /usr/bin/grep\n",
            "checking for egrep... /usr/bin/grep -E\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking minix/config.h usability... no\n",
            "checking minix/config.h presence... no\n",
            "checking for minix/config.h... no\n",
            "checking whether it is safe to define __EXTENSIONS__... yes\n",
            "checking for special C compiler options needed for large files... no\n",
            "checking for _FILE_OFFSET_BITS value needed for large files... no\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports the include directive... yes (GNU style)\n",
            "checking whether make supports nested variables... yes\n",
            "checking dependency style of gcc... gcc3\n",
            "checking whether to enable maintainer-specific portions of Makefiles... yes\n",
            "checking for inline... inline\n",
            "checking build system type... x86_64-pc-linux-gnu\n",
            "checking host system type... x86_64-pc-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /usr/bin/sed\n",
            "checking for fgrep... /usr/bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... no\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "checking for a working dd... /usr/bin/dd\n",
            "checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking whether make supports nested variables... (cached) yes\n",
            "checking if gcc supports -pedantic flag... yes\n",
            "checking if gcc supports -Wall flag... yes\n",
            "checking if gcc supports -Wextra flag... yes\n",
            "checking if gcc supports -Wno-sign-compare flag... yes\n",
            "checking if gcc supports -Wno-parentheses flag... yes\n",
            "checking if gcc supports -Wno-long-long flag... yes\n",
            "checking for cos in -lm... yes\n",
            "checking for gcc way to treat warnings as errors... -Werror\n",
            "checking if gcc supports __attribute__(( visibility(\"default\") ))... yes\n",
            "checking if gcc supports -fvisibility=hidden... yes\n",
            "checking for doxygen... no\n",
            "checking for dot... yes\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating rnnoise.pc\n",
            "config.status: creating rnnoise-uninstalled.pc\n",
            "config.status: creating doc/Doxyfile\n",
            "config.status: creating config.h\n",
            "config.status: config.h is unchanged\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "configure:\n",
            "------------------------------------------------------------------------\n",
            "  rnnoise unknown: Automatic configuration OK.\n",
            "\n",
            "    Assertions ................... no\n",
            "\n",
            "    Hidden visibility ............ yes\n",
            "\n",
            "    API code examples ............ yes\n",
            "    API documentation ............ yes\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "test -z \"librnnoise.la\" || rm -f librnnoise.la\n",
            "rm -f ./so_locations\n",
            "rm -rf .libs _libs\n",
            "rm -rf examples/.libs examples/_libs\n",
            "rm -rf src/.libs src/_libs\n",
            " rm -f examples/rnnoise_demo\n",
            "rm -f *.o\n",
            "rm -f examples/*.o\n",
            "rm -f src/*.o\n",
            "rm -f src/*.lo\n",
            "rm -f *.lo\n",
            "make  all-am\n",
            "make[1]: Entering directory '/content/rnnoise'\n",
            "  CC       examples/rnnoise_demo.o\n",
            "\u001b[01m\u001b[Kexamples/rnnoise_demo.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmain\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/rnnoise_demo.c:48:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "   48 |     \u001b[01;35m\u001b[Kfread(tmp, sizeof(short), FRAME_SIZE, f1)\u001b[m\u001b[K;\n",
            "      |     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "  CC       src/denoise.lo\n",
            "  CC       src/rnn.lo\n",
            "  CC       src/rnn_data.lo\n",
            "  CC       src/rnn_reader.lo\n",
            "  CC       src/pitch.lo\n",
            "  CC       src/kiss_fft.lo\n",
            "  CC       src/celt_lpc.lo\n",
            "  CCLD     librnnoise.la\n",
            "  CCLD     examples/rnnoise_demo\n",
            "make[1]: Leaving directory '/content/rnnoise'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "import pyloudnorm as pyln\n",
        "import sys\n",
        "import glob\n",
        "#src = sys.argv[1]\n",
        "rnn = \"/content/rnnoise/examples/rnnoise_demo\"\n",
        "\n",
        "#paths = Path(src).glob(\"**/*.wav\")\n",
        "#paths = Path(orig_wavs).glob(\"**/*.wav\")\n",
        "paths = glob.glob(os.path.join(orig_waves, '*.wav'))\n",
        "#print(paths)\n",
        "#paths = Path(orig_wavs).glob(\"*.wav\")\n",
        "\n",
        "for filepath in paths:\n",
        "  target_filepath=Path(str(filepath).replace(\"orignal\", \"converted\"))\n",
        "  target_dir=os.path.dirname(target_filepath)\n",
        "  #print(target_filepath)\n",
        "  if (str(filepath) == str(target_filepath)):\n",
        "    raise ValueError(\"Source and target path are identical: \" + str(target_filepath))\n",
        "  print(\"From: \" + str(filepath))\n",
        "  print(\"To: \" + str(target_filepath))\n",
        "\n",
        "# Stereo to Mono; upsample to 48000Hz\n",
        "# added -G to fix gain, -v 0.95\n",
        "  subprocess.run([\"sox\", \"-G\", \"-v\", \"0.95\", filepath, \"48k.wav\", \"remix\", \"-\", \"rate\", \"48000\"])\n",
        "  subprocess.run([\"sox\", \"48k.wav\", \"-c\", \"1\", \"-r\", \"48000\", \"-b\", \"16\", \"-e\", \"signed-integer\", \"-t\", \"raw\", \"temp.raw\"]) # convert wav to raw\n",
        "  subprocess.run([rnn, \"temp.raw\", \"rnn.raw\"]) # apply rnnoise\n",
        "  subprocess.run([\"sox\", \"-G\", \"-v\", \"0.95\", \"-r\", \"48k\", \"-b\", \"16\", \"-e\", \"signed-integer\", \"rnn.raw\", \"-t\", \"wav\", \"rnn.wav\"]) # convert raw back to wav\n",
        "\n",
        "  subprocess.run([\"mkdir\", \"-p\", str(target_dir)])\n",
        "  subprocess.run([\"sox\", \"rnn.wav\", str(target_filepath), \"remix\", \"-\", \"highpass\", \"100\", \"lowpass\", \"7000\", \"rate\", \"22050\"]) # apply high/low pass filter and change sr to 22050Hz\n",
        "  data, rate = sf.read(target_filepath)\n",
        "\n",
        "# peak normalize audio to -1 dB\n",
        "  peak_normalized_audio = pyln.normalize.peak(data, -1.0)\n",
        "\n",
        "# measure the loudness first\n",
        "  meter = pyln.Meter(rate) # create BS.1770 meter\n",
        "  loudness = meter.integrated_loudness(data)\n",
        "\n",
        "# loudness normalize audio to -25 dB LUFS\n",
        "  loudness_normalized_audio = pyln.normalize.loudness(data, loudness, -25.0)\n",
        "  sf.write(target_filepath, data=loudness_normalized_audio, samplerate=22050)\n",
        "  print(\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUwNr5bZu9MO",
        "outputId": "1189588f-42e5-402f-c3b8-2d14f716baf2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: /content/drive/MyDrive/dataset/orignal/data-04.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-04.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-01.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-01.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-03.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-03.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-02.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-02.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-05.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-05.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-16.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-16.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-06.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-06.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-08.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-08.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-19.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-19.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-17.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-17.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-15.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-15.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-07.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-07.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-13.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-13.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-10.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-10.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-09.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-09.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-11.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-11.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-18.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-18.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-12.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-12.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-14.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-14.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-33.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-33.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-30.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-30.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-32.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-32.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-23.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-23.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-31.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-31.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-28.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-28.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-20.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-20.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-24.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-24.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-27.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-27.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-22.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-22.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-25.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-25.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-26.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-26.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-29.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-29.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-21.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-21.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-46.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-46.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-38.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-38.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-37.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-37.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-42.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-42.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-45.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-45.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-34.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-34.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-40.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-40.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-39.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-39.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-41.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-41.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-36.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-36.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-35.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-35.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-44.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-44.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-47.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-47.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-43.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-43.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-49.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-49.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-58.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-58.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-55.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-55.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-62.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-62.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-48.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-48.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-60.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-60.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-54.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-54.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-56.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-56.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-50.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-50.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-61.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-61.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-57.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-57.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-53.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-53.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-51.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-51.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-52.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-52.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-59.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-59.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-67.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-67.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-63.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-63.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-69.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-69.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-73.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-73.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-72.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-72.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-74.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-74.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-64.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-64.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-68.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-68.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-71.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-71.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-76.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-76.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-65.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-65.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-66.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-66.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-70.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-70.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-77.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-77.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-78.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-78.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-81.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-81.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-80.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-80.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-82.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-82.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-83.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-83.wav\n",
            "\n",
            "From: /content/drive/MyDrive/dataset/orignal/data-79.wav\n",
            "To: /content/drive/MyDrive/dataset/converted/data-79.wav\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7t1_gM511R09"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import DatasetDict, Dataset\n",
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "\n",
        "lines = []\n",
        "with open('/content/drive/MyDrive/dataset.txt', 'r', encoding = 'utf-8') as f:\n",
        "  text  = ' '.join(f)\n",
        "  lines = text.split('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WqlBfYbR1Zve"
      },
      "outputs": [],
      "source": [
        "df['data'] = lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CxZ_Ly1G1Zyo",
        "outputId": "8e739497-6f5c-4574-969e-494e87d12ebe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                data\n",
              "0  data-01|Um it was really romanticized that you...\n",
              "1   data-02|One time you know five shifts don't s...\n",
              "2   data-03|Lived more life I've realized having ..."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b66dead4-cbd4-4567-980f-3db6ea6de0a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data-01|Um it was really romanticized that you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data-02|One time you know five shifts don't s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data-03|Lived more life I've realized having ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b66dead4-cbd4-4567-980f-3db6ea6de0a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-48b961fd-520b-4fd6-965b-fa7c3541ac00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48b961fd-520b-4fd6-965b-fa7c3541ac00')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-48b961fd-520b-4fd6-965b-fa7c3541ac00 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b66dead4-cbd4-4567-980f-3db6ea6de0a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b66dead4-cbd4-4567-980f-3db6ea6de0a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTI67OVV1Z1d",
        "outputId": "d6abd9fe-0a84-4efc-f9fe-97b6721b4d13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['data'],\n",
              "    num_rows: 82\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "datasets = Dataset.from_pandas(df)\n",
        "datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3i2EIHC91Z4P"
      },
      "outputs": [],
      "source": [
        "final = []\n",
        "def process(data):\n",
        "  audio_path = data['data'].split('|')[0]\n",
        "  dialogue = data['data'].split('|')[1]\n",
        "  speaker = 'priyanka'\n",
        "\n",
        "  final = f\"{audio_path}|{speaker}|{dialogue}\"\n",
        "  return {\n",
        "      'final_data' : final\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "7b142ae5439d4e0788b2d14793265d32",
            "892051cab6e24834bdda277c1fd6901f",
            "9686db22f81b499facd75e7942c4e2c7",
            "d17fad708e874f93a8e9b9eb9e0ceb2a",
            "52bffd98efc3483f98e3e3ec3135226d",
            "bf472fa68224433d951db9528053f737",
            "e4d53b1e384f4581b51ce64b15da68e3",
            "3ee8faef59cd498693184a59903fb8b8",
            "3a08a0fd13ae4ea994e8f732c103d7ba",
            "748e1d70a6f34d69bacc681113ed85bd",
            "ed05ac9b712d42b694b557217664c333"
          ]
        },
        "id": "E-zS4JBu1Z6Z",
        "outputId": "deca4f8b-4feb-4044-c750-07d76fb072ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b142ae5439d4e0788b2d14793265d32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['final_data'],\n",
              "    num_rows: 82\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "final_dataset = datasets.map(process, batched = False, remove_columns = ['data'])\n",
        "final_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "D0Vxp2ek1Z8x"
      },
      "outputs": [],
      "source": [
        "df_final = pd.DataFrame()\n",
        "df_final['inp'] = final_dataset['final_data']\n",
        "df_final.to_csv('/content/drive/MyDrive/dataset/metadata.csv', index = False)\n",
        "df_final.to_csv('metadata.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Cwqgx56J1Z_J",
        "outputId": "fcc83eda-607a-48c5-8ea5-3bb08c101b1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 inp\n",
              "0  data-01|priyanka|Um it was really romanticized...\n",
              "1   data-02|priyanka|One time you know five shift...\n",
              "2   data-03|priyanka|Lived more life I've realize...\n",
              "3   data-04|priyanka|Me and my husband just by ou...\n",
              "4   data-05|priyanka|and really motivated to take..."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-68f690ce-cf3b-4720-9678-023e385a17a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>data-01|priyanka|Um it was really romanticized...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>data-02|priyanka|One time you know five shift...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>data-03|priyanka|Lived more life I've realize...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>data-04|priyanka|Me and my husband just by ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>data-05|priyanka|and really motivated to take...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f690ce-cf3b-4720-9678-023e385a17a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-6cc33a3b-c339-4cf5-8dfe-a8475640e56b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cc33a3b-c339-4cf5-8dfe-a8475640e56b')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-6cc33a3b-c339-4cf5-8dfe-a8475640e56b button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68f690ce-cf3b-4720-9678-023e385a17a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68f690ce-cf3b-4720-9678-023e385a17a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dataset/metadata.csv')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2WM8vyCd1aBr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/dataset/cloned\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XWWv-upo1aGH"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'orignal/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b6d1T0hxmbyk"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/drive/MyDrive/dataset/converted'\n",
        "meta_file = '/content/drive/MyDrive/dataset/metadata.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UjKzzf9bc97Y"
      },
      "outputs": [],
      "source": [
        "code = '''\n",
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "########################\n",
        "# DATASETS\n",
        "########################\n",
        "\n",
        "\n",
        "def coqui(root_path, meta_file, ignored_speakers=None):\n",
        "    \"\"\"Interal dataset formatter.\"\"\"\n",
        "    filepath = os.path.join(root_path, meta_file)\n",
        "    # ensure there are 4 columns for every line\n",
        "    with open(filepath, \"r\", encoding=\"utf8\") as f:\n",
        "        lines = f.readlines()\n",
        "    num_cols = len(lines[0].split(\"|\"))  # take the first row as reference\n",
        "    for idx, line in enumerate(lines[1:]):\n",
        "        if len(line.split(\"|\")) != num_cols:\n",
        "            print(f\" > Missing column in line {idx + 1} -> {line.strip()}\")\n",
        "    # load metadata\n",
        "    metadata = pd.read_csv(os.path.join(root_path, meta_file), sep=\"|\")\n",
        "    assert all(x in metadata.columns for x in [\"audio_file\", \"text\"])\n",
        "    speaker_name = None if \"speaker_name\" in metadata.columns else \"coqui\"\n",
        "    emotion_name = None if \"emotion_name\" in metadata.columns else \"neutral\"\n",
        "    items = []\n",
        "    not_found_counter = 0\n",
        "    for row in metadata.itertuples():\n",
        "        if speaker_name is None and ignored_speakers is not None and row.speaker_name in ignored_speakers:\n",
        "            continue\n",
        "        audio_path = os.path.join(root_path, row.audio_file)\n",
        "        if not os.path.exists(audio_path):\n",
        "            not_found_counter += 1\n",
        "            continue\n",
        "        items.append(\n",
        "            {\n",
        "                \"text\": row.text,\n",
        "                \"audio_file\": audio_path,\n",
        "                \"speaker_name\": speaker_name if speaker_name is not None else row.speaker_name,\n",
        "                \"emotion_name\": emotion_name if emotion_name is not None else row.emotion_name,\n",
        "                \"root_path\": root_path,\n",
        "            }\n",
        "        )\n",
        "    if not_found_counter > 0:\n",
        "        print(f\" | > [!] {not_found_counter} files not found\")\n",
        "    return items\n",
        "\n",
        "\n",
        "def tweb(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalize TWEB dataset.\n",
        "    https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset\n",
        "    \"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"tweb\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"\\t\")\n",
        "            wav_file = os.path.join(root_path, cols[0] + \".wav\")\n",
        "            text = cols[1]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def mozilla(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes Mozilla meta data files to TTS format\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"mozilla\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = cols[1].strip()\n",
        "            text = cols[0].strip()\n",
        "            wav_file = os.path.join(root_path, \"wavs\", wav_file)\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def mozilla_de(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes Mozilla meta data files to TTS format\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"mozilla\"\n",
        "    with open(txt_file, \"r\", encoding=\"ISO 8859-1\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.strip().split(\"|\")\n",
        "            wav_file = cols[0].strip()\n",
        "            text = cols[1].strip()\n",
        "            folder_name = f\"BATCH_{wav_file.split('_')[0]}_FINAL\"\n",
        "            wav_file = os.path.join(root_path, folder_name, wav_file)\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def mailabs(root_path, meta_files=None, ignored_speakers=None):\n",
        "    \"\"\"Normalizes M-AI-Labs meta data files to TTS format\n",
        "\n",
        "    Args:\n",
        "        root_path (str): root folder of the MAILAB language folder.\n",
        "        meta_files (str):  list of meta files to be used in the training. If None, finds all the csv files\n",
        "            recursively. Defaults to None\n",
        "    \"\"\"\n",
        "    speaker_regex = re.compile(f\"by_book{os.sep}(male|female){os.sep}(?P<speaker_name>[^{os.sep}]+){os.sep}\")\n",
        "    if not meta_files:\n",
        "        csv_files = glob(root_path + f\"{os.sep}**{os.sep}metadata.csv\", recursive=True)\n",
        "    else:\n",
        "        csv_files = meta_files\n",
        "\n",
        "    # meta_files = [f.strip() for f in meta_files.split(\",\")]\n",
        "    items = []\n",
        "    for csv_file in csv_files:\n",
        "        if os.path.isfile(csv_file):\n",
        "            txt_file = csv_file\n",
        "        else:\n",
        "            txt_file = os.path.join(root_path, csv_file)\n",
        "\n",
        "        folder = os.path.dirname(txt_file)\n",
        "        # determine speaker based on folder structure...\n",
        "        speaker_name_match = speaker_regex.search(txt_file)\n",
        "        if speaker_name_match is None:\n",
        "            continue\n",
        "        speaker_name = speaker_name_match.group(\"speaker_name\")\n",
        "        # ignore speakers\n",
        "        if isinstance(ignored_speakers, list):\n",
        "            if speaker_name in ignored_speakers:\n",
        "                continue\n",
        "        print(\" | > {}\".format(csv_file))\n",
        "        with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "            for line in ttf:\n",
        "                cols = line.split(\"|\")\n",
        "                if not meta_files:\n",
        "                    wav_file = os.path.join(folder, \"wavs\", cols[0] + \".wav\")\n",
        "                else:\n",
        "                    wav_file = os.path.join(root_path, folder.replace(\"metadata.csv\", \"\"), \"wavs\", cols[0] + \".wav\")\n",
        "                if os.path.isfile(wav_file):\n",
        "                    text = cols[1].strip()\n",
        "                    items.append(\n",
        "                        {\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path}\n",
        "                    )\n",
        "                else:\n",
        "                    # M-AI-Labs have some missing samples, so just print the warning\n",
        "                    print(\"> File %s does not exist!\" % (wav_file))\n",
        "    return items\n",
        "\n",
        "\n",
        "def ljspeech(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the LJSpeech meta data file to TTS format\n",
        "    https://keithito.com/LJ-Speech-Dataset/\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"ljspeech\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, \"wavs\", cols[0] + \".wav\")\n",
        "            text = cols[2]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "# custom formatter\n",
        "def custom_formatter(root_path, meta_file, **kwargs):\n",
        "    df  = pd.read_csv(meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"custom_formatter\"\n",
        "    for line in df['inp']:\n",
        "      cols = line.split(\"|\")\n",
        "      wav_file = os.path.join(root_path, cols[0].replace(' ','') + \".wav\")\n",
        "      print(wav_file)\n",
        "      text = cols[2]\n",
        "      items.append({\"text\":text, \"audio_file\":wav_file, \"speaker_name\":speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def ljspeech_test(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the LJSpeech meta data file for TTS testing\n",
        "    https://keithito.com/LJ-Speech-Dataset/\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        speaker_id = 0\n",
        "        for idx, line in enumerate(ttf):\n",
        "            # 2 samples per speaker to avoid eval split issues\n",
        "            if idx % 2 == 0:\n",
        "                speaker_id += 1\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, \"wavs\", cols[0] + \".wav\")\n",
        "            text = cols[2]\n",
        "            items.append(\n",
        "                {\"text\": text, \"audio_file\": wav_file, \"speaker_name\": f\"ljspeech-{speaker_id}\", \"root_path\": root_path}\n",
        "            )\n",
        "    return items\n",
        "\n",
        "\n",
        "def thorsten(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the thorsten meta data file to TTS format\n",
        "    https://github.com/thorstenMueller/deep-learning-german-tts/\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"thorsten\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, \"wavs\", cols[0] + \".wav\")\n",
        "            text = cols[1]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def sam_accenture(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the sam-accenture meta data file to TTS format\n",
        "    https://github.com/Sam-Accenture-Non-Binary-Voice/non-binary-voice-files\"\"\"\n",
        "    xml_file = os.path.join(root_path, \"voice_over_recordings\", meta_file)\n",
        "    xml_root = ET.parse(xml_file).getroot()\n",
        "    items = []\n",
        "    speaker_name = \"sam_accenture\"\n",
        "    for item in xml_root.findall(\"./fileid\"):\n",
        "        text = item.text\n",
        "        wav_file = os.path.join(root_path, \"vo_voice_quality_transformation\", item.get(\"id\") + \".wav\")\n",
        "        if not os.path.exists(wav_file):\n",
        "            print(f\" [!] {wav_file} in metafile does not exist. Skipping...\")\n",
        "            continue\n",
        "        items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def ruslan(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the RUSLAN meta data file to TTS format\n",
        "    https://ruslan-corpus.github.io/\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"ruslan\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, \"RUSLAN\", cols[0] + \".wav\")\n",
        "            text = cols[1]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def css10(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the CSS10 dataset file to TTS format\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"css10\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, cols[0])\n",
        "            text = cols[1]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name})\n",
        "    return items\n",
        "\n",
        "\n",
        "def nancy(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the Nancy meta data file to TTS format\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"nancy\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            utt_id = line.split()[1]\n",
        "            text = line[line.find('\"') + 1 : line.rfind('\"') - 1]\n",
        "            wav_file = os.path.join(root_path, \"wavn\", utt_id + \".wav\")\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name})\n",
        "    return items\n",
        "\n",
        "\n",
        "def common_voice(root_path, meta_file, ignored_speakers=None):\n",
        "    \"\"\"Normalize the common voice meta data file to TTS format.\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            if line.startswith(\"client_id\"):\n",
        "                continue\n",
        "            cols = line.split(\"\\t\")\n",
        "            text = cols[2]\n",
        "            speaker_name = cols[0]\n",
        "            # ignore speakers\n",
        "            if isinstance(ignored_speakers, list):\n",
        "                if speaker_name in ignored_speakers:\n",
        "                    continue\n",
        "            wav_file = os.path.join(root_path, \"clips\", cols[1].replace(\".mp3\", \".wav\"))\n",
        "            items.append(\n",
        "                {\"text\": text, \"audio_file\": wav_file, \"speaker_name\": \"MCV_\" + speaker_name, \"root_path\": root_path}\n",
        "            )\n",
        "    return items\n",
        "\n",
        "\n",
        "def libri_tts(root_path, meta_files=None, ignored_speakers=None):\n",
        "    \"\"\"https://ai.google/tools/datasets/libri-tts/\"\"\"\n",
        "    items = []\n",
        "    if not meta_files:\n",
        "        meta_files = glob(f\"{root_path}/**/*trans.tsv\", recursive=True)\n",
        "    else:\n",
        "        if isinstance(meta_files, str):\n",
        "            meta_files = [os.path.join(root_path, meta_files)]\n",
        "\n",
        "    for meta_file in meta_files:\n",
        "        _meta_file = os.path.basename(meta_file).split(\".\")[0]\n",
        "        with open(meta_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "            for line in ttf:\n",
        "                cols = line.split(\"\\t\")\n",
        "                file_name = cols[0]\n",
        "                speaker_name, chapter_id, *_ = cols[0].split(\"_\")\n",
        "                _root_path = os.path.join(root_path, f\"{speaker_name}/{chapter_id}\")\n",
        "                wav_file = os.path.join(_root_path, file_name + \".wav\")\n",
        "                text = cols[2]\n",
        "                # ignore speakers\n",
        "                if isinstance(ignored_speakers, list):\n",
        "                    if speaker_name in ignored_speakers:\n",
        "                        continue\n",
        "                items.append(\n",
        "                    {\n",
        "                        \"text\": text,\n",
        "                        \"audio_file\": wav_file,\n",
        "                        \"speaker_name\": f\"LTTS_{speaker_name}\",\n",
        "                        \"root_path\": root_path,\n",
        "                    }\n",
        "                )\n",
        "    for item in items:\n",
        "        assert os.path.exists(item[\"audio_file\"]), f\" [!] wav files don't exist - {item['audio_file']}\"\n",
        "    return items\n",
        "\n",
        "\n",
        "def custom_turkish(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"turkish-female\"\n",
        "    skipped_files = []\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, \"wavs\", cols[0].strip() + \".wav\")\n",
        "            if not os.path.exists(wav_file):\n",
        "                skipped_files.append(wav_file)\n",
        "                continue\n",
        "            text = cols[1].strip()\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    print(f\" [!] {len(skipped_files)} files skipped. They don't exist...\")\n",
        "    return items\n",
        "\n",
        "\n",
        "# ToDo: add the dataset link when the dataset is released publicly\n",
        "def brspeech(root_path, meta_file, ignored_speakers=None):\n",
        "    \"\"\"BRSpeech 3.0 beta\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            if line.startswith(\"wav_filename\"):\n",
        "                continue\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, cols[0])\n",
        "            text = cols[2]\n",
        "            speaker_id = cols[3]\n",
        "            # ignore speakers\n",
        "            if isinstance(ignored_speakers, list):\n",
        "                if speaker_id in ignored_speakers:\n",
        "                    continue\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_id, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def vctk(root_path, meta_files=None, wavs_path=\"wav48_silence_trimmed\", mic=\"mic1\", ignored_speakers=None):\n",
        "    \"\"\"VCTK dataset v0.92.\n",
        "\n",
        "    URL:\n",
        "        https://datashare.ed.ac.uk/bitstream/handle/10283/3443/VCTK-Corpus-0.92.zip\n",
        "\n",
        "    This dataset has 2 recordings per speaker that are annotated with ```mic1``` and ```mic2```.\n",
        "    It is believed that (😄 ) ```mic1``` files are the same as the previous version of the dataset.\n",
        "\n",
        "    mic1:\n",
        "        Audio recorded using an omni-directional microphone (DPA 4035).\n",
        "        Contains very low frequency noises.\n",
        "        This is the same audio released in previous versions of VCTK:\n",
        "        https://doi.org/10.7488/ds/1994\n",
        "\n",
        "    mic2:\n",
        "        Audio recorded using a small diaphragm condenser microphone with\n",
        "        very wide bandwidth (Sennheiser MKH 800).\n",
        "        Two speakers, p280 and p315 had technical issues of the audio\n",
        "        recordings using MKH 800.\n",
        "    \"\"\"\n",
        "    file_ext = \"flac\"\n",
        "    items = []\n",
        "    meta_files = glob(f\"{os.path.join(root_path,'txt')}/**/*.txt\", recursive=True)\n",
        "    for meta_file in meta_files:\n",
        "        _, speaker_id, txt_file = os.path.relpath(meta_file, root_path).split(os.sep)\n",
        "        file_id = txt_file.split(\".\")[0]\n",
        "        # ignore speakers\n",
        "        if isinstance(ignored_speakers, list):\n",
        "            if speaker_id in ignored_speakers:\n",
        "                continue\n",
        "        with open(meta_file, \"r\", encoding=\"utf-8\") as file_text:\n",
        "            text = file_text.readlines()[0]\n",
        "        # p280 has no mic2 recordings\n",
        "        if speaker_id == \"p280\":\n",
        "            wav_file = os.path.join(root_path, wavs_path, speaker_id, file_id + f\"_mic1.{file_ext}\")\n",
        "        else:\n",
        "            wav_file = os.path.join(root_path, wavs_path, speaker_id, file_id + f\"_{mic}.{file_ext}\")\n",
        "        if os.path.exists(wav_file):\n",
        "            items.append(\n",
        "                {\"text\": text, \"audio_file\": wav_file, \"speaker_name\": \"VCTK_\" + speaker_id, \"root_path\": root_path}\n",
        "            )\n",
        "        else:\n",
        "            print(f\" [!] wav files don't exist - {wav_file}\")\n",
        "    return items\n",
        "\n",
        "\n",
        "def vctk_old(root_path, meta_files=None, wavs_path=\"wav48\", ignored_speakers=None):\n",
        "    \"\"\"homepages.inf.ed.ac.uk/jyamagis/release/VCTK-Corpus.tar.gz\"\"\"\n",
        "    items = []\n",
        "    meta_files = glob(f\"{os.path.join(root_path,'txt')}/**/*.txt\", recursive=True)\n",
        "    for meta_file in meta_files:\n",
        "        _, speaker_id, txt_file = os.path.relpath(meta_file, root_path).split(os.sep)\n",
        "        file_id = txt_file.split(\".\")[0]\n",
        "        # ignore speakers\n",
        "        if isinstance(ignored_speakers, list):\n",
        "            if speaker_id in ignored_speakers:\n",
        "                continue\n",
        "        with open(meta_file, \"r\", encoding=\"utf-8\") as file_text:\n",
        "            text = file_text.readlines()[0]\n",
        "        wav_file = os.path.join(root_path, wavs_path, speaker_id, file_id + \".wav\")\n",
        "        items.append(\n",
        "            {\"text\": text, \"audio_file\": wav_file, \"speaker_name\": \"VCTK_old_\" + speaker_id, \"root_path\": root_path}\n",
        "        )\n",
        "    return items\n",
        "\n",
        "\n",
        "def synpaflex(root_path, metafiles=None, **kwargs):  # pylint: disable=unused-argument\n",
        "    items = []\n",
        "    speaker_name = \"synpaflex\"\n",
        "    root_path = os.path.join(root_path, \"\")\n",
        "    wav_files = glob(f\"{root_path}**/*.wav\", recursive=True)\n",
        "    for wav_file in wav_files:\n",
        "        if os.sep + \"wav\" + os.sep in wav_file:\n",
        "            txt_file = wav_file.replace(\"wav\", \"txt\")\n",
        "        else:\n",
        "            txt_file = os.path.join(\n",
        "                os.path.dirname(wav_file), \"txt\", os.path.basename(wav_file).replace(\".wav\", \".txt\")\n",
        "            )\n",
        "        if os.path.exists(txt_file) and os.path.exists(wav_file):\n",
        "            with open(txt_file, \"r\", encoding=\"utf-8\") as file_text:\n",
        "                text = file_text.readlines()[0]\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def open_bible(root_path, meta_files=\"train\", ignore_digits_sentences=True, ignored_speakers=None):\n",
        "    \"\"\"ToDo: Refer the paper when available\"\"\"\n",
        "    items = []\n",
        "    split_dir = meta_files\n",
        "    meta_files = glob(f\"{os.path.join(root_path, split_dir)}/**/*.txt\", recursive=True)\n",
        "    for meta_file in meta_files:\n",
        "        _, speaker_id, txt_file = os.path.relpath(meta_file, root_path).split(os.sep)\n",
        "        file_id = txt_file.split(\".\")[0]\n",
        "        # ignore speakers\n",
        "        if isinstance(ignored_speakers, list):\n",
        "            if speaker_id in ignored_speakers:\n",
        "                continue\n",
        "        with open(meta_file, \"r\", encoding=\"utf-8\") as file_text:\n",
        "            text = file_text.readline().replace(\"\\n\", \"\")\n",
        "        # ignore sentences that contains digits\n",
        "        if ignore_digits_sentences and any(map(str.isdigit, text)):\n",
        "            continue\n",
        "        wav_file = os.path.join(root_path, split_dir, speaker_id, file_id + \".flac\")\n",
        "        items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": \"OB_\" + speaker_id, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def mls(root_path, meta_files=None, ignored_speakers=None):\n",
        "    \"\"\"http://www.openslr.org/94/\"\"\"\n",
        "    items = []\n",
        "    with open(os.path.join(root_path, meta_files), \"r\", encoding=\"utf-8\") as meta:\n",
        "        for line in meta:\n",
        "            file, text = line.split(\"\\t\")\n",
        "            text = text[:-1]\n",
        "            speaker, book, *_ = file.split(\"_\")\n",
        "            wav_file = os.path.join(root_path, os.path.dirname(meta_files), \"audio\", speaker, book, file + \".wav\")\n",
        "            # ignore speakers\n",
        "            if isinstance(ignored_speakers, list):\n",
        "                if speaker in ignored_speakers:\n",
        "                    continue\n",
        "            items.append(\n",
        "                {\"text\": text, \"audio_file\": wav_file, \"speaker_name\": \"MLS_\" + speaker, \"root_path\": root_path}\n",
        "            )\n",
        "    return items\n",
        "\n",
        "\n",
        "# ======================================== VOX CELEB ===========================================\n",
        "def voxceleb2(root_path, meta_file=None, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"\n",
        "    :param meta_file   Used only for consistency with load_tts_samples api\n",
        "    \"\"\"\n",
        "    return _voxcel_x(root_path, meta_file, voxcel_idx=\"2\")\n",
        "\n",
        "\n",
        "def voxceleb1(root_path, meta_file=None, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"\n",
        "    :param meta_file   Used only for consistency with load_tts_samples api\n",
        "    \"\"\"\n",
        "    return _voxcel_x(root_path, meta_file, voxcel_idx=\"1\")\n",
        "\n",
        "\n",
        "def _voxcel_x(root_path, meta_file, voxcel_idx):\n",
        "    assert voxcel_idx in [\"1\", \"2\"]\n",
        "    expected_count = 148_000 if voxcel_idx == \"1\" else 1_000_000\n",
        "    voxceleb_path = Path(root_path)\n",
        "    cache_to = voxceleb_path / f\"metafile_voxceleb{voxcel_idx}.csv\"\n",
        "    cache_to.parent.mkdir(exist_ok=True)\n",
        "\n",
        "    # if not exists meta file, crawl recursively for 'wav' files\n",
        "    if meta_file is not None:\n",
        "        with open(str(meta_file), \"r\", encoding=\"utf-8\") as f:\n",
        "            return [x.strip().split(\"|\") for x in f.readlines()]\n",
        "\n",
        "    elif not cache_to.exists():\n",
        "        cnt = 0\n",
        "        meta_data = []\n",
        "        wav_files = voxceleb_path.rglob(\"**/*.wav\")\n",
        "        for path in tqdm(\n",
        "            wav_files,\n",
        "            desc=f\"Building VoxCeleb {voxcel_idx} Meta file ... this needs to be done only once.\",\n",
        "            total=expected_count,\n",
        "        ):\n",
        "            speaker_id = str(Path(path).parent.parent.stem)\n",
        "            assert speaker_id.startswith(\"id\")\n",
        "            text = None  # VoxCel does not provide transciptions, and they are not needed for training the SE\n",
        "            meta_data.append(f\"{text}|{path}|voxcel{voxcel_idx}_{speaker_id}\\n\")\n",
        "            cnt += 1\n",
        "        with open(str(cache_to), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\".join(meta_data))\n",
        "        if cnt < expected_count:\n",
        "            raise ValueError(f\"Found too few instances for Voxceleb. Should be around {expected_count}, is: {cnt}\")\n",
        "\n",
        "    with open(str(cache_to), \"r\", encoding=\"utf-8\") as f:\n",
        "        return [x.strip().split(\"|\") for x in f.readlines()]\n",
        "\n",
        "\n",
        "def emotion(root_path, meta_file, ignored_speakers=None):\n",
        "    \"\"\"Generic emotion dataset\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            if line.startswith(\"file_path\"):\n",
        "                continue\n",
        "            cols = line.split(\",\")\n",
        "            wav_file = os.path.join(root_path, cols[0])\n",
        "            speaker_id = cols[1]\n",
        "            emotion_id = cols[2].replace(\"\\n\", \"\")\n",
        "            # ignore speakers\n",
        "            if isinstance(ignored_speakers, list):\n",
        "                if speaker_id in ignored_speakers:\n",
        "                    continue\n",
        "            items.append(\n",
        "                {\"audio_file\": wav_file, \"speaker_name\": speaker_id, \"emotion_name\": emotion_id, \"root_path\": root_path}\n",
        "            )\n",
        "    return items\n",
        "\n",
        "\n",
        "def baker(root_path: str, meta_file: str, **kwargs) -> List[List[str]]:  # pylint: disable=unused-argument\n",
        "    \"\"\"Normalizes the Baker meta data file to TTS format\n",
        "\n",
        "    Args:\n",
        "        root_path (str): path to the baker dataset\n",
        "        meta_file (str): name of the meta dataset containing names of wav to select and the transcript of the sentence\n",
        "    Returns:\n",
        "        List[List[str]]: List of (text, wav_path, speaker_name) associated with each sentences\n",
        "    \"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"baker\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            wav_name, text = line.rstrip(\"\\n\").split(\"|\")\n",
        "            wav_path = os.path.join(root_path, \"clips_22\", wav_name)\n",
        "            items.append({\"text\": text, \"audio_file\": wav_path, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def kokoro(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Japanese single-speaker dataset from https://github.com/kaiidams/Kokoro-Speech-Dataset\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"kokoro\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, \"wavs\", cols[0] + \".wav\")\n",
        "            text = cols[2].replace(\" \", \"\")\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "\n",
        "\n",
        "def kss(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
        "    \"\"\"Korean single-speaker dataset from https://www.kaggle.com/datasets/bryanpark/korean-single-speaker-speech-dataset\"\"\"\n",
        "    txt_file = os.path.join(root_path, meta_file)\n",
        "    items = []\n",
        "    speaker_name = \"kss\"\n",
        "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
        "        for line in ttf:\n",
        "            cols = line.split(\"|\")\n",
        "            wav_file = os.path.join(root_path, cols[0])\n",
        "            text = cols[2]  # cols[1] => 6월, cols[2] => 유월\n",
        "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
        "    return items\n",
        "'''\n",
        "\n",
        "\n",
        "with open(\"/content/TTS/TTS/tts/datasets/formatters.py\",\"w\") as f:\n",
        "  f.write(code)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dJe52s-prW1o"
      },
      "outputs": [],
      "source": [
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"custom_formatter\", meta_file_train=\"/content/drive/MyDrive/dataset/metadata.csv\", path=root_path, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GAg4A_w8prHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0489cf8-a10f-4984-9467-291ead3d30eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseDatasetConfig(formatter='custom_formatter', dataset_name='', path='/content/drive/MyDrive/dataset/converted', meta_file_train='/content/drive/MyDrive/dataset/metadata.csv', ignored_speakers=None, language='', phonemizer='', meta_file_val='', meta_file_attn_mask='')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dataset_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0haqE1R8rW4P"
      },
      "outputs": [],
      "source": [
        "# GlowTTSConfig: all model related values for training, validating and testing.\n",
        "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
        "config = GlowTTSConfig(\n",
        "    batch_size=1,\n",
        "    eval_batch_size=1,\n",
        "    num_loader_workers=2,\n",
        "    num_eval_loader_workers=2,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=100,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDUHccznrW6l",
        "outputId": "cb9efb09-0be5-43e4-83ab-5988c24552b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "# Modify sample rate if for a custom audio dataset:\n",
        "# ap.sample_rate = 22050"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5EvCjPrOrW9j"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUlmgNe5hm4n",
        "outputId": "762a29fa-94fb-4038-f8d5-96991d14ac43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TTS/TTS/tts/datasets\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/TTS/TTS/tts/datasets\n",
        "from formatters import custom_formatter\n",
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gct4PZndrXBr",
        "outputId": "b242bd60-0675-4bff-eb82-c6c77762b44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset/converted/data-01.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-02.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-03.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-04.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-05.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-06.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-07.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-08.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-09.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-10.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-11.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-12.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-13.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-14.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-15.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-16.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-17.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-18.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-19.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-20.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-21.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-22.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-23.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-24.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-25.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-26.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-27.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-28.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-29.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-30.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-31.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-32.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-33.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-34.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-35.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-36.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-37.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-38.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-39.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-40.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-41.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-42.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-43.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-44.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-45.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-46.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-47.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-48.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-49.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-50.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-51.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-52.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-53.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-54.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-55.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-56.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-57.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-58.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-59.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-60.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-61.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-62.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-63.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-64.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-65.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-66.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-67.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-68.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-69.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-70.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-71.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-72.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-73.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-74.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-76.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-77.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-78.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-79.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-80.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-81.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-82.wav\n",
            "/content/drive/MyDrive/dataset/converted/data-83.wav\n",
            " | > Found 82 files in /content/drive/MyDrive/dataset/converted\n"
          ]
        }
      ],
      "source": [
        "from TTS.tts.datasets import load_tts_samples\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    formatter = custom_formatter,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size= 0.012195121951219513,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wOv9A72_rXEA"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.models.glow_tts import GlowTTS\n",
        "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fehejH6PrXGm",
        "outputId": "2917b266-ec47-48dc-c5c6-455efa97f3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: True\n",
            " | > Precision: fp16\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            " > Model has 28610257 parameters\n"
          ]
        }
      ],
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAGBZobKrXKn",
        "outputId": "08788357-65b6-4a73-f0db-8d4accedd320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 11:56:24) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 81\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 203\n",
            " | > Min text length: 80\n",
            " | > Avg text length: 136.02469135802468\n",
            " | \n",
            " | > Max audio length: 176201.0\n",
            " | > Min audio length: 176201.0\n",
            " | > Avg audio length: 176201.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:56:31 -- STEP: 0/81 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 4.4068  (4.406763553619385)\n",
            "     | > loader_time: 2.857  (2.8570308685302734)\n",
            "\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:56:43 -- STEP: 25/81 -- GLOBAL_STEP: 25\u001b[0m\n",
            "     | > loss: 3.1193394660949707  (3.2002307891845705)\n",
            "     | > log_mle: 0.7333346605300903  (0.744204580783844)\n",
            "     | > loss_dur: 2.386004686355591  (2.4560261885325114)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.0364, device='cuda:0')  (tensor(9.7304, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.5974  (0.4597616672515869)\n",
            "     | > loader_time: 0.0036  (3.2982821750640867)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:56:53 -- STEP: 50/81 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss: 3.6516542434692383  (3.3254688143730164)\n",
            "     | > log_mle: 0.8104709982872009  (0.7502001076936722)\n",
            "     | > loss_dur: 2.8411831855773926  (2.575268691778183)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.7427, device='cuda:0')  (tensor(10.4278, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.3587  (0.4373034906387329)\n",
            "     | > loader_time: 0.0042  (1.6519914674758909)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:57:04 -- STEP: 75/81 -- GLOBAL_STEP: 75\u001b[0m\n",
            "     | > loss: 2.9634130001068115  (3.2924804504101095)\n",
            "     | > log_mle: 0.7339704036712646  (0.748225095638862)\n",
            "     | > loss_dur: 2.229442596435547  (2.544255350186275)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.0439, device='cuda:0')  (tensor(10.4418, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.3957  (0.4384796237945557)\n",
            "     | > loader_time: 0.0029  (1.1033002599080404)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 124\n",
            " | > Min text length: 124\n",
            " | > Avg text length: 124.0\n",
            " | \n",
            " | > Max audio length: 176201.0\n",
            " | > Min audio length: 176201.0\n",
            " | > Avg audio length: 176201.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7795641422271729 \u001b[0m(+0)\n",
            "     | > avg_loss: 3.430224657058716 \u001b[0m(+0)\n",
            "     | > avg_log_mle: 0.738339364528656 \u001b[0m(+0)\n",
            "     | > avg_loss_dur: 2.691885232925415 \u001b[0m(+0)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7795641422271729 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.430224657058716 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.738339364528656 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.691885232925415 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_81.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 11:57:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:57:34 -- STEP: 19/81 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > loss: 3.090282917022705  (3.160123034527427)\n",
            "     | > log_mle: 0.7502326965332031  (0.744166192255522)\n",
            "     | > loss_dur: 2.340050220489502  (2.415956879916944)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.1821, device='cuda:0')  (tensor(10.3164, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.3539  (0.48826176241824504)\n",
            "     | > loader_time: 0.0026  (0.0037635000128495065)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:57:43 -- STEP: 44/81 -- GLOBAL_STEP: 125\u001b[0m\n",
            "     | > loss: 3.3779547214508057  (3.283540725708008)\n",
            "     | > log_mle: 0.7494926452636719  (0.7444490221413699)\n",
            "     | > loss_dur: 2.628462076187134  (2.5390917035666387)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.7599, device='cuda:0')  (tensor(10.5556, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.4513  (0.4249810359694741)\n",
            "     | > loader_time: 0.0038  (0.00389884276823564)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:57:54 -- STEP: 69/81 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > loss: 3.434969425201416  (3.2613792281219927)\n",
            "     | > log_mle: 0.6839388608932495  (0.7475532483363497)\n",
            "     | > loss_dur: 2.751030683517456  (2.5138259866963266)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.5836, device='cuda:0')  (tensor(10.4668, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.2854  (0.4179914999699247)\n",
            "     | > loader_time: 0.0037  (0.003715100495711617)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.48023033142089844 \u001b[0m(-0.2993338108062744)\n",
            "     | > avg_loss:\u001b[92m 3.4081602096557617 \u001b[0m(-0.0220644474029541)\n",
            "     | > avg_log_mle:\u001b[92m 0.7373959422111511 \u001b[0m(-0.0009434223175048828)\n",
            "     | > avg_loss_dur:\u001b[92m 2.670764207839966 \u001b[0m(-0.02112102508544922)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.48023033142089844 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.4081602096557617 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.7373959422111511 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.670764207839966 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_162.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 11:58:15) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:58:22 -- STEP: 13/81 -- GLOBAL_STEP: 175\u001b[0m\n",
            "     | > loss: 2.935649871826172  (3.1167497084690976)\n",
            "     | > log_mle: 0.7253357172012329  (0.73332790686534)\n",
            "     | > loss_dur: 2.2103142738342285  (2.3834218245286207)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.6555, device='cuda:0')  (tensor(10.1826, device='cuda:0'))\n",
            "     | > current_lr: 5e-07 \n",
            "     | > step_time: 0.404  (0.3638616525209867)\n",
            "     | > loader_time: 0.0119  (0.004833496533907375)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:58:34 -- STEP: 38/81 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > loss: 3.505828857421875  (3.2904416950125444)\n",
            "     | > log_mle: 0.7578668594360352  (0.7416963247876418)\n",
            "     | > loss_dur: 2.74796199798584  (2.5487453812047054)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(11.1106, device='cuda:0')  (tensor(10.4301, device='cuda:0'))\n",
            "     | > current_lr: 5e-07 \n",
            "     | > step_time: 0.3081  (0.45107633189151164)\n",
            "     | > loader_time: 0.0057  (0.004397712255779065)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:58:42 -- STEP: 63/81 -- GLOBAL_STEP: 225\u001b[0m\n",
            "     | > loss: 3.114931344985962  (3.2671203121306402)\n",
            "     | > log_mle: 0.7280206084251404  (0.7467474379236736)\n",
            "     | > loss_dur: 2.3869106769561768  (2.5203728846141273)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.9215, device='cuda:0')  (tensor(10.3424, device='cuda:0'))\n",
            "     | > current_lr: 5e-07 \n",
            "     | > step_time: 0.2882  (0.3900525645604209)\n",
            "     | > loader_time: 0.003  (0.0042247091020856595)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.4831924438476562 \u001b[0m(+1.0029621124267578)\n",
            "     | > avg_loss:\u001b[92m 3.373093843460083 \u001b[0m(-0.03506636619567871)\n",
            "     | > avg_log_mle:\u001b[92m 0.7348220944404602 \u001b[0m(-0.002573847770690918)\n",
            "     | > avg_loss_dur:\u001b[92m 2.6382718086242676 \u001b[0m(-0.03249239921569824)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.4831924438476562 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.373093843460083 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.7348220944404602 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.6382718086242676 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_243.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 11:59:01) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:59:04 -- STEP: 7/81 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > loss: 3.063870668411255  (3.1681878566741943)\n",
            "     | > log_mle: 0.7383997440338135  (0.7410731060164315)\n",
            "     | > loss_dur: 2.3254709243774414  (2.427114793232509)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.8549, device='cuda:0')  (tensor(10.1129, device='cuda:0'))\n",
            "     | > current_lr: 7.5e-07 \n",
            "     | > step_time: 0.3045  (0.29556635447910856)\n",
            "     | > loader_time: 0.0024  (0.0033956936427525113)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:59:18 -- STEP: 32/81 -- GLOBAL_STEP: 275\u001b[0m\n",
            "     | > loss: 3.451338291168213  (3.189522407948971)\n",
            "     | > log_mle: 0.7464350461959839  (0.7391336131840944)\n",
            "     | > loss_dur: 2.7049031257629395  (2.450388792902231)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.3736, device='cuda:0')  (tensor(10.0331, device='cuda:0'))\n",
            "     | > current_lr: 7.5e-07 \n",
            "     | > step_time: 0.2935  (0.49192628264427174)\n",
            "     | > loader_time: 0.0118  (0.005383744835853577)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:59:26 -- STEP: 57/81 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > loss: 3.5427632331848145  (3.224268398786846)\n",
            "     | > log_mle: 0.7462700605392456  (0.7429292024227611)\n",
            "     | > loss_dur: 2.7964932918548584  (2.481339191135606)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.2975, device='cuda:0')  (tensor(10.0372, device='cuda:0'))\n",
            "     | > current_lr: 7.5e-07 \n",
            "     | > step_time: 0.2907  (0.4061225464469507)\n",
            "     | > loader_time: 0.0034  (0.004641997186761153)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8963193893432617 \u001b[0m(-0.5868730545043945)\n",
            "     | > avg_loss:\u001b[91m 3.4127938747406006 \u001b[0m(+0.03970003128051758)\n",
            "     | > avg_log_mle:\u001b[92m 0.7299204468727112 \u001b[0m(-0.0049016475677490234)\n",
            "     | > avg_loss_dur:\u001b[91m 2.682873487472534 \u001b[0m(+0.0446016788482666)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8963193893432617 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.4127938747406006 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.7299204468727112 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.682873487472534 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 11:59:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:59:49 -- STEP: 1/81 -- GLOBAL_STEP: 325\u001b[0m\n",
            "     | > loss: 3.0193521976470947  (3.0193521976470947)\n",
            "     | > log_mle: 0.7358322143554688  (0.7358322143554688)\n",
            "     | > loss_dur: 2.283519983291626  (2.283519983291626)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.4851, device='cuda:0')  (tensor(9.4851, device='cuda:0'))\n",
            "     | > current_lr: 1e-06 \n",
            "     | > step_time: 0.2864  (0.28637218475341797)\n",
            "     | > loader_time: 0.0025  (0.002537250518798828)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 11:59:59 -- STEP: 26/81 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > loss: 3.1557507514953613  (3.075535911780137)\n",
            "     | > log_mle: 0.7162788510322571  (0.7324588665595422)\n",
            "     | > loss_dur: 2.439471960067749  (2.3430770360506497)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.4275, device='cuda:0')  (tensor(9.4599, device='cuda:0'))\n",
            "     | > current_lr: 1e-06 \n",
            "     | > step_time: 0.465  (0.3833748193887564)\n",
            "     | > loader_time: 0.0022  (0.0036303171744713415)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:00:08 -- STEP: 51/81 -- GLOBAL_STEP: 375\u001b[0m\n",
            "     | > loss: 3.115311861038208  (3.151525483411901)\n",
            "     | > log_mle: 0.730968713760376  (0.737359347296696)\n",
            "     | > loss_dur: 2.384343147277832  (2.4141661326090493)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.2927, device='cuda:0')  (tensor(9.5578, device='cuda:0'))\n",
            "     | > current_lr: 1e-06 \n",
            "     | > step_time: 0.3007  (0.3766288570329255)\n",
            "     | > loader_time: 0.0108  (0.004016305886062921)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:00:17 -- STEP: 76/81 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > loss: 3.171308994293213  (3.1247916252989523)\n",
            "     | > log_mle: 0.6889926195144653  (0.7346712844936469)\n",
            "     | > loss_dur: 2.482316255569458  (2.390120340021033)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.4414, device='cuda:0')  (tensor(9.4161, device='cuda:0'))\n",
            "     | > current_lr: 1e-06 \n",
            "     | > step_time: 0.3548  (0.3596586679157458)\n",
            "     | > loader_time: 0.0024  (0.0038291466863531816)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8056676387786865 \u001b[0m(-0.0906517505645752)\n",
            "     | > avg_loss:\u001b[92m 3.3102612495422363 \u001b[0m(-0.10253262519836426)\n",
            "     | > avg_log_mle:\u001b[92m 0.7218362092971802 \u001b[0m(-0.008084237575531006)\n",
            "     | > avg_loss_dur:\u001b[92m 2.5884251594543457 \u001b[0m(-0.09444832801818848)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8056676387786865 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.3102612495422363 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.7218362092971802 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.5884251594543457 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_405.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:00:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:00:41 -- STEP: 20/81 -- GLOBAL_STEP: 425\u001b[0m\n",
            "     | > loss: 3.7543842792510986  (2.9595988035202025)\n",
            "     | > log_mle: 0.7307040691375732  (0.7273621469736099)\n",
            "     | > loss_dur: 3.0236802101135254  (2.2322366535663605)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.6038, device='cuda:0')  (tensor(8.7797, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-06 \n",
            "     | > step_time: 0.6419  (0.4513016939163208)\n",
            "     | > loader_time: 0.0119  (0.006554317474365234)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:00:52 -- STEP: 45/81 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > loss: 2.7480685710906982  (3.0611949920654298)\n",
            "     | > log_mle: 0.7531564235687256  (0.7259327305687798)\n",
            "     | > loss_dur: 1.9949121475219727  (2.3352622509002687)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(7.8080, device='cuda:0')  (tensor(8.8711, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-06 \n",
            "     | > step_time: 0.3  (0.4388358857896594)\n",
            "     | > loader_time: 0.007  (0.005619668960571289)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:01:01 -- STEP: 70/81 -- GLOBAL_STEP: 475\u001b[0m\n",
            "     | > loss: 2.8067526817321777  (3.0299755777631487)\n",
            "     | > log_mle: 0.7441936731338501  (0.7268673147474016)\n",
            "     | > loss_dur: 2.062558889389038  (2.303108251094819)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.0665, device='cuda:0')  (tensor(8.7086, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-06 \n",
            "     | > step_time: 0.4316  (0.40118864945002963)\n",
            "     | > loader_time: 0.0147  (0.0057251998356410445)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7218379974365234 \u001b[0m(-0.08382964134216309)\n",
            "     | > avg_loss:\u001b[92m 3.1987202167510986 \u001b[0m(-0.1115410327911377)\n",
            "     | > avg_log_mle:\u001b[92m 0.7095682621002197 \u001b[0m(-0.01226794719696045)\n",
            "     | > avg_loss_dur:\u001b[92m 2.489151954650879 \u001b[0m(-0.0992732048034668)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7218379974365234 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.1987202167510986 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.7095682621002197 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.489151954650879 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_486.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:01:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:01:23 -- STEP: 14/81 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > loss: 3.076331615447998  (2.8690666471208846)\n",
            "     | > log_mle: 0.7440617680549622  (0.7091176339558193)\n",
            "     | > loss_dur: 2.3322699069976807  (2.1599489876202176)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.4854, device='cuda:0')  (tensor(8.0978, device='cuda:0'))\n",
            "     | > current_lr: 1.5e-06 \n",
            "     | > step_time: 0.6902  (0.42374982152666363)\n",
            "     | > loader_time: 0.0031  (0.005779079028538295)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:01:36 -- STEP: 39/81 -- GLOBAL_STEP: 525\u001b[0m\n",
            "     | > loss: 3.2259724140167236  (2.9761779063787217)\n",
            "     | > log_mle: 0.6923699975013733  (0.711193981843117)\n",
            "     | > loss_dur: 2.533602476119995  (2.2649839230072804)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.6599, device='cuda:0')  (tensor(8.1457, device='cuda:0'))\n",
            "     | > current_lr: 1.5e-06 \n",
            "     | > step_time: 0.3021  (0.45522594451904297)\n",
            "     | > loader_time: 0.0027  (0.005806947365785256)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:01:44 -- STEP: 64/81 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > loss: 2.9991326332092285  (2.943135604262352)\n",
            "     | > log_mle: 0.7511483430862427  (0.7151301372796297)\n",
            "     | > loss_dur: 2.2479841709136963  (2.228005459532142)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(7.9006, device='cuda:0')  (tensor(7.9895, device='cuda:0'))\n",
            "     | > current_lr: 1.5e-06 \n",
            "     | > step_time: 0.4141  (0.4026394598186016)\n",
            "     | > loader_time: 0.0025  (0.005248233675956726)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7323026657104492 \u001b[0m(+0.010464668273925781)\n",
            "     | > avg_loss:\u001b[92m 3.0569300651550293 \u001b[0m(-0.14179015159606934)\n",
            "     | > avg_log_mle:\u001b[92m 0.6917133927345276 \u001b[0m(-0.01785486936569214)\n",
            "     | > avg_loss_dur:\u001b[92m 2.3652167320251465 \u001b[0m(-0.12393522262573242)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7323026657104492 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 3.0569300651550293 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.6917133927345276 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.3652167320251465 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_567.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:02:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:02:12 -- STEP: 8/81 -- GLOBAL_STEP: 575\u001b[0m\n",
            "     | > loss: 2.526681661605835  (2.8132904767990112)\n",
            "     | > log_mle: 0.6870899796485901  (0.6988984942436218)\n",
            "     | > loss_dur: 1.8395917415618896  (2.114391967654228)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(6.7728, device='cuda:0')  (tensor(7.4134, device='cuda:0'))\n",
            "     | > current_lr: 1.75e-06 \n",
            "     | > step_time: 0.4797  (0.5848800539970398)\n",
            "     | > loader_time: 0.0028  (0.008994877338409424)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:02:22 -- STEP: 33/81 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > loss: 3.0657033920288086  (2.838863351128318)\n",
            "     | > log_mle: 0.6787117719650269  (0.694871521357334)\n",
            "     | > loss_dur: 2.3869917392730713  (2.143991813515172)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(7.8646, device='cuda:0')  (tensor(7.3570, device='cuda:0'))\n",
            "     | > current_lr: 1.75e-06 \n",
            "     | > step_time: 0.3043  (0.4327403415333141)\n",
            "     | > loader_time: 0.0032  (0.005567803527369644)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:02:31 -- STEP: 58/81 -- GLOBAL_STEP: 625\u001b[0m\n",
            "     | > loss: 2.865020275115967  (2.8571495804293403)\n",
            "     | > log_mle: 0.686612606048584  (0.6955251858152194)\n",
            "     | > loss_dur: 2.178407669067383  (2.161624384337457)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(6.8857, device='cuda:0')  (tensor(7.3084, device='cuda:0'))\n",
            "     | > current_lr: 1.75e-06 \n",
            "     | > step_time: 0.4306  (0.407983685361928)\n",
            "     | > loader_time: 0.0044  (0.005600435980435074)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5034120082855225 \u001b[0m(-0.22889065742492676)\n",
            "     | > avg_loss:\u001b[92m 2.802098274230957 \u001b[0m(-0.25483179092407227)\n",
            "     | > avg_log_mle:\u001b[92m 0.666049599647522 \u001b[0m(-0.025663793087005615)\n",
            "     | > avg_loss_dur:\u001b[92m 2.1360487937927246 \u001b[0m(-0.22916793823242188)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5034120082855225 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 2.802098274230957 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.666049599647522 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 2.1360487937927246 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_648.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:02:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:02:55 -- STEP: 2/81 -- GLOBAL_STEP: 650\u001b[0m\n",
            "     | > loss: 2.766735076904297  (2.7193400859832764)\n",
            "     | > log_mle: 0.7120653390884399  (0.692907065153122)\n",
            "     | > loss_dur: 2.0546696186065674  (2.026432991027832)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(6.9936, device='cuda:0')  (tensor(6.8452, device='cuda:0'))\n",
            "     | > current_lr: 2e-06 \n",
            "     | > step_time: 0.5139  (0.5043021440505981)\n",
            "     | > loader_time: 0.0081  (0.011107921600341797)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:03:05 -- STEP: 27/81 -- GLOBAL_STEP: 675\u001b[0m\n",
            "     | > loss: 2.394285202026367  (2.618343794787372)\n",
            "     | > log_mle: 0.6580624580383301  (0.6712621340045223)\n",
            "     | > loss_dur: 1.7362226247787476  (1.9470816497449521)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.3592, device='cuda:0')  (tensor(6.4364, device='cuda:0'))\n",
            "     | > current_lr: 2e-06 \n",
            "     | > step_time: 0.3834  (0.38856866624620223)\n",
            "     | > loader_time: 0.0039  (0.00518826202110008)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:03:17 -- STEP: 52/81 -- GLOBAL_STEP: 700\u001b[0m\n",
            "     | > loss: 2.0729682445526123  (2.639710701428927)\n",
            "     | > log_mle: 0.6725758910179138  (0.6710979124674429)\n",
            "     | > loss_dur: 1.4003922939300537  (1.968612790107727)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.1835, device='cuda:0')  (tensor(6.3830, device='cuda:0'))\n",
            "     | > current_lr: 2e-06 \n",
            "     | > step_time: 0.4348  (0.4186320992616507)\n",
            "     | > loader_time: 0.0035  (0.004940129243410551)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:03:25 -- STEP: 77/81 -- GLOBAL_STEP: 725\u001b[0m\n",
            "     | > loss: 2.036531925201416  (2.6107067163888513)\n",
            "     | > log_mle: 0.6790937185287476  (0.6645720105666618)\n",
            "     | > loss_dur: 1.357438087463379  (1.9461347019517576)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.0069, device='cuda:0')  (tensor(6.2445, device='cuda:0'))\n",
            "     | > current_lr: 2e-06 \n",
            "     | > step_time: 0.2249  (0.388225930077689)\n",
            "     | > loader_time: 0.0018  (0.004683237571220894)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5138025283813477 \u001b[0m(+0.010390520095825195)\n",
            "     | > avg_loss:\u001b[92m 2.6178436279296875 \u001b[0m(-0.18425464630126953)\n",
            "     | > avg_log_mle:\u001b[92m 0.629042387008667 \u001b[0m(-0.03700721263885498)\n",
            "     | > avg_loss_dur:\u001b[92m 1.988801121711731 \u001b[0m(-0.14724767208099365)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5138025283813477 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 2.6178436279296875 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.629042387008667 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.988801121711731 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_729.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:03:41) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:03:55 -- STEP: 21/81 -- GLOBAL_STEP: 750\u001b[0m\n",
            "     | > loss: 2.395595073699951  (2.440653227624439)\n",
            "     | > log_mle: 0.6252436637878418  (0.6456024958973839)\n",
            "     | > loss_dur: 1.7703512907028198  (1.7950507061822074)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.4095, device='cuda:0')  (tensor(5.6731, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-06 \n",
            "     | > step_time: 0.4467  (0.5404620397658575)\n",
            "     | > loader_time: 0.0117  (0.006414038794381278)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:04:06 -- STEP: 46/81 -- GLOBAL_STEP: 775\u001b[0m\n",
            "     | > loss: 2.5824525356292725  (2.4808495951735443)\n",
            "     | > log_mle: 0.7075427174568176  (0.6381596002889718)\n",
            "     | > loss_dur: 1.8749098777770996  (1.842689988405808)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.6463, device='cuda:0')  (tensor(5.6215, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-06 \n",
            "     | > step_time: 0.2892  (0.48024184289185895)\n",
            "     | > loader_time: 0.0029  (0.0062482253364894704)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:04:14 -- STEP: 71/81 -- GLOBAL_STEP: 800\u001b[0m\n",
            "     | > loss: 2.1565303802490234  (2.44537809701033)\n",
            "     | > log_mle: 0.5666433572769165  (0.6303837526012477)\n",
            "     | > loss_dur: 1.589887022972107  (1.814994341890577)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.8462, device='cuda:0')  (tensor(5.4963, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-06 \n",
            "     | > step_time: 0.2916  (0.4159698486328124)\n",
            "     | > loader_time: 0.0049  (0.005513738578474017)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7488358020782471 \u001b[0m(+0.23503327369689941)\n",
            "     | > avg_loss:\u001b[92m 2.5209856033325195 \u001b[0m(-0.09685802459716797)\n",
            "     | > avg_log_mle:\u001b[92m 0.5786827802658081 \u001b[0m(-0.05035960674285889)\n",
            "     | > avg_loss_dur:\u001b[92m 1.9423028230667114 \u001b[0m(-0.04649829864501953)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7488358020782471 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 2.5209856033325195 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.5786827802658081 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.9423028230667114 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_810.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:04:32) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:04:40 -- STEP: 15/81 -- GLOBAL_STEP: 825\u001b[0m\n",
            "     | > loss: 2.268953561782837  (2.292290218671163)\n",
            "     | > log_mle: 0.6384844183921814  (0.6040249466896057)\n",
            "     | > loss_dur: 1.6304692029953003  (1.688265283902486)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.0050, device='cuda:0')  (tensor(5.0739, device='cuda:0'))\n",
            "     | > current_lr: 2.4999999999999998e-06 \n",
            "     | > step_time: 0.531  (0.4093283176422119)\n",
            "     | > loader_time: 0.0036  (0.004811875025431315)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:04:53 -- STEP: 40/81 -- GLOBAL_STEP: 850\u001b[0m\n",
            "     | > loss: 2.5544021129608154  (2.3766233682632447)\n",
            "     | > log_mle: 0.6386281847953796  (0.590311226248741)\n",
            "     | > loss_dur: 1.915773868560791  (1.7863121390342713)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.1993, device='cuda:0')  (tensor(5.1252, device='cuda:0'))\n",
            "     | > current_lr: 2.4999999999999998e-06 \n",
            "     | > step_time: 0.2944  (0.4569412171840668)\n",
            "     | > loader_time: 0.0024  (0.004869693517684936)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:05:01 -- STEP: 65/81 -- GLOBAL_STEP: 875\u001b[0m\n",
            "     | > loss: 1.9105987548828125  (2.346762378399189)\n",
            "     | > log_mle: 0.5959470868110657  (0.5868249054138475)\n",
            "     | > loss_dur: 1.314651608467102  (1.7599374752778274)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.2232, device='cuda:0')  (tensor(5.0574, device='cuda:0'))\n",
            "     | > current_lr: 2.4999999999999998e-06 \n",
            "     | > step_time: 0.4556  (0.4038821000319261)\n",
            "     | > loader_time: 0.0126  (0.00489199344928448)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8701438903808594 \u001b[0m(+0.1213080883026123)\n",
            "     | > avg_loss:\u001b[92m 2.340648651123047 \u001b[0m(-0.18033695220947266)\n",
            "     | > avg_log_mle:\u001b[92m 0.5208994746208191 \u001b[0m(-0.057783305644989014)\n",
            "     | > avg_loss_dur:\u001b[92m 1.8197492361068726 \u001b[0m(-0.12255358695983887)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8701438903808594 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 2.340648651123047 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.5208994746208191 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.8197492361068726 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_891.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:05:19) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:05:24 -- STEP: 9/81 -- GLOBAL_STEP: 900\u001b[0m\n",
            "     | > loss: 2.087348461151123  (2.2337039841545954)\n",
            "     | > log_mle: 0.5921699404716492  (0.5646638804011874)\n",
            "     | > loss_dur: 1.495178461074829  (1.6690400838851929)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.4404, device='cuda:0')  (tensor(4.7729, device='cuda:0'))\n",
            "     | > current_lr: 2.75e-06 \n",
            "     | > step_time: 0.4869  (0.403886874516805)\n",
            "     | > loader_time: 0.0025  (0.00471851560804579)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:05:37 -- STEP: 34/81 -- GLOBAL_STEP: 925\u001b[0m\n",
            "     | > loss: 1.8633003234863281  (2.2449839535881493)\n",
            "     | > log_mle: 0.5698226094245911  (0.5451469736940722)\n",
            "     | > loss_dur: 1.2934776544570923  (1.6998369483386768)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.9806, device='cuda:0')  (tensor(4.7716, device='cuda:0'))\n",
            "     | > current_lr: 2.75e-06 \n",
            "     | > step_time: 0.3997  (0.4719057013006771)\n",
            "     | > loader_time: 0.0086  (0.008011123713325049)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:05:46 -- STEP: 59/81 -- GLOBAL_STEP: 950\u001b[0m\n",
            "     | > loss: 2.0292446613311768  (2.2810489707073924)\n",
            "     | > log_mle: 0.48667797446250916  (0.5354698355925285)\n",
            "     | > loss_dur: 1.5425667762756348  (1.7455791234970093)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.4745, device='cuda:0')  (tensor(4.8580, device='cuda:0'))\n",
            "     | > current_lr: 2.75e-06 \n",
            "     | > step_time: 0.4894  (0.4235016006534382)\n",
            "     | > loader_time: 0.0032  (0.006766949669789458)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5085625648498535 \u001b[0m(-0.36158132553100586)\n",
            "     | > avg_loss:\u001b[92m 2.2192018032073975 \u001b[0m(-0.12144684791564941)\n",
            "     | > avg_log_mle:\u001b[92m 0.4641801118850708 \u001b[0m(-0.05671936273574829)\n",
            "     | > avg_loss_dur:\u001b[92m 1.7550216913223267 \u001b[0m(-0.0647275447845459)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5085625648498535 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 2.2192018032073975 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.4641801118850708 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.7550216913223267 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_972.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:06:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:06:10 -- STEP: 3/81 -- GLOBAL_STEP: 975\u001b[0m\n",
            "     | > loss: 1.9577690362930298  (2.133087674776713)\n",
            "     | > log_mle: 0.5210003852844238  (0.5347867012023926)\n",
            "     | > loss_dur: 1.436768651008606  (1.5983009735743205)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.2671, device='cuda:0')  (tensor(4.6763, device='cuda:0'))\n",
            "     | > current_lr: 3e-06 \n",
            "     | > step_time: 0.5098  (0.4958759943644206)\n",
            "     | > loader_time: 0.0132  (0.009255727132161459)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:06:22 -- STEP: 28/81 -- GLOBAL_STEP: 1000\u001b[0m\n",
            "     | > loss: 2.0606555938720703  (2.10895203266825)\n",
            "     | > log_mle: 0.5203424692153931  (0.49954080688101893)\n",
            "     | > loss_dur: 1.5403132438659668  (1.6094112311090742)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.2622, device='cuda:0')  (tensor(4.5431, device='cuda:0'))\n",
            "     | > current_lr: 3e-06 \n",
            "     | > step_time: 0.426  (0.4772680827549526)\n",
            "     | > loader_time: 0.0043  (0.0078229478427342)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_1000.pth\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:06:43 -- STEP: 53/81 -- GLOBAL_STEP: 1025\u001b[0m\n",
            "     | > loss: 2.3312582969665527  (2.1431838633879186)\n",
            "     | > log_mle: 0.37220191955566406  (0.4906191932705213)\n",
            "     | > loss_dur: 1.9590564966201782  (1.652564674053552)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.1861, device='cuda:0')  (tensor(4.5968, device='cuda:0'))\n",
            "     | > current_lr: 3e-06 \n",
            "     | > step_time: 0.3455  (0.4588579501745836)\n",
            "     | > loader_time: 0.003  (0.006739971772679743)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:06:51 -- STEP: 78/81 -- GLOBAL_STEP: 1050\u001b[0m\n",
            "     | > loss: 2.345921516418457  (2.1145419570115904)\n",
            "     | > log_mle: 0.2535645365715027  (0.478395524697426)\n",
            "     | > loss_dur: 2.0923569202423096  (1.6361464353708117)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.6201, device='cuda:0')  (tensor(4.5585, device='cuda:0'))\n",
            "     | > current_lr: 3e-06 \n",
            "     | > step_time: 0.3664  (0.41429685323666304)\n",
            "     | > loader_time: 0.0025  (0.0056790480246910685)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7283010482788086 \u001b[0m(+0.21973848342895508)\n",
            "     | > avg_loss:\u001b[92m 2.0946295261383057 \u001b[0m(-0.1245722770690918)\n",
            "     | > avg_log_mle:\u001b[92m 0.40620261430740356 \u001b[0m(-0.057977497577667236)\n",
            "     | > avg_loss_dur:\u001b[92m 1.6884269714355469 \u001b[0m(-0.06659471988677979)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7283010482788086 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 2.0946295261383057 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.40620261430740356 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.6884269714355469 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1053.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:07:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:07:15 -- STEP: 22/81 -- GLOBAL_STEP: 1075\u001b[0m\n",
            "     | > loss: 2.3638346195220947  (2.0011570236899634)\n",
            "     | > log_mle: 0.39070290327072144  (0.4644024521112442)\n",
            "     | > loss_dur: 1.9731316566467285  (1.5367545702240684)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.1543, device='cuda:0')  (tensor(4.4244, device='cuda:0'))\n",
            "     | > current_lr: 3.25e-06 \n",
            "     | > step_time: 0.5033  (0.39168943058360706)\n",
            "     | > loader_time: 0.0168  (0.00660772757096724)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:07:27 -- STEP: 47/81 -- GLOBAL_STEP: 1100\u001b[0m\n",
            "     | > loss: 1.9833475351333618  (2.026791095733642)\n",
            "     | > log_mle: 0.3611443042755127  (0.4481836513001868)\n",
            "     | > loss_dur: 1.6222032308578491  (1.578607439994812)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.6097, device='cuda:0')  (tensor(4.4756, device='cuda:0'))\n",
            "     | > current_lr: 3.25e-06 \n",
            "     | > step_time: 0.3412  (0.4319845970640791)\n",
            "     | > loader_time: 0.0032  (0.005370997368021214)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:07:35 -- STEP: 72/81 -- GLOBAL_STEP: 1125\u001b[0m\n",
            "     | > loss: 1.7774572372436523  (1.993204277422692)\n",
            "     | > log_mle: 0.3984299302101135  (0.43545645309819114)\n",
            "     | > loss_dur: 1.3790273666381836  (1.557747819357448)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.2486, device='cuda:0')  (tensor(4.4358, device='cuda:0'))\n",
            "     | > current_lr: 3.25e-06 \n",
            "     | > step_time: 0.4849  (0.3971512383884853)\n",
            "     | > loader_time: 0.0051  (0.004865378141403198)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9278948307037354 \u001b[0m(+0.19959378242492676)\n",
            "     | > avg_loss:\u001b[92m 1.9175076484680176 \u001b[0m(-0.17712187767028809)\n",
            "     | > avg_log_mle:\u001b[92m 0.354763925075531 \u001b[0m(-0.05143868923187256)\n",
            "     | > avg_loss_dur:\u001b[92m 1.5627436637878418 \u001b[0m(-0.12568330764770508)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.9278948307037354 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.9175076484680176 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.354763925075531 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.5627436637878418 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1134.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:07:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:08:07 -- STEP: 16/81 -- GLOBAL_STEP: 1150\u001b[0m\n",
            "     | > loss: 2.1059651374816895  (1.8317976519465446)\n",
            "     | > log_mle: 0.34266114234924316  (0.4218494463711977)\n",
            "     | > loss_dur: 1.7633041143417358  (1.409948218613863)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.7927, device='cuda:0')  (tensor(4.2275, device='cuda:0'))\n",
            "     | > current_lr: 3.5e-06 \n",
            "     | > step_time: 0.6555  (0.49792735278606415)\n",
            "     | > loader_time: 0.0052  (0.007607102394104004)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:08:17 -- STEP: 41/81 -- GLOBAL_STEP: 1175\u001b[0m\n",
            "     | > loss: 1.7736636400222778  (1.9018294404192668)\n",
            "     | > log_mle: 0.36103832721710205  (0.39999643549686525)\n",
            "     | > loss_dur: 1.4126253128051758  (1.501833010010603)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.9129, device='cuda:0')  (tensor(4.3877, device='cuda:0'))\n",
            "     | > current_lr: 3.5e-06 \n",
            "     | > step_time: 0.3321  (0.4217906347135218)\n",
            "     | > loader_time: 0.0031  (0.00584176110058296)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:08:29 -- STEP: 66/81 -- GLOBAL_STEP: 1200\u001b[0m\n",
            "     | > loss: 1.7001639604568481  (1.8749862439704663)\n",
            "     | > log_mle: 0.45016488432884216  (0.39701167652101227)\n",
            "     | > loss_dur: 1.2499990463256836  (1.4779745782866622)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.5977, device='cuda:0')  (tensor(4.3341, device='cuda:0'))\n",
            "     | > current_lr: 3.5e-06 \n",
            "     | > step_time: 0.4849  (0.4378123066642068)\n",
            "     | > loader_time: 0.0108  (0.006055615165016868)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5828783512115479 \u001b[0m(-0.3450164794921875)\n",
            "     | > avg_loss:\u001b[92m 1.7952734231948853 \u001b[0m(-0.12223422527313232)\n",
            "     | > avg_log_mle:\u001b[92m 0.31112396717071533 \u001b[0m(-0.043639957904815674)\n",
            "     | > avg_loss_dur:\u001b[92m 1.48414945602417 \u001b[0m(-0.07859420776367188)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5828783512115479 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.7952734231948853 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.31112396717071533 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.48414945602417 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1215.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 15/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:08:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:08:53 -- STEP: 10/81 -- GLOBAL_STEP: 1225\u001b[0m\n",
            "     | > loss: 1.6090874671936035  (1.7269905924797058)\n",
            "     | > log_mle: 0.274541974067688  (0.3913147509098053)\n",
            "     | > loss_dur: 1.3345454931259155  (1.335675847530365)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.7514, device='cuda:0')  (tensor(4.4338, device='cuda:0'))\n",
            "     | > current_lr: 3.7499999999999997e-06 \n",
            "     | > step_time: 0.4166  (0.4116292715072632)\n",
            "     | > loader_time: 0.0027  (0.007329082489013672)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:09:02 -- STEP: 35/81 -- GLOBAL_STEP: 1250\u001b[0m\n",
            "     | > loss: 1.606139898300171  (1.7419755390712193)\n",
            "     | > log_mle: 0.35717183351516724  (0.37094520074980597)\n",
            "     | > loss_dur: 1.2489681243896484  (1.3710303374699184)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.8161, device='cuda:0')  (tensor(4.5541, device='cuda:0'))\n",
            "     | > current_lr: 3.7499999999999997e-06 \n",
            "     | > step_time: 0.6068  (0.3910666193280901)\n",
            "     | > loader_time: 0.0168  (0.005670874459402901)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:09:14 -- STEP: 60/81 -- GLOBAL_STEP: 1275\u001b[0m\n",
            "     | > loss: 1.5038135051727295  (1.7567581097284952)\n",
            "     | > log_mle: 0.507056474685669  (0.36096698890129725)\n",
            "     | > loss_dur: 0.9967570304870605  (1.395791119337082)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.3458, device='cuda:0')  (tensor(4.5396, device='cuda:0'))\n",
            "     | > current_lr: 3.7499999999999997e-06 \n",
            "     | > step_time: 0.2975  (0.4154176712036133)\n",
            "     | > loader_time: 0.0031  (0.005321486790974935)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5505852699279785 \u001b[0m(-0.032293081283569336)\n",
            "     | > avg_loss:\u001b[92m 1.659976840019226 \u001b[0m(-0.13529658317565918)\n",
            "     | > avg_log_mle:\u001b[92m 0.2774242162704468 \u001b[0m(-0.033699750900268555)\n",
            "     | > avg_loss_dur:\u001b[92m 1.3825526237487793 \u001b[0m(-0.10159683227539062)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5505852699279785 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.659976840019226 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.2774242162704468 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.3825526237487793 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1296.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 16/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:09:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:09:40 -- STEP: 4/81 -- GLOBAL_STEP: 1300\u001b[0m\n",
            "     | > loss: 1.7583496570587158  (1.6441853940486908)\n",
            "     | > log_mle: 0.26891231536865234  (0.3618009686470032)\n",
            "     | > loss_dur: 1.4894373416900635  (1.2823844254016876)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(6.2222, device='cuda:0')  (tensor(4.6028, device='cuda:0'))\n",
            "     | > current_lr: 4e-06 \n",
            "     | > step_time: 0.3109  (0.30199486017227173)\n",
            "     | > loader_time: 0.0028  (0.00435328483581543)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:09:51 -- STEP: 29/81 -- GLOBAL_STEP: 1325\u001b[0m\n",
            "     | > loss: 2.5085885524749756  (1.6429365955550095)\n",
            "     | > log_mle: 0.3432486057281494  (0.3449994448957772)\n",
            "     | > loss_dur: 2.165339946746826  (1.297937152714565)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(10.7690, device='cuda:0')  (tensor(4.8281, device='cuda:0'))\n",
            "     | > current_lr: 4e-06 \n",
            "     | > step_time: 0.5593  (0.44616071931247053)\n",
            "     | > loader_time: 0.0037  (0.004142654353174671)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:10:01 -- STEP: 54/81 -- GLOBAL_STEP: 1350\u001b[0m\n",
            "     | > loss: 2.03364634513855  (1.6525463682633859)\n",
            "     | > log_mle: 0.21639329195022583  (0.33577428813333865)\n",
            "     | > loss_dur: 1.8172529935836792  (1.316772081233837)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(6.4105, device='cuda:0')  (tensor(4.8079, device='cuda:0'))\n",
            "     | > current_lr: 4e-06 \n",
            "     | > step_time: 0.3066  (0.4196380685876917)\n",
            "     | > loader_time: 0.0026  (0.004177225960625544)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:10:09 -- STEP: 79/81 -- GLOBAL_STEP: 1375\u001b[0m\n",
            "     | > loss: 1.574100375175476  (1.6237026045594034)\n",
            "     | > log_mle: 0.2718617916107178  (0.3259785835501514)\n",
            "     | > loss_dur: 1.3022385835647583  (1.2977240221409856)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.1110, device='cuda:0')  (tensor(5.1090, device='cuda:0'))\n",
            "     | > current_lr: 4e-06 \n",
            "     | > step_time: 0.3522  (0.38643449771253374)\n",
            "     | > loader_time: 0.0041  (0.003997576387622688)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8071155548095703 \u001b[0m(+0.2565302848815918)\n",
            "     | > avg_loss:\u001b[92m 1.568298578262329 \u001b[0m(-0.09167826175689697)\n",
            "     | > avg_log_mle:\u001b[92m 0.24900084733963013 \u001b[0m(-0.02842336893081665)\n",
            "     | > avg_loss_dur:\u001b[92m 1.3192976713180542 \u001b[0m(-0.0632549524307251)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8071155548095703 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.568298578262329 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.24900084733963013 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.3192976713180542 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1377.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 17/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:10:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:10:39 -- STEP: 23/81 -- GLOBAL_STEP: 1400\u001b[0m\n",
            "     | > loss: 1.1606616973876953  (1.5249841420546821)\n",
            "     | > log_mle: 0.1727285385131836  (0.33471216196599224)\n",
            "     | > loss_dur: 0.9879331588745117  (1.1902719865674558)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.0834, device='cuda:0')  (tensor(4.9114, device='cuda:0'))\n",
            "     | > current_lr: 4.25e-06 \n",
            "     | > step_time: 0.4211  (0.4953827132349429)\n",
            "     | > loader_time: 0.0116  (0.0096609177796737)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:10:48 -- STEP: 48/81 -- GLOBAL_STEP: 1425\u001b[0m\n",
            "     | > loss: 1.2991087436676025  (1.5645401999354362)\n",
            "     | > log_mle: 0.23144716024398804  (0.3217371093730133)\n",
            "     | > loss_dur: 1.0676616430282593  (1.2428030942877137)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(8.1581, device='cuda:0')  (tensor(5.0705, device='cuda:0'))\n",
            "     | > current_lr: 4.25e-06 \n",
            "     | > step_time: 0.3143  (0.4286534935235977)\n",
            "     | > loader_time: 0.0022  (0.006934508681297302)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:10:58 -- STEP: 73/81 -- GLOBAL_STEP: 1450\u001b[0m\n",
            "     | > loss: 2.2416276931762695  (1.5530246871791473)\n",
            "     | > log_mle: 0.17852717638015747  (0.3094305240944642)\n",
            "     | > loss_dur: 2.063100576400757  (1.2435941663506913)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(9.6854, device='cuda:0')  (tensor(5.7268, device='cuda:0'))\n",
            "     | > current_lr: 4.25e-06 \n",
            "     | > step_time: 0.402  (0.41993521011039003)\n",
            "     | > loader_time: 0.0029  (0.007489139086579623)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5839571952819824 \u001b[0m(-0.2231583595275879)\n",
            "     | > avg_loss:\u001b[92m 1.4869632720947266 \u001b[0m(-0.08133530616760254)\n",
            "     | > avg_log_mle:\u001b[92m 0.22730368375778198 \u001b[0m(-0.021697163581848145)\n",
            "     | > avg_loss_dur:\u001b[92m 1.2596596479415894 \u001b[0m(-0.059638023376464844)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5839571952819824 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.4869632720947266 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.22730368375778198 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.2596596479415894 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1458.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 18/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:11:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:11:24 -- STEP: 17/81 -- GLOBAL_STEP: 1475\u001b[0m\n",
            "     | > loss: 1.5000648498535156  (1.4430999896105599)\n",
            "     | > log_mle: 0.3560947775840759  (0.32450567974763755)\n",
            "     | > loss_dur: 1.1439701318740845  (1.1185943203813888)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.4023, device='cuda:0')  (tensor(4.7579, device='cuda:0'))\n",
            "     | > current_lr: 4.5e-06 \n",
            "     | > step_time: 0.4548  (0.5001017486347872)\n",
            "     | > loader_time: 0.0028  (0.005125382367302389)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:11:34 -- STEP: 42/81 -- GLOBAL_STEP: 1500\u001b[0m\n",
            "     | > loss: 1.4895718097686768  (1.4940817412875949)\n",
            "     | > log_mle: 0.34825748205184937  (0.29908258787223263)\n",
            "     | > loss_dur: 1.1413143873214722  (1.1949991583824158)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.1755, device='cuda:0')  (tensor(5.6783, device='cuda:0'))\n",
            "     | > current_lr: 4.5e-06 \n",
            "     | > step_time: 0.4359  (0.4228660890034267)\n",
            "     | > loader_time: 0.0055  (0.004858238356454032)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:11:46 -- STEP: 67/81 -- GLOBAL_STEP: 1525\u001b[0m\n",
            "     | > loss: 1.4038002490997314  (1.475235689931841)\n",
            "     | > log_mle: 0.3083645701408386  (0.29566980030999257)\n",
            "     | > loss_dur: 1.095435619354248  (1.1795658922907133)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.9726, device='cuda:0')  (tensor(6.3903, device='cuda:0'))\n",
            "     | > current_lr: 4.5e-06 \n",
            "     | > step_time: 0.516  (0.4510929264239411)\n",
            "     | > loader_time: 0.005  (0.006125386081524749)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8352599143981934 \u001b[0m(+0.25130271911621094)\n",
            "     | > avg_loss:\u001b[92m 1.412409782409668 \u001b[0m(-0.0745534896850586)\n",
            "     | > avg_log_mle:\u001b[92m 0.208621084690094 \u001b[0m(-0.01868259906768799)\n",
            "     | > avg_loss_dur:\u001b[92m 1.2037887573242188 \u001b[0m(-0.055870890617370605)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8352599143981934 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.412409782409668 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.208621084690094 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.2037887573242188 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1539.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 19/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:12:14) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:12:21 -- STEP: 11/81 -- GLOBAL_STEP: 1550\u001b[0m\n",
            "     | > loss: 1.0519955158233643  (1.3650299527428367)\n",
            "     | > log_mle: 0.374853253364563  (0.3147256455638192)\n",
            "     | > loss_dur: 0.6771422028541565  (1.0503042990511113)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.1708, device='cuda:0')  (tensor(5.5845, device='cuda:0'))\n",
            "     | > current_lr: 4.749999999999999e-06 \n",
            "     | > step_time: 0.4569  (0.4446122646331787)\n",
            "     | > loader_time: 0.0033  (0.0035135312513871627)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:12:33 -- STEP: 36/81 -- GLOBAL_STEP: 1575\u001b[0m\n",
            "     | > loss: 1.7026708126068115  (1.4273668494489455)\n",
            "     | > log_mle: 0.215559720993042  (0.2845624362428983)\n",
            "     | > loss_dur: 1.4871110916137695  (1.1428044107225204)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(7.6224, device='cuda:0')  (tensor(6.8517, device='cuda:0'))\n",
            "     | > current_lr: 4.749999999999999e-06 \n",
            "     | > step_time: 0.3055  (0.4654039078288608)\n",
            "     | > loader_time: 0.005  (0.004745417171054416)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:12:40 -- STEP: 61/81 -- GLOBAL_STEP: 1600\u001b[0m\n",
            "     | > loss: 1.3434100151062012  (1.4324054600762535)\n",
            "     | > log_mle: 0.41413557529449463  (0.27860887812786417)\n",
            "     | > loss_dur: 0.9292744398117065  (1.1537965799941392)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.8720, device='cuda:0')  (tensor(7.4798, device='cuda:0'))\n",
            "     | > current_lr: 4.749999999999999e-06 \n",
            "     | > step_time: 0.2977  (0.39538028591968977)\n",
            "     | > loader_time: 0.0042  (0.004164398693647542)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7766094207763672 \u001b[0m(-0.05865049362182617)\n",
            "     | > avg_loss:\u001b[92m 1.3542046546936035 \u001b[0m(-0.05820512771606445)\n",
            "     | > avg_log_mle:\u001b[92m 0.19062799215316772 \u001b[0m(-0.01799309253692627)\n",
            "     | > avg_loss_dur:\u001b[92m 1.163576602935791 \u001b[0m(-0.040212154388427734)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7766094207763672 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.3542046546936035 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.19062799215316772 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.163576602935791 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1620.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 20/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:13:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:13:06 -- STEP: 5/81 -- GLOBAL_STEP: 1625\u001b[0m\n",
            "     | > loss: 1.329538345336914  (1.3662135362625123)\n",
            "     | > log_mle: 0.3450655937194824  (0.30032050609588623)\n",
            "     | > loss_dur: 0.9844728112220764  (1.065893018245697)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.2670, device='cuda:0')  (tensor(8.8570, device='cuda:0'))\n",
            "     | > current_lr: 4.9999999999999996e-06 \n",
            "     | > step_time: 0.4991  (0.47862744331359863)\n",
            "     | > loader_time: 0.0113  (0.004633569717407226)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:13:17 -- STEP: 30/81 -- GLOBAL_STEP: 1650\u001b[0m\n",
            "     | > loss: 1.5810818672180176  (1.3678002576033275)\n",
            "     | > log_mle: 0.2799815535545349  (0.27298650244871775)\n",
            "     | > loss_dur: 1.3011003732681274  (1.0948137521743775)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(4.3953, device='cuda:0')  (tensor(8.1748, device='cuda:0'))\n",
            "     | > current_lr: 4.9999999999999996e-06 \n",
            "     | > step_time: 0.3031  (0.44254602591196696)\n",
            "     | > loader_time: 0.003  (0.003991079330444336)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:13:26 -- STEP: 55/81 -- GLOBAL_STEP: 1675\u001b[0m\n",
            "     | > loss: 1.2263000011444092  (1.3778171766888012)\n",
            "     | > log_mle: 0.3697054982185364  (0.26593949740583267)\n",
            "     | > loss_dur: 0.856594443321228  (1.1118776776573873)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(2.4494, device='cuda:0')  (tensor(7.7344, device='cuda:0'))\n",
            "     | > current_lr: 4.9999999999999996e-06 \n",
            "     | > step_time: 0.4713  (0.3920000206340443)\n",
            "     | > loader_time: 0.0122  (0.004609532789750533)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:13:36 -- STEP: 80/81 -- GLOBAL_STEP: 1700\u001b[0m\n",
            "     | > loss: 1.4609599113464355  (1.359904681891203)\n",
            "     | > log_mle: 0.03499668836593628  (0.2522206321358682)\n",
            "     | > loss_dur: 1.4259631633758545  (1.107684051245451)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(15.1953, device='cuda:0')  (tensor(8.9388, device='cuda:0'))\n",
            "     | > current_lr: 4.9999999999999996e-06 \n",
            "     | > step_time: 0.2301  (0.3966484993696214)\n",
            "     | > loader_time: 0.0025  (0.004842996597290039)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5040037631988525 \u001b[0m(-0.27260565757751465)\n",
            "     | > avg_loss:\u001b[92m 1.2990514039993286 \u001b[0m(-0.0551532506942749)\n",
            "     | > avg_log_mle:\u001b[92m 0.17642629146575928 \u001b[0m(-0.014201700687408447)\n",
            "     | > avg_loss_dur:\u001b[92m 1.1226251125335693 \u001b[0m(-0.04095149040222168)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5040037631988525 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.2990514039993286 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.17642629146575928 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.1226251125335693 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1701.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 21/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:13:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:14:01 -- STEP: 24/81 -- GLOBAL_STEP: 1725\u001b[0m\n",
            "     | > loss: 1.476983904838562  (1.292219653725624)\n",
            "     | > log_mle: 0.2332545518875122  (0.2713900183637937)\n",
            "     | > loss_dur: 1.2437293529510498  (1.0208296452959378)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(3.7286, device='cuda:0')  (tensor(7.7522, device='cuda:0'))\n",
            "     | > current_lr: 5.25e-06 \n",
            "     | > step_time: 0.2924  (0.34918936093648273)\n",
            "     | > loader_time: 0.005  (0.00420612096786499)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:14:09 -- STEP: 49/81 -- GLOBAL_STEP: 1750\u001b[0m\n",
            "     | > loss: 1.0514415502548218  (1.3198510651685753)\n",
            "     | > log_mle: 0.238025963306427  (0.2593158313206264)\n",
            "     | > loss_dur: 0.8134155869483948  (1.0605352362807916)\n",
            "     | > amp_scaler: 16384.0  (16384.0)\n",
            "     | > grad_norm: tensor(5.6023, device='cuda:0')  (tensor(8.1680, device='cuda:0'))\n",
            "     | > current_lr: 5.25e-06 \n",
            "     | > step_time: 0.4085  (0.3455392000626544)\n",
            "     | > loader_time: 0.0124  (0.004515535977421974)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:14:20 -- STEP: 74/81 -- GLOBAL_STEP: 1775\u001b[0m\n",
            "     | > loss: 1.2035528421401978  (1.3165089359154571)\n",
            "     | > log_mle: 0.2041805386543274  (0.2475753450715864)\n",
            "     | > loss_dur: 0.9993723034858704  (1.0689335900384025)\n",
            "     | > amp_scaler: 8192.0  (15719.783783783783)\n",
            "     | > grad_norm: tensor(12.7400, device='cuda:0')  (tensor(9.6419, device='cuda:0'))\n",
            "     | > current_lr: 5.25e-06 \n",
            "     | > step_time: 0.2399  (0.36228014005197057)\n",
            "     | > loader_time: 0.0023  (0.005253891687135436)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.506756067276001 \u001b[0m(+0.0027523040771484375)\n",
            "     | > avg_loss:\u001b[92m 1.2634328603744507 \u001b[0m(-0.03561854362487793)\n",
            "     | > avg_log_mle:\u001b[92m 0.16154193878173828 \u001b[0m(-0.014884352684020996)\n",
            "     | > avg_loss_dur:\u001b[92m 1.1018909215927124 \u001b[0m(-0.020734190940856934)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.506756067276001 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.2634328603744507 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.16154193878173828 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.1018909215927124 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1782.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 22/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:14:35) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:14:46 -- STEP: 18/81 -- GLOBAL_STEP: 1800\u001b[0m\n",
            "     | > loss: 1.0510499477386475  (1.2359265552626715)\n",
            "     | > log_mle: 0.38178038597106934  (0.2756960988044739)\n",
            "     | > loss_dur: 0.6692695617675781  (0.9602304564581977)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(2.1943, device='cuda:0')  (tensor(7.3279, device='cuda:0'))\n",
            "     | > current_lr: 5.5e-06 \n",
            "     | > step_time: 0.29  (0.29927880234188503)\n",
            "     | > loader_time: 0.0029  (0.003304812643263075)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:14:55 -- STEP: 43/81 -- GLOBAL_STEP: 1825\u001b[0m\n",
            "     | > loss: 1.1204750537872314  (1.291295938713606)\n",
            "     | > log_mle: 0.38297492265701294  (0.2468692895977996)\n",
            "     | > loss_dur: 0.7375000715255737  (1.044426650501961)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(2.3371, device='cuda:0')  (tensor(8.6980, device='cuda:0'))\n",
            "     | > current_lr: 5.5e-06 \n",
            "     | > step_time: 0.4036  (0.3323005188343137)\n",
            "     | > loader_time: 0.0028  (0.004846084949582122)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:15:05 -- STEP: 68/81 -- GLOBAL_STEP: 1850\u001b[0m\n",
            "     | > loss: 1.093151330947876  (1.2760263593757855)\n",
            "     | > log_mle: 0.24788892269134521  (0.24049550470183878)\n",
            "     | > loss_dur: 0.8452624082565308  (1.0355308546739466)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(6.8121, device='cuda:0')  (tensor(9.8364, device='cuda:0'))\n",
            "     | > current_lr: 5.5e-06 \n",
            "     | > step_time: 0.3026  (0.36407276812721706)\n",
            "     | > loader_time: 0.0032  (0.004422307014465332)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5996391773223877 \u001b[0m(+0.09288311004638672)\n",
            "     | > avg_loss:\u001b[92m 1.219813346862793 \u001b[0m(-0.043619513511657715)\n",
            "     | > avg_log_mle:\u001b[92m 0.14855557680130005 \u001b[0m(-0.012986361980438232)\n",
            "     | > avg_loss_dur:\u001b[92m 1.0712577104568481 \u001b[0m(-0.030633211135864258)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5996391773223877 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.219813346862793 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.14855557680130005 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.0712577104568481 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1863.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 23/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:15:29) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:15:34 -- STEP: 12/81 -- GLOBAL_STEP: 1875\u001b[0m\n",
            "     | > loss: 1.2091491222381592  (1.1864142169555028)\n",
            "     | > log_mle: 0.059562861919403076  (0.24620725214481357)\n",
            "     | > loss_dur: 1.1495863199234009  (0.9402069995800654)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(30.1275, device='cuda:0')  (tensor(9.3266, device='cuda:0'))\n",
            "     | > current_lr: 5.75e-06 \n",
            "     | > step_time: 0.2985  (0.2901315093040467)\n",
            "     | > loader_time: 0.0027  (0.0037962992986043296)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:15:46 -- STEP: 37/81 -- GLOBAL_STEP: 1900\u001b[0m\n",
            "     | > loss: 1.4594823122024536  (1.2442541267420795)\n",
            "     | > log_mle: 0.12732017040252686  (0.22946268964458155)\n",
            "     | > loss_dur: 1.3321621417999268  (1.014791461261543)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(11.4697, device='cuda:0')  (tensor(8.1638, device='cuda:0'))\n",
            "     | > current_lr: 5.75e-06 \n",
            "     | > step_time: 0.4867  (0.4098621767920417)\n",
            "     | > loader_time: 0.0061  (0.00574441858240076)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:15:58 -- STEP: 62/81 -- GLOBAL_STEP: 1925\u001b[0m\n",
            "     | > loss: 1.1755266189575195  (1.2474341488653613)\n",
            "     | > log_mle: 0.301827609539032  (0.22786818108251017)\n",
            "     | > loss_dur: 0.8736990690231323  (1.019565981241964)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(2.4069, device='cuda:0')  (tensor(9.9433, device='cuda:0'))\n",
            "     | > current_lr: 5.75e-06 \n",
            "     | > step_time: 0.2894  (0.43048715591430664)\n",
            "     | > loader_time: 0.0032  (0.006522628568833874)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7608616352081299 \u001b[0m(+0.1612224578857422)\n",
            "     | > avg_loss:\u001b[92m 1.1626027822494507 \u001b[0m(-0.057210564613342285)\n",
            "     | > avg_log_mle:\u001b[92m 0.1361790895462036 \u001b[0m(-0.012376487255096436)\n",
            "     | > avg_loss_dur:\u001b[92m 1.026423692703247 \u001b[0m(-0.044834017753601074)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7608616352081299 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.1626027822494507 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.1361790895462036 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 1.026423692703247 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_1944.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 24/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:16:22) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:16:27 -- STEP: 6/81 -- GLOBAL_STEP: 1950\u001b[0m\n",
            "     | > loss: 1.3099017143249512  (1.2054430643717449)\n",
            "     | > log_mle: 0.21796447038650513  (0.24546842773755392)\n",
            "     | > loss_dur: 1.0919371843338013  (0.959974616765976)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(8.5908, device='cuda:0')  (tensor(10.2314, device='cuda:0'))\n",
            "     | > current_lr: 6e-06 \n",
            "     | > step_time: 0.498  (0.4781968593597412)\n",
            "     | > loader_time: 0.0128  (0.008321881294250488)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:16:36 -- STEP: 31/81 -- GLOBAL_STEP: 1975\u001b[0m\n",
            "     | > loss: 1.0655628442764282  (1.1936728781269446)\n",
            "     | > log_mle: 0.28439861536026  (0.22587204940857428)\n",
            "     | > loss_dur: 0.7811642289161682  (0.9678008210274481)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(3.8362, device='cuda:0')  (tensor(9.5721, device='cuda:0'))\n",
            "     | > current_lr: 6e-06 \n",
            "     | > step_time: 0.2838  (0.3793304197249874)\n",
            "     | > loader_time: 0.0039  (0.005167238173946258)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:16:45 -- STEP: 56/81 -- GLOBAL_STEP: 2000\u001b[0m\n",
            "     | > loss: 1.2519147396087646  (1.2117634958454546)\n",
            "     | > log_mle: 0.09586799144744873  (0.21524837613105774)\n",
            "     | > loss_dur: 1.156046748161316  (0.9965151197143963)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(27.8413, device='cuda:0')  (tensor(11.8970, device='cuda:0'))\n",
            "     | > current_lr: 6e-06 \n",
            "     | > step_time: 0.469  (0.36457015786852154)\n",
            "     | > loader_time: 0.0028  (0.004836912666048325)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_2000.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5238449573516846 \u001b[0m(-0.2370166778564453)\n",
            "     | > avg_loss:\u001b[92m 1.1061952114105225 \u001b[0m(-0.05640757083892822)\n",
            "     | > avg_log_mle:\u001b[92m 0.12283581495285034 \u001b[0m(-0.013343274593353271)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9833594560623169 \u001b[0m(-0.043064236640930176)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5238449573516846 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.1061952114105225 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.12283581495285034 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.9833594560623169 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2025.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 25/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:17:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:17:18 -- STEP: 0/81 -- GLOBAL_STEP: 2025\u001b[0m\n",
            "     | > loss: 1.0913894176483154  (1.0913894176483154)\n",
            "     | > log_mle: 0.352470338344574  (0.352470338344574)\n",
            "     | > loss_dur: 0.7389190793037415  (0.7389190793037415)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(2.3537, device='cuda:0')  (tensor(2.3537, device='cuda:0'))\n",
            "     | > current_lr: 6.2499999999999995e-06 \n",
            "     | > step_time: 0.4996  (0.49956440925598145)\n",
            "     | > loader_time: 0.9459  (0.9458727836608887)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:17:27 -- STEP: 25/81 -- GLOBAL_STEP: 2050\u001b[0m\n",
            "     | > loss: 1.0729827880859375  (1.1493644881248475)\n",
            "     | > log_mle: 0.2020743489265442  (0.22499017000198365)\n",
            "     | > loss_dur: 0.8709084391593933  (0.9243743109703064)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(20.7579, device='cuda:0')  (tensor(11.3288, device='cuda:0'))\n",
            "     | > current_lr: 6.2499999999999995e-06 \n",
            "     | > step_time: 0.4565  (0.3331026077270508)\n",
            "     | > loader_time: 0.0032  (0.00452352523803711)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:17:44 -- STEP: 50/81 -- GLOBAL_STEP: 2075\u001b[0m\n",
            "     | > loss: 1.5029494762420654  (1.1751399266719813)\n",
            "     | > log_mle: 0.0869796872138977  (0.21132229447364806)\n",
            "     | > loss_dur: 1.4159698486328125  (0.963817628622055)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(34.0554, device='cuda:0')  (tensor(11.1776, device='cuda:0'))\n",
            "     | > current_lr: 6.2499999999999995e-06 \n",
            "     | > step_time: 0.6502  (0.5068815279006958)\n",
            "     | > loader_time: 0.0049  (0.0060516071319580075)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:17:55 -- STEP: 75/81 -- GLOBAL_STEP: 2100\u001b[0m\n",
            "     | > loss: 0.977537989616394  (1.1618168878555295)\n",
            "     | > log_mle: 0.1860729455947876  (0.20286977608998616)\n",
            "     | > loss_dur: 0.7914650440216064  (0.958947106997172)\n",
            "     | > amp_scaler: 4096.0  (7809.706666666667)\n",
            "     | > grad_norm: tensor(14.8522, device='cuda:0')  (tensor(13.9842, device='cuda:0'))\n",
            "     | > current_lr: 6.2499999999999995e-06 \n",
            "     | > step_time: 0.3945  (0.480123421351115)\n",
            "     | > loader_time: 0.0027  (0.0055888938903808595)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7850198745727539 \u001b[0m(+0.26117491722106934)\n",
            "     | > avg_loss:\u001b[92m 1.0812783241271973 \u001b[0m(-0.024916887283325195)\n",
            "     | > avg_log_mle:\u001b[92m 0.11754906177520752 \u001b[0m(-0.005286753177642822)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9637293219566345 \u001b[0m(-0.019630134105682373)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7850198745727539 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.0812783241271973 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.11754906177520752 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.9637293219566345 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2106.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 26/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:18:12) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:18:22 -- STEP: 19/81 -- GLOBAL_STEP: 2125\u001b[0m\n",
            "     | > loss: 0.9512559771537781  (1.0933801061228703)\n",
            "     | > log_mle: 0.20917773246765137  (0.22962811746095357)\n",
            "     | > loss_dur: 0.7420782446861267  (0.8637519949360898)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(6.2075, device='cuda:0')  (tensor(7.2691, device='cuda:0'))\n",
            "     | > current_lr: 6.5e-06 \n",
            "     | > step_time: 0.2896  (0.40401264240867213)\n",
            "     | > loader_time: 0.0065  (0.006101746308176141)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:18:30 -- STEP: 44/81 -- GLOBAL_STEP: 2150\u001b[0m\n",
            "     | > loss: 1.2147183418273926  (1.1443582759662105)\n",
            "     | > log_mle: 0.209178626537323  (0.2022250321778384)\n",
            "     | > loss_dur: 1.0055397748947144  (0.9421332464976744)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(8.8571, device='cuda:0')  (tensor(9.9633, device='cuda:0'))\n",
            "     | > current_lr: 6.5e-06 \n",
            "     | > step_time: 0.2898  (0.3435219472104852)\n",
            "     | > loader_time: 0.0037  (0.004558346488259055)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:18:41 -- STEP: 69/81 -- GLOBAL_STEP: 2175\u001b[0m\n",
            "     | > loss: 1.286906123161316  (1.1317962995473887)\n",
            "     | > log_mle: -0.012067914009094238  (0.19303796861482703)\n",
            "     | > loss_dur: 1.2989740371704102  (0.9387583343879037)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(179.9934, device='cuda:0')  (tensor(13.7136, device='cuda:0'))\n",
            "     | > current_lr: 6.5e-06 \n",
            "     | > step_time: 0.4752  (0.38666405539581733)\n",
            "     | > loader_time: 0.0035  (0.0045790361321490745)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6084082126617432 \u001b[0m(-0.17661166191101074)\n",
            "     | > avg_loss:\u001b[92m 1.0478702783584595 \u001b[0m(-0.03340804576873779)\n",
            "     | > avg_log_mle:\u001b[92m 0.10337644815444946 \u001b[0m(-0.014172613620758057)\n",
            "     | > avg_loss_dur:\u001b[92m 0.94449383020401 \u001b[0m(-0.01923549175262451)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.6084082126617432 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.0478702783584595 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.10337644815444946 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.94449383020401 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2187.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 27/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:19:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:19:07 -- STEP: 13/81 -- GLOBAL_STEP: 2200\u001b[0m\n",
            "     | > loss: 0.9643765091896057  (1.0470148691764245)\n",
            "     | > log_mle: 0.23368459939956665  (0.2065516160084651)\n",
            "     | > loss_dur: 0.7306919097900391  (0.8404632531679593)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(7.6229, device='cuda:0')  (tensor(13.2469, device='cuda:0'))\n",
            "     | > current_lr: 6.75e-06 \n",
            "     | > step_time: 0.2959  (0.30014426891620344)\n",
            "     | > loader_time: 0.0037  (0.003660752223088191)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:19:17 -- STEP: 38/81 -- GLOBAL_STEP: 2225\u001b[0m\n",
            "     | > loss: 1.2290878295898438  (1.1155527359560917)\n",
            "     | > log_mle: 0.20570284128189087  (0.18811836525013573)\n",
            "     | > loss_dur: 1.0233850479125977  (0.9274343707059559)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(13.5430, device='cuda:0')  (tensor(12.8942, device='cuda:0'))\n",
            "     | > current_lr: 6.75e-06 \n",
            "     | > step_time: 0.4261  (0.3368907100275943)\n",
            "     | > loader_time: 0.0051  (0.004465416858070777)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:19:27 -- STEP: 63/81 -- GLOBAL_STEP: 2250\u001b[0m\n",
            "     | > loss: 0.9547756314277649  (1.1080635417075382)\n",
            "     | > log_mle: 0.06774753332138062  (0.1839494232147459)\n",
            "     | > loss_dur: 0.8870280981063843  (0.924114119438898)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(44.1989, device='cuda:0')  (tensor(14.0674, device='cuda:0'))\n",
            "     | > current_lr: 6.75e-06 \n",
            "     | > step_time: 0.282  (0.3622521105266753)\n",
            "     | > loader_time: 0.0043  (0.005125969175308469)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5049207210540771 \u001b[0m(-0.10348749160766602)\n",
            "     | > avg_loss:\u001b[92m 1.0185773372650146 \u001b[0m(-0.029292941093444824)\n",
            "     | > avg_log_mle:\u001b[92m 0.09220004081726074 \u001b[0m(-0.01117640733718872)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9263773560523987 \u001b[0m(-0.018116474151611328)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5049207210540771 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 1.0185773372650146 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.09220004081726074 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.9263773560523987 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2268.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 28/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:19:52) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:20:02 -- STEP: 7/81 -- GLOBAL_STEP: 2275\u001b[0m\n",
            "     | > loss: 1.0100384950637817  (1.0768533519336156)\n",
            "     | > log_mle: 0.25252294540405273  (0.21087064061846053)\n",
            "     | > loss_dur: 0.757515549659729  (0.8659827028002057)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(3.0190, device='cuda:0')  (tensor(10.7234, device='cuda:0'))\n",
            "     | > current_lr: 7e-06 \n",
            "     | > step_time: 0.5551  (0.9144744532448905)\n",
            "     | > loader_time: 0.0042  (0.008049113409859794)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:20:13 -- STEP: 32/81 -- GLOBAL_STEP: 2300\u001b[0m\n",
            "     | > loss: 1.0898998975753784  (1.0739759299904108)\n",
            "     | > log_mle: 0.03751397132873535  (0.18135121278464794)\n",
            "     | > loss_dur: 1.052385926246643  (0.892624719068408)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(12.8073, device='cuda:0')  (tensor(12.4160, device='cuda:0'))\n",
            "     | > current_lr: 7e-06 \n",
            "     | > step_time: 0.2796  (0.5208777040243148)\n",
            "     | > loader_time: 0.0024  (0.004429660737514494)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:20:21 -- STEP: 57/81 -- GLOBAL_STEP: 2325\u001b[0m\n",
            "     | > loss: 0.9487817287445068  (1.0803958062540024)\n",
            "     | > log_mle: -0.11005985736846924  (0.16948920070079335)\n",
            "     | > loss_dur: 1.058841586112976  (0.9109066097359908)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(37.0425, device='cuda:0')  (tensor(12.7074, device='cuda:0'))\n",
            "     | > current_lr: 7e-06 \n",
            "     | > step_time: 0.4088  (0.4237340835102817)\n",
            "     | > loader_time: 0.0035  (0.003956656706960577)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8334228992462158 \u001b[0m(+0.32850217819213867)\n",
            "     | > avg_loss:\u001b[92m 0.9895188808441162 \u001b[0m(-0.029058456420898438)\n",
            "     | > avg_log_mle:\u001b[92m 0.08146268129348755 \u001b[0m(-0.010737359523773193)\n",
            "     | > avg_loss_dur:\u001b[92m 0.9080561995506287 \u001b[0m(-0.01832115650177002)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8334228992462158 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.9895188808441162 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.08146268129348755 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.9080561995506287 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2349.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 29/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:20:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:20:46 -- STEP: 1/81 -- GLOBAL_STEP: 2350\u001b[0m\n",
            "     | > loss: 0.9721440672874451  (0.9721440672874451)\n",
            "     | > log_mle: 0.15226209163665771  (0.15226209163665771)\n",
            "     | > loss_dur: 0.8198819756507874  (0.8198819756507874)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(25.3908, device='cuda:0')  (tensor(25.3908, device='cuda:0'))\n",
            "     | > current_lr: 7.25e-06 \n",
            "     | > step_time: 0.4437  (0.44373250007629395)\n",
            "     | > loader_time: 0.004  (0.004013776779174805)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:20:56 -- STEP: 26/81 -- GLOBAL_STEP: 2375\u001b[0m\n",
            "     | > loss: 0.955214262008667  (1.022647665097163)\n",
            "     | > log_mle: 0.02657783031463623  (0.17829107550474313)\n",
            "     | > loss_dur: 0.9286364316940308  (0.8443565918849065)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(33.8086, device='cuda:0')  (tensor(11.1263, device='cuda:0'))\n",
            "     | > current_lr: 7.25e-06 \n",
            "     | > step_time: 0.2978  (0.4082399606704712)\n",
            "     | > loader_time: 0.0032  (0.004785528549781213)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:21:04 -- STEP: 51/81 -- GLOBAL_STEP: 2400\u001b[0m\n",
            "     | > loss: 0.9696877598762512  (1.0536457346934902)\n",
            "     | > log_mle: 0.09696108102798462  (0.1695685608714234)\n",
            "     | > loss_dur: 0.8727266788482666  (0.8840771726533478)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(12.7067, device='cuda:0')  (tensor(10.9337, device='cuda:0'))\n",
            "     | > current_lr: 7.25e-06 \n",
            "     | > step_time: 0.2929  (0.35230324782577216)\n",
            "     | > loader_time: 0.005  (0.004433973162781959)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:21:15 -- STEP: 76/81 -- GLOBAL_STEP: 2425\u001b[0m\n",
            "     | > loss: 1.0030635595321655  (1.0415941782687839)\n",
            "     | > log_mle: 0.035241901874542236  (0.16081271359795016)\n",
            "     | > loss_dur: 0.9678216576576233  (0.8807814646708342)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(52.4700, device='cuda:0')  (tensor(17.2965, device='cuda:0'))\n",
            "     | > current_lr: 7.25e-06 \n",
            "     | > step_time: 0.3791  (0.37848728267770065)\n",
            "     | > loader_time: 0.005  (0.004984162355724134)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.571211576461792 \u001b[0m(-0.26221132278442383)\n",
            "     | > avg_loss:\u001b[92m 0.9811959862709045 \u001b[0m(-0.00832289457321167)\n",
            "     | > avg_log_mle:\u001b[92m 0.06970536708831787 \u001b[0m(-0.011757314205169678)\n",
            "     | > avg_loss_dur:\u001b[91m 0.9114906191825867 \u001b[0m(+0.003434419631958008)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.571211576461792 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.9811959862709045 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.06970536708831787 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.9114906191825867 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2430.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 30/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:21:28) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:21:39 -- STEP: 20/81 -- GLOBAL_STEP: 2450\u001b[0m\n",
            "     | > loss: 1.2298128604888916  (0.9925227463245392)\n",
            "     | > log_mle: 0.18624842166900635  (0.1911007285118103)\n",
            "     | > loss_dur: 1.0435644388198853  (0.8014220133423805)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(3.9963, device='cuda:0')  (tensor(10.7734, device='cuda:0'))\n",
            "     | > current_lr: 7.499999999999999e-06 \n",
            "     | > step_time: 0.3065  (0.415820574760437)\n",
            "     | > loader_time: 0.0029  (0.006076252460479737)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:21:46 -- STEP: 45/81 -- GLOBAL_STEP: 2475\u001b[0m\n",
            "     | > loss: 1.01615571975708  (1.0279296358426413)\n",
            "     | > log_mle: 0.27098548412323  (0.16597430176205105)\n",
            "     | > loss_dur: 0.7451701760292053  (0.8619553334183163)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(9.9832, device='cuda:0')  (tensor(14.5143, device='cuda:0'))\n",
            "     | > current_lr: 7.499999999999999e-06 \n",
            "     | > step_time: 0.2868  (0.3484246042039659)\n",
            "     | > loader_time: 0.004  (0.004608413908216688)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:21:58 -- STEP: 70/81 -- GLOBAL_STEP: 2500\u001b[0m\n",
            "     | > loss: 0.986086368560791  (1.0144782287733896)\n",
            "     | > log_mle: 0.281643271446228  (0.15747232096535818)\n",
            "     | > loss_dur: 0.704443097114563  (0.857005906530789)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.0734, device='cuda:0')  (tensor(21.3611, device='cuda:0'))\n",
            "     | > current_lr: 7.499999999999999e-06 \n",
            "     | > step_time: 0.5166  (0.381619381904602)\n",
            "     | > loader_time: 0.003  (0.004548617771693638)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5332896709442139 \u001b[0m(-0.037921905517578125)\n",
            "     | > avg_loss:\u001b[92m 0.9567005634307861 \u001b[0m(-0.024495422840118408)\n",
            "     | > avg_log_mle:\u001b[92m 0.05884355306625366 \u001b[0m(-0.010861814022064209)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8978570103645325 \u001b[0m(-0.0136336088180542)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5332896709442139 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.9567005634307861 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.05884355306625366 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8978570103645325 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2511.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 31/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:22:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:22:32 -- STEP: 14/81 -- GLOBAL_STEP: 2525\u001b[0m\n",
            "     | > loss: 1.1553707122802734  (0.9527256233351571)\n",
            "     | > log_mle: 0.3134598135948181  (0.17780399748257228)\n",
            "     | > loss_dur: 0.8419108390808105  (0.7749216301100594)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.5888, device='cuda:0')  (tensor(8.5054, device='cuda:0'))\n",
            "     | > current_lr: 7.75e-06 \n",
            "     | > step_time: 0.4496  (0.34204655034201487)\n",
            "     | > loader_time: 0.0032  (0.004178506987435477)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:22:44 -- STEP: 39/81 -- GLOBAL_STEP: 2550\u001b[0m\n",
            "     | > loss: 1.0333118438720703  (0.9970933642142858)\n",
            "     | > log_mle: 0.06380760669708252  (0.14708346128463745)\n",
            "     | > loss_dur: 0.9695042967796326  (0.8500099090429455)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(17.8559, device='cuda:0')  (tensor(14.4343, device='cuda:0'))\n",
            "     | > current_lr: 7.75e-06 \n",
            "     | > step_time: 0.3004  (0.4037325565631573)\n",
            "     | > loader_time: 0.0042  (0.004317301970261794)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:22:51 -- STEP: 64/81 -- GLOBAL_STEP: 2575\u001b[0m\n",
            "     | > loss: 0.951587438583374  (0.9924646820873023)\n",
            "     | > log_mle: 0.14813226461410522  (0.14580161403864622)\n",
            "     | > loss_dur: 0.8034551739692688  (0.8466630717739464)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(25.6546, device='cuda:0')  (tensor(16.6848, device='cuda:0'))\n",
            "     | > current_lr: 7.75e-06 \n",
            "     | > step_time: 0.2881  (0.36248939484357834)\n",
            "     | > loader_time: 0.003  (0.00406290590763092)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8731629848480225 \u001b[0m(+0.3398733139038086)\n",
            "     | > avg_loss:\u001b[92m 0.9370014667510986 \u001b[0m(-0.0196990966796875)\n",
            "     | > avg_log_mle:\u001b[92m 0.054465413093566895 \u001b[0m(-0.004378139972686768)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8825360536575317 \u001b[0m(-0.015320956707000732)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8731629848480225 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.9370014667510986 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.054465413093566895 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8825360536575317 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2592.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 32/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:23:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:23:23 -- STEP: 8/81 -- GLOBAL_STEP: 2600\u001b[0m\n",
            "     | > loss: 0.8629661202430725  (0.9443006664514542)\n",
            "     | > log_mle: 0.1997537612915039  (0.17788197100162506)\n",
            "     | > loss_dur: 0.6632123589515686  (0.7664186879992485)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(7.5606, device='cuda:0')  (tensor(18.5713, device='cuda:0'))\n",
            "     | > current_lr: 8e-06 \n",
            "     | > step_time: 0.5026  (0.47215911746025085)\n",
            "     | > loader_time: 0.0036  (0.007833361625671387)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:23:31 -- STEP: 33/81 -- GLOBAL_STEP: 2625\u001b[0m\n",
            "     | > loss: 0.9826249480247498  (0.9659460078586232)\n",
            "     | > log_mle: 0.13361763954162598  (0.1435535495931452)\n",
            "     | > loss_dur: 0.8490073084831238  (0.8223924600716793)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(18.7214, device='cuda:0')  (tensor(15.9171, device='cuda:0'))\n",
            "     | > current_lr: 8e-06 \n",
            "     | > step_time: 0.2916  (0.3733411196506385)\n",
            "     | > loader_time: 0.0059  (0.00506473310065992)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:23:41 -- STEP: 58/81 -- GLOBAL_STEP: 2650\u001b[0m\n",
            "     | > loss: 1.1451345682144165  (0.978360762883877)\n",
            "     | > log_mle: 0.1797354817390442  (0.13466492398031818)\n",
            "     | > loss_dur: 0.9653990864753723  (0.8436958389035587)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(8.4580, device='cuda:0')  (tensor(20.0011, device='cuda:0'))\n",
            "     | > current_lr: 8e-06 \n",
            "     | > step_time: 0.51  (0.37168545969601335)\n",
            "     | > loader_time: 0.0032  (0.004639193929474928)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7817513942718506 \u001b[0m(-0.09141159057617188)\n",
            "     | > avg_loss:\u001b[92m 0.8981808423995972 \u001b[0m(-0.038820624351501465)\n",
            "     | > avg_log_mle:\u001b[92m 0.041689932346343994 \u001b[0m(-0.0127754807472229)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8564909100532532 \u001b[0m(-0.026045143604278564)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7817513942718506 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.8981808423995972 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.041689932346343994 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8564909100532532 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2673.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 33/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:24:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:24:21 -- STEP: 2/81 -- GLOBAL_STEP: 2675\u001b[0m\n",
            "     | > loss: 1.0245084762573242  (0.9632989168167114)\n",
            "     | > log_mle: 0.28669601678848267  (0.20070195198059082)\n",
            "     | > loss_dur: 0.7378124594688416  (0.7625969648361206)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.7041, device='cuda:0')  (tensor(20.0789, device='cuda:0'))\n",
            "     | > current_lr: 8.25e-06 \n",
            "     | > step_time: 0.8213  (0.7056722640991211)\n",
            "     | > loader_time: 0.0026  (0.0028548240661621094)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:24:36 -- STEP: 27/81 -- GLOBAL_STEP: 2700\u001b[0m\n",
            "     | > loss: 0.9622895121574402  (0.9183513897436636)\n",
            "     | > log_mle: -0.0027832388877868652  (0.13720959204214592)\n",
            "     | > loss_dur: 0.965072751045227  (0.7811417910787795)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(28.0044, device='cuda:0')  (tensor(16.3372, device='cuda:0'))\n",
            "     | > current_lr: 8.25e-06 \n",
            "     | > step_time: 0.2949  (0.5937781245620163)\n",
            "     | > loader_time: 0.0031  (0.005907712159333406)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:24:43 -- STEP: 52/81 -- GLOBAL_STEP: 2725\u001b[0m\n",
            "     | > loss: 0.8592791557312012  (0.9466413867015105)\n",
            "     | > log_mle: 0.1818719506263733  (0.13446546861758601)\n",
            "     | > loss_dur: 0.6774072051048279  (0.8121759157914382)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.7353, device='cuda:0')  (tensor(14.9166, device='cuda:0'))\n",
            "     | > current_lr: 8.25e-06 \n",
            "     | > step_time: 0.2851  (0.4501498800057631)\n",
            "     | > loader_time: 0.0027  (0.005101937514085036)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:24:54 -- STEP: 77/81 -- GLOBAL_STEP: 2750\u001b[0m\n",
            "     | > loss: 0.7610984444618225  (0.9346855700790108)\n",
            "     | > log_mle: 0.24249416589736938  (0.12488112047121126)\n",
            "     | > loss_dur: 0.5186042785644531  (0.8098044488337133)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.3257, device='cuda:0')  (tensor(17.1059, device='cuda:0'))\n",
            "     | > current_lr: 8.25e-06 \n",
            "     | > step_time: 0.4037  (0.4414938208344695)\n",
            "     | > loader_time: 0.0027  (0.005174547046810002)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1782317161560059 \u001b[0m(+0.3964803218841553)\n",
            "     | > avg_loss:\u001b[91m 0.9075749516487122 \u001b[0m(+0.00939410924911499)\n",
            "     | > avg_log_mle:\u001b[92m 0.03384077548980713 \u001b[0m(-0.007849156856536865)\n",
            "     | > avg_loss_dur:\u001b[91m 0.873734176158905 \u001b[0m(+0.017243266105651855)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.1782317161560059 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.9075749516487122 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.03384077548980713 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.873734176158905 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 34/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:25:07) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:25:18 -- STEP: 21/81 -- GLOBAL_STEP: 2775\u001b[0m\n",
            "     | > loss: 0.8964493870735168  (0.8997731634548732)\n",
            "     | > log_mle: 0.12327289581298828  (0.1533922240847633)\n",
            "     | > loss_dur: 0.7731764912605286  (0.7463809351126353)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(11.2122, device='cuda:0')  (tensor(10.9089, device='cuda:0'))\n",
            "     | > current_lr: 8.5e-06 \n",
            "     | > step_time: 0.2883  (0.4353634516398112)\n",
            "     | > loader_time: 0.0046  (0.007631892249697731)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:25:26 -- STEP: 46/81 -- GLOBAL_STEP: 2800\u001b[0m\n",
            "     | > loss: 1.1023809909820557  (0.9326898805473162)\n",
            "     | > log_mle: 0.2719784379005432  (0.13248179140298258)\n",
            "     | > loss_dur: 0.8304025530815125  (0.8002080833134444)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(6.1203, device='cuda:0')  (tensor(14.5257, device='cuda:0'))\n",
            "     | > current_lr: 8.5e-06 \n",
            "     | > step_time: 0.2873  (0.36073378376338794)\n",
            "     | > loader_time: 0.003  (0.005769610404968262)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:25:37 -- STEP: 71/81 -- GLOBAL_STEP: 2825\u001b[0m\n",
            "     | > loss: 0.7872567176818848  (0.9140907097870196)\n",
            "     | > log_mle: 0.05018877983093262  (0.11935845395209081)\n",
            "     | > loss_dur: 0.7370679378509521  (0.7947322528966716)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(38.3769, device='cuda:0')  (tensor(20.4630, device='cuda:0'))\n",
            "     | > current_lr: 8.5e-06 \n",
            "     | > step_time: 0.418  (0.3881471593615035)\n",
            "     | > loader_time: 0.0039  (0.006081483733486122)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5386843681335449 \u001b[0m(-0.6395473480224609)\n",
            "     | > avg_loss:\u001b[92m 0.8788264989852905 \u001b[0m(-0.02874845266342163)\n",
            "     | > avg_log_mle:\u001b[92m 0.01939678192138672 \u001b[0m(-0.01444399356842041)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8594297170639038 \u001b[0m(-0.01430445909500122)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5386843681335449 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.8788264989852905 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.01939678192138672 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8594297170639038 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2835.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 35/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:25:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:26:04 -- STEP: 15/81 -- GLOBAL_STEP: 2850\u001b[0m\n",
            "     | > loss: 0.8741413950920105  (0.8657325665156047)\n",
            "     | > log_mle: 0.1998809576034546  (0.14869268735249838)\n",
            "     | > loss_dur: 0.6742604374885559  (0.7170398811499278)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(7.1727, device='cuda:0')  (tensor(15.9915, device='cuda:0'))\n",
            "     | > current_lr: 8.750000000000001e-06 \n",
            "     | > step_time: 0.2962  (0.29589274724324544)\n",
            "     | > loader_time: 0.006  (0.004491106669108073)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:26:13 -- STEP: 40/81 -- GLOBAL_STEP: 2875\u001b[0m\n",
            "     | > loss: 1.1219499111175537  (0.9125128835439682)\n",
            "     | > log_mle: 0.2690141201019287  (0.11742217242717742)\n",
            "     | > loss_dur: 0.8529358506202698  (0.7950907133519649)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.5014, device='cuda:0')  (tensor(17.4960, device='cuda:0'))\n",
            "     | > current_lr: 8.750000000000001e-06 \n",
            "     | > step_time: 0.4453  (0.32709525823593133)\n",
            "     | > loader_time: 0.0051  (0.004456436634063721)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:26:24 -- STEP: 65/81 -- GLOBAL_STEP: 2900\u001b[0m\n",
            "     | > loss: 0.7231923937797546  (0.8968695961512052)\n",
            "     | > log_mle: 0.16078293323516846  (0.11236348427259005)\n",
            "     | > loss_dur: 0.5624094605445862  (0.784506111420118)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(10.0137, device='cuda:0')  (tensor(19.7282, device='cuda:0'))\n",
            "     | > current_lr: 8.750000000000001e-06 \n",
            "     | > step_time: 0.2967  (0.3575511675614576)\n",
            "     | > loader_time: 0.0026  (0.004239808596097504)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5681819915771484 \u001b[0m(+0.029497623443603516)\n",
            "     | > avg_loss:\u001b[92m 0.8703343272209167 \u001b[0m(-0.00849217176437378)\n",
            "     | > avg_log_mle:\u001b[91m 0.04778873920440674 \u001b[0m(+0.02839195728302002)\n",
            "     | > avg_loss_dur:\u001b[92m 0.82254558801651 \u001b[0m(-0.0368841290473938)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5681819915771484 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.8703343272209167 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.04778873920440674 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.82254558801651 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2916.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 36/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:26:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:26:55 -- STEP: 9/81 -- GLOBAL_STEP: 2925\u001b[0m\n",
            "     | > loss: 0.8435422778129578  (0.8764176898532443)\n",
            "     | > log_mle: 0.20891720056533813  (0.15379885832468668)\n",
            "     | > loss_dur: 0.6346250772476196  (0.7226188315285577)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(13.6041, device='cuda:0')  (tensor(31.6134, device='cuda:0'))\n",
            "     | > current_lr: 9e-06 \n",
            "     | > step_time: 0.4059  (0.33621811866760254)\n",
            "     | > loader_time: 0.0023  (0.004475090238783095)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:27:06 -- STEP: 34/81 -- GLOBAL_STEP: 2950\u001b[0m\n",
            "     | > loss: 0.7666133046150208  (0.881139883223702)\n",
            "     | > log_mle: 0.17176216840744019  (0.11430851501577041)\n",
            "     | > loss_dur: 0.5948511362075806  (0.7668313699610093)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.6364, device='cuda:0')  (tensor(25.4024, device='cuda:0'))\n",
            "     | > current_lr: 9e-06 \n",
            "     | > step_time: 0.311  (0.42102798293618593)\n",
            "     | > loader_time: 0.0065  (0.0056429820902207314)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:27:14 -- STEP: 59/81 -- GLOBAL_STEP: 2975\u001b[0m\n",
            "     | > loss: 0.7765739560127258  (0.887514161861549)\n",
            "     | > log_mle: 0.03248506784439087  (0.09972298549393475)\n",
            "     | > loss_dur: 0.744088888168335  (0.787791175357366)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(12.0237, device='cuda:0')  (tensor(24.0486, device='cuda:0'))\n",
            "     | > current_lr: 9e-06 \n",
            "     | > step_time: 0.295  (0.36599989664756644)\n",
            "     | > loader_time: 0.0051  (0.005148645174705378)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.769951343536377 \u001b[0m(+0.20176935195922852)\n",
            "     | > avg_loss:\u001b[92m 0.841346800327301 \u001b[0m(-0.028987526893615723)\n",
            "     | > avg_log_mle:\u001b[92m 0.006305336952209473 \u001b[0m(-0.041483402252197266)\n",
            "     | > avg_loss_dur:\u001b[91m 0.8350414633750916 \u001b[0m(+0.012495875358581543)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.769951343536377 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.841346800327301 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.006305336952209473 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8350414633750916 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_2997.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 37/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:27:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:27:47 -- STEP: 3/81 -- GLOBAL_STEP: 3000\u001b[0m\n",
            "     | > loss: 0.8117972016334534  (0.8475856979688009)\n",
            "     | > log_mle: 0.12843865156173706  (0.1576216220855713)\n",
            "     | > loss_dur: 0.6833585500717163  (0.6899640758832296)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(8.0111, device='cuda:0')  (tensor(17.3831, device='cuda:0'))\n",
            "     | > current_lr: 9.250000000000001e-06 \n",
            "     | > step_time: 0.5397  (0.5145435333251953)\n",
            "     | > loader_time: 0.0162  (0.01267552375793457)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_3000.pth\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:28:06 -- STEP: 28/81 -- GLOBAL_STEP: 3025\u001b[0m\n",
            "     | > loss: 0.8581928014755249  (0.8373487889766693)\n",
            "     | > log_mle: 0.1436251401901245  (0.1033933971609388)\n",
            "     | > loss_dur: 0.7145676612854004  (0.7339553939444678)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.1953, device='cuda:0')  (tensor(15.7633, device='cuda:0'))\n",
            "     | > current_lr: 9.250000000000001e-06 \n",
            "     | > step_time: 0.461  (0.4058741671698434)\n",
            "     | > loader_time: 0.0047  (0.005998875413622175)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:28:15 -- STEP: 53/81 -- GLOBAL_STEP: 3050\u001b[0m\n",
            "     | > loss: 0.7515424489974976  (0.8624831134418272)\n",
            "     | > log_mle: -0.07539570331573486  (0.09678769111633301)\n",
            "     | > loss_dur: 0.8269381523132324  (0.7656954234501101)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(76.2653, device='cuda:0')  (tensor(17.1240, device='cuda:0'))\n",
            "     | > current_lr: 9.250000000000001e-06 \n",
            "     | > step_time: 0.3059  (0.3852300463982348)\n",
            "     | > loader_time: 0.0039  (0.005453316670543743)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:28:23 -- STEP: 78/81 -- GLOBAL_STEP: 3075\u001b[0m\n",
            "     | > loss: 0.8493564128875732  (0.850323233848963)\n",
            "     | > log_mle: -0.22858142852783203  (0.08661973476409912)\n",
            "     | > loss_dur: 1.0779378414154053  (0.7637034990848639)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(76.1930, device='cuda:0')  (tensor(22.0784, device='cuda:0'))\n",
            "     | > current_lr: 9.250000000000001e-06 \n",
            "     | > step_time: 0.3534  (0.36237674493056077)\n",
            "     | > loader_time: 0.0024  (0.0048297429696107525)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7806544303894043 \u001b[0m(+0.010703086853027344)\n",
            "     | > avg_loss:\u001b[92m 0.8293224573135376 \u001b[0m(-0.012024343013763428)\n",
            "     | > avg_log_mle:\u001b[91m 0.017345309257507324 \u001b[0m(+0.011039972305297852)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8119771480560303 \u001b[0m(-0.02306431531906128)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7806544303894043 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.8293224573135376 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.017345309257507324 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8119771480560303 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3078.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 38/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:28:45) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:29:02 -- STEP: 22/81 -- GLOBAL_STEP: 3100\u001b[0m\n",
            "     | > loss: 0.9623181223869324  (0.8373823084614493)\n",
            "     | > log_mle: 0.013558447360992432  (0.11474134163423018)\n",
            "     | > loss_dur: 0.9487596750259399  (0.7226409668272191)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(21.6499, device='cuda:0')  (tensor(14.1158, device='cuda:0'))\n",
            "     | > current_lr: 9.499999999999999e-06 \n",
            "     | > step_time: 0.3013  (0.5529572313482111)\n",
            "     | > loader_time: 0.0076  (0.006001374938271262)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:29:12 -- STEP: 47/81 -- GLOBAL_STEP: 3125\u001b[0m\n",
            "     | > loss: 0.8036836981773376  (0.8534810834742607)\n",
            "     | > log_mle: -0.007116854190826416  (0.09700783389679929)\n",
            "     | > loss_dur: 0.8108005523681641  (0.7564732508456452)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(39.4724, device='cuda:0')  (tensor(20.5989, device='cuda:0'))\n",
            "     | > current_lr: 9.499999999999999e-06 \n",
            "     | > step_time: 0.5018  (0.4523929484347079)\n",
            "     | > loader_time: 0.0149  (0.005960474623010513)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:29:22 -- STEP: 72/81 -- GLOBAL_STEP: 3150\u001b[0m\n",
            "     | > loss: 0.766613781452179  (0.839167612294356)\n",
            "     | > log_mle: 0.059721291065216064  (0.08723635640409258)\n",
            "     | > loss_dur: 0.7068924903869629  (0.7519312558902633)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(12.9737, device='cuda:0')  (tensor(30.0394, device='cuda:0'))\n",
            "     | > current_lr: 9.499999999999999e-06 \n",
            "     | > step_time: 0.2858  (0.4324852791097428)\n",
            "     | > loader_time: 0.0039  (0.006326019763946533)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5093979835510254 \u001b[0m(-0.2712564468383789)\n",
            "     | > avg_loss:\u001b[92m 0.8154162168502808 \u001b[0m(-0.013906240463256836)\n",
            "     | > avg_log_mle:\u001b[92m -0.008175492286682129 \u001b[0m(-0.025520801544189453)\n",
            "     | > avg_loss_dur:\u001b[91m 0.8235917091369629 \u001b[0m(+0.011614561080932617)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5093979835510254 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.8154162168502808 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.008175492286682129 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8235917091369629 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3159.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 39/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:29:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:29:56 -- STEP: 16/81 -- GLOBAL_STEP: 3175\u001b[0m\n",
            "     | > loss: 0.8904421329498291  (0.8043881170451641)\n",
            "     | > log_mle: 0.0017554759979248047  (0.10897836089134216)\n",
            "     | > loss_dur: 0.8886866569519043  (0.695409756153822)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(14.2237, device='cuda:0')  (tensor(11.6929, device='cuda:0'))\n",
            "     | > current_lr: 9.75e-06 \n",
            "     | > step_time: 0.5003  (0.4420494884252548)\n",
            "     | > loader_time: 0.017  (0.005297899246215821)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:30:06 -- STEP: 41/81 -- GLOBAL_STEP: 3200\u001b[0m\n",
            "     | > loss: 0.7185767292976379  (0.8310915522459077)\n",
            "     | > log_mle: 0.020240485668182373  (0.08078719348442265)\n",
            "     | > loss_dur: 0.6983362436294556  (0.7503043616690287)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(26.7538, device='cuda:0')  (tensor(16.4232, device='cuda:0'))\n",
            "     | > current_lr: 9.75e-06 \n",
            "     | > step_time: 0.291  (0.3990174793615574)\n",
            "     | > loader_time: 0.0028  (0.0045648318965260575)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:30:14 -- STEP: 66/81 -- GLOBAL_STEP: 3225\u001b[0m\n",
            "     | > loss: 0.8691805005073547  (0.8218304207830718)\n",
            "     | > log_mle: 0.17291629314422607  (0.07918157992940962)\n",
            "     | > loss_dur: 0.6962642073631287  (0.7426488435629642)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.1685, device='cuda:0')  (tensor(20.2615, device='cuda:0'))\n",
            "     | > current_lr: 9.75e-06 \n",
            "     | > step_time: 0.4686  (0.37352781223528314)\n",
            "     | > loader_time: 0.0024  (0.00424332690961433)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7885572910308838 \u001b[0m(+0.2791593074798584)\n",
            "     | > avg_loss:\u001b[91m 0.8537024855613708 \u001b[0m(+0.03828626871109009)\n",
            "     | > avg_log_mle:\u001b[91m 0.06360739469528198 \u001b[0m(+0.07178288698196411)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7900950908660889 \u001b[0m(-0.03349661827087402)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7885572910308838 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.8537024855613708 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: 0.06360739469528198 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7900950908660889 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 40/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:30:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:30:37 -- STEP: 10/81 -- GLOBAL_STEP: 3250\u001b[0m\n",
            "     | > loss: 0.6475391983985901  (0.7835057318210602)\n",
            "     | > log_mle: -0.03152209520339966  (0.10105496644973755)\n",
            "     | > loss_dur: 0.6790612936019897  (0.6824507653713227)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(14.5799, device='cuda:0')  (tensor(16.2520, device='cuda:0'))\n",
            "     | > current_lr: 9.999999999999999e-06 \n",
            "     | > step_time: 0.4788  (0.4415275096893311)\n",
            "     | > loader_time: 0.004  (0.0050732135772705075)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:30:47 -- STEP: 35/81 -- GLOBAL_STEP: 3275\u001b[0m\n",
            "     | > loss: 0.75030517578125  (0.8016516276768275)\n",
            "     | > log_mle: 0.07435941696166992  (0.0748808707509722)\n",
            "     | > loss_dur: 0.6759457588195801  (0.7267707586288452)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(11.4391, device='cuda:0')  (tensor(15.3342, device='cuda:0'))\n",
            "     | > current_lr: 9.999999999999999e-06 \n",
            "     | > step_time: 0.2829  (0.4077972207750593)\n",
            "     | > loader_time: 0.0039  (0.005123935426984513)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:30:55 -- STEP: 60/81 -- GLOBAL_STEP: 3300\u001b[0m\n",
            "     | > loss: 0.757960319519043  (0.8127036104599635)\n",
            "     | > log_mle: 0.23848140239715576  (0.06657675206661226)\n",
            "     | > loss_dur: 0.5194789171218872  (0.7461268583933512)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(3.6289, device='cuda:0')  (tensor(22.0024, device='cuda:0'))\n",
            "     | > current_lr: 9.999999999999999e-06 \n",
            "     | > step_time: 0.4102  (0.36612361669540405)\n",
            "     | > loader_time: 0.0029  (0.005083521207173664)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5289938449859619 \u001b[0m(-0.2595634460449219)\n",
            "     | > avg_loss:\u001b[92m 0.7833438515663147 \u001b[0m(-0.07035863399505615)\n",
            "     | > avg_log_mle:\u001b[92m -0.02370584011077881 \u001b[0m(-0.08731323480606079)\n",
            "     | > avg_loss_dur:\u001b[91m 0.8070496916770935 \u001b[0m(+0.01695460081100464)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5289938449859619 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7833438515663147 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.02370584011077881 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8070496916770935 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3321.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 41/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:31:29) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:31:31 -- STEP: 4/81 -- GLOBAL_STEP: 3325\u001b[0m\n",
            "     | > loss: 0.8345062732696533  (0.7945887893438339)\n",
            "     | > log_mle: -0.010137677192687988  (0.08873297274112701)\n",
            "     | > loss_dur: 0.8446439504623413  (0.7058558166027069)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(53.0075, device='cuda:0')  (tensor(21.8710, device='cuda:0'))\n",
            "     | > current_lr: 1.025e-05 \n",
            "     | > step_time: 0.3045  (0.29494261741638184)\n",
            "     | > loader_time: 0.0038  (0.0042969584465026855)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:31:41 -- STEP: 29/81 -- GLOBAL_STEP: 3350\u001b[0m\n",
            "     | > loss: 1.2101911306381226  (0.7917402838838512)\n",
            "     | > log_mle: 0.035431504249572754  (0.06802423452508861)\n",
            "     | > loss_dur: 1.1747596263885498  (0.7237160503864288)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(52.8774, device='cuda:0')  (tensor(23.6967, device='cuda:0'))\n",
            "     | > current_lr: 1.025e-05 \n",
            "     | > step_time: 0.528  (0.3651256807919206)\n",
            "     | > loader_time: 0.0035  (0.004266788219583447)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:31:54 -- STEP: 54/81 -- GLOBAL_STEP: 3375\u001b[0m\n",
            "     | > loss: 1.1050775051116943  (0.8022021993442818)\n",
            "     | > log_mle: 0.02022683620452881  (0.06231203233754195)\n",
            "     | > loss_dur: 1.0848506689071655  (0.739890166454845)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(365.8061, device='cuda:0')  (tensor(34.0871, device='cuda:0'))\n",
            "     | > current_lr: 1.025e-05 \n",
            "     | > step_time: 0.4226  (0.43415783069751873)\n",
            "     | > loader_time: 0.0035  (0.005937399687590422)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:32:03 -- STEP: 79/81 -- GLOBAL_STEP: 3400\u001b[0m\n",
            "     | > loss: 0.7555627226829529  (0.7857469923888579)\n",
            "     | > log_mle: -0.007521986961364746  (0.05247053541714632)\n",
            "     | > loss_dur: 0.7630847096443176  (0.7332764562172225)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(22.4778, device='cuda:0')  (tensor(31.7470, device='cuda:0'))\n",
            "     | > current_lr: 1.025e-05 \n",
            "     | > step_time: 0.3371  (0.4071501840518998)\n",
            "     | > loader_time: 0.0028  (0.005694081511678575)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8031938076019287 \u001b[0m(+0.2741999626159668)\n",
            "     | > avg_loss:\u001b[91m 0.7911337018013 \u001b[0m(+0.0077898502349853516)\n",
            "     | > avg_log_mle:\u001b[92m -0.026759207248687744 \u001b[0m(-0.0030533671379089355)\n",
            "     | > avg_loss_dur:\u001b[91m 0.8178929090499878 \u001b[0m(+0.010843217372894287)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8031938076019287 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7911337018013 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.026759207248687744 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8178929090499878 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 42/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:32:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:32:27 -- STEP: 23/81 -- GLOBAL_STEP: 3425\u001b[0m\n",
            "     | > loss: 0.5133703947067261  (0.7587163033692733)\n",
            "     | > log_mle: -0.08565151691436768  (0.07214171990104344)\n",
            "     | > loss_dur: 0.5990219116210938  (0.6865745821724767)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(36.8358, device='cuda:0')  (tensor(14.3445, device='cuda:0'))\n",
            "     | > current_lr: 1.05e-05 \n",
            "     | > step_time: 0.4321  (0.38189069084499194)\n",
            "     | > loader_time: 0.0033  (0.0038955418959907865)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:32:37 -- STEP: 48/81 -- GLOBAL_STEP: 3450\u001b[0m\n",
            "     | > loss: 0.6316280364990234  (0.7837595803042253)\n",
            "     | > log_mle: -0.040656089782714844  (0.06059744829932851)\n",
            "     | > loss_dur: 0.6722841262817383  (0.7231621313840151)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(37.2830, device='cuda:0')  (tensor(19.4113, device='cuda:0'))\n",
            "     | > current_lr: 1.05e-05 \n",
            "     | > step_time: 0.29  (0.3868839095036189)\n",
            "     | > loader_time: 0.0064  (0.004325782259305318)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:32:45 -- STEP: 73/81 -- GLOBAL_STEP: 3475\u001b[0m\n",
            "     | > loss: 1.2271127700805664  (0.7782493707251875)\n",
            "     | > log_mle: -0.052596867084503174  (0.05111241830538398)\n",
            "     | > loss_dur: 1.2797096967697144  (0.7271369536445565)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(101.4420, device='cuda:0')  (tensor(28.7110, device='cuda:0'))\n",
            "     | > current_lr: 1.05e-05 \n",
            "     | > step_time: 0.3371  (0.36279372646384045)\n",
            "     | > loader_time: 0.0019  (0.004343205935334506)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.7297229766845703 \u001b[0m(+0.9265291690826416)\n",
            "     | > avg_loss:\u001b[92m 0.7817884683609009 \u001b[0m(-0.00934523344039917)\n",
            "     | > avg_log_mle:\u001b[91m -0.019707202911376953 \u001b[0m(+0.007052004337310791)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8014956712722778 \u001b[0m(-0.01639723777770996)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.7297229766845703 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7817884683609009 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.019707202911376953 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8014956712722778 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3483.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 43/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:33:10) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:33:21 -- STEP: 17/81 -- GLOBAL_STEP: 3500\u001b[0m\n",
            "     | > loss: 0.8128526210784912  (0.7608577118200415)\n",
            "     | > log_mle: 0.0809507966041565  (0.07538370525135714)\n",
            "     | > loss_dur: 0.7319018244743347  (0.6854740083217621)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(13.5931, device='cuda:0')  (tensor(14.8146, device='cuda:0'))\n",
            "     | > current_lr: 1.075e-05 \n",
            "     | > step_time: 0.3063  (0.37511560496161966)\n",
            "     | > loader_time: 0.0066  (0.005052482380586512)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:33:31 -- STEP: 42/81 -- GLOBAL_STEP: 3525\u001b[0m\n",
            "     | > loss: 0.8386117219924927  (0.7744132620947701)\n",
            "     | > log_mle: 0.09499567747116089  (0.04962528887249175)\n",
            "     | > loss_dur: 0.7436160445213318  (0.7247879732222785)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(5.2228, device='cuda:0')  (tensor(18.7025, device='cuda:0'))\n",
            "     | > current_lr: 1.075e-05 \n",
            "     | > step_time: 0.496  (0.37742908228011357)\n",
            "     | > loader_time: 0.0035  (0.004749576250712077)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:33:41 -- STEP: 67/81 -- GLOBAL_STEP: 3550\u001b[0m\n",
            "     | > loss: 0.6953078508377075  (0.7654954195022583)\n",
            "     | > log_mle: 0.04736357927322388  (0.048734084883732584)\n",
            "     | > loss_dur: 0.6479442715644836  (0.7167613346185259)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(4.6726, device='cuda:0')  (tensor(24.9479, device='cuda:0'))\n",
            "     | > current_lr: 1.075e-05 \n",
            "     | > step_time: 0.2901  (0.38012354765365375)\n",
            "     | > loader_time: 0.0029  (0.00452954733549659)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5200879573822021 \u001b[0m(-1.2096350193023682)\n",
            "     | > avg_loss:\u001b[92m 0.7660033702850342 \u001b[0m(-0.0157850980758667)\n",
            "     | > avg_log_mle:\u001b[92m -0.0476222038269043 \u001b[0m(-0.027915000915527344)\n",
            "     | > avg_loss_dur:\u001b[91m 0.8136255741119385 \u001b[0m(+0.012129902839660645)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5200879573822021 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7660033702850342 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.0476222038269043 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8136255741119385 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3564.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 44/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:34:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:34:16 -- STEP: 11/81 -- GLOBAL_STEP: 3575\u001b[0m\n",
            "     | > loss: 0.6261074542999268  (0.7227152260867032)\n",
            "     | > log_mle: 0.1316540241241455  (0.07183150811628862)\n",
            "     | > loss_dur: 0.49445345997810364  (0.6508837206797167)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(3.5650, device='cuda:0')  (tensor(10.5242, device='cuda:0'))\n",
            "     | > current_lr: 1.1e-05 \n",
            "     | > step_time: 0.424  (0.46075398271734064)\n",
            "     | > loader_time: 0.0046  (0.012404463507912376)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:34:25 -- STEP: 36/81 -- GLOBAL_STEP: 3600\u001b[0m\n",
            "     | > loss: 0.8861619830131531  (0.7526183740960227)\n",
            "     | > log_mle: -0.01769256591796875  (0.04088545342286428)\n",
            "     | > loss_dur: 0.9038545489311218  (0.711732922328843)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(43.9396, device='cuda:0')  (tensor(23.2866, device='cuda:0'))\n",
            "     | > current_lr: 1.1e-05 \n",
            "     | > step_time: 0.2884  (0.3890087604522705)\n",
            "     | > loader_time: 0.0073  (0.007579174306657579)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:34:34 -- STEP: 61/81 -- GLOBAL_STEP: 3625\u001b[0m\n",
            "     | > loss: 0.773928165435791  (0.7575222302655704)\n",
            "     | > log_mle: 0.17999762296676636  (0.03619837956350358)\n",
            "     | > loss_dur: 0.5939305424690247  (0.7213238516791922)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.1287, device='cuda:0')  (tensor(23.4893, device='cuda:0'))\n",
            "     | > current_lr: 1.1e-05 \n",
            "     | > step_time: 0.4247  (0.3681844062492496)\n",
            "     | > loader_time: 0.0023  (0.006729739611266089)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5225236415863037 \u001b[0m(+0.0024356842041015625)\n",
            "     | > avg_loss:\u001b[92m 0.7581301927566528 \u001b[0m(-0.007873177528381348)\n",
            "     | > avg_log_mle:\u001b[91m -0.03322255611419678 \u001b[0m(+0.01439964771270752)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7913527488708496 \u001b[0m(-0.022272825241088867)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5225236415863037 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7581301927566528 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.03322255611419678 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7913527488708496 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3645.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 45/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:34:59) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:35:03 -- STEP: 5/81 -- GLOBAL_STEP: 3650\u001b[0m\n",
            "     | > loss: 0.7619971036911011  (0.7490208148956299)\n",
            "     | > log_mle: 0.09827107191085815  (0.07269097566604614)\n",
            "     | > loss_dur: 0.6637260317802429  (0.6763298392295838)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(5.8836, device='cuda:0')  (tensor(24.2799, device='cuda:0'))\n",
            "     | > current_lr: 1.125e-05 \n",
            "     | > step_time: 0.3182  (0.3931113243103027)\n",
            "     | > loader_time: 0.0062  (0.005885696411132813)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:35:11 -- STEP: 30/81 -- GLOBAL_STEP: 3675\u001b[0m\n",
            "     | > loss: 0.8665149807929993  (0.7463380038738251)\n",
            "     | > log_mle: 0.0436440110206604  (0.03811983068784078)\n",
            "     | > loss_dur: 0.8228709697723389  (0.708218174179395)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(8.4468, device='cuda:0')  (tensor(20.5856, device='cuda:0'))\n",
            "     | > current_lr: 1.125e-05 \n",
            "     | > step_time: 0.2958  (0.31557568709055583)\n",
            "     | > loader_time: 0.0048  (0.0045412858327229825)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:35:27 -- STEP: 55/81 -- GLOBAL_STEP: 3700\u001b[0m\n",
            "     | > loss: 0.7049822211265564  (0.7512334856120023)\n",
            "     | > log_mle: 0.12368631362915039  (0.0319381442936984)\n",
            "     | > loss_dur: 0.581295907497406  (0.7192953402345831)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.5427, device='cuda:0')  (tensor(19.7047, device='cuda:0'))\n",
            "     | > current_lr: 1.125e-05 \n",
            "     | > step_time: 0.4049  (0.4543139977888627)\n",
            "     | > loader_time: 0.0034  (0.005603283101862127)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:35:35 -- STEP: 80/81 -- GLOBAL_STEP: 3725\u001b[0m\n",
            "     | > loss: 0.7500390410423279  (0.7382215954363347)\n",
            "     | > log_mle: -0.2152928113937378  (0.019600175321102142)\n",
            "     | > loss_dur: 0.9653318524360657  (0.7186214193701744)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(40.2032, device='cuda:0')  (tensor(23.7614, device='cuda:0'))\n",
            "     | > current_lr: 1.125e-05 \n",
            "     | > step_time: 0.236  (0.4050861090421677)\n",
            "     | > loader_time: 0.0028  (0.005078712105751037)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5277574062347412 \u001b[0m(+0.0052337646484375)\n",
            "     | > avg_loss:\u001b[91m 0.7711705565452576 \u001b[0m(+0.013040363788604736)\n",
            "     | > avg_log_mle:\u001b[92m -0.03586101531982422 \u001b[0m(-0.0026384592056274414)\n",
            "     | > avg_loss_dur:\u001b[91m 0.8070315718650818 \u001b[0m(+0.015678822994232178)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5277574062347412 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7711705565452576 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.03586101531982422 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8070315718650818 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 46/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:35:50) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:36:04 -- STEP: 24/81 -- GLOBAL_STEP: 3750\u001b[0m\n",
            "     | > loss: 0.780482292175293  (0.7213064879179001)\n",
            "     | > log_mle: -0.003270447254180908  (0.04376045614480972)\n",
            "     | > loss_dur: 0.7837527394294739  (0.6775460292895635)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(11.3917, device='cuda:0')  (tensor(19.2767, device='cuda:0'))\n",
            "     | > current_lr: 1.15e-05 \n",
            "     | > step_time: 0.4893  (0.49377769231796265)\n",
            "     | > loader_time: 0.0049  (0.009924809137980143)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:36:15 -- STEP: 49/81 -- GLOBAL_STEP: 3775\u001b[0m\n",
            "     | > loss: 0.5829055905342102  (0.7361040346476496)\n",
            "     | > log_mle: 0.0023783445358276367  (0.03128253318825547)\n",
            "     | > loss_dur: 0.5805272459983826  (0.7048215020676047)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(12.9464, device='cuda:0')  (tensor(19.7967, device='cuda:0'))\n",
            "     | > current_lr: 1.15e-05 \n",
            "     | > step_time: 0.2956  (0.45068277631487164)\n",
            "     | > loader_time: 0.0074  (0.007016697708441287)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:36:23 -- STEP: 74/81 -- GLOBAL_STEP: 3800\u001b[0m\n",
            "     | > loss: 0.6073135733604431  (0.7317583971732372)\n",
            "     | > log_mle: -0.023328721523284912  (0.020763085500614065)\n",
            "     | > loss_dur: 0.630642294883728  (0.7109953128808253)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(17.5997, device='cuda:0')  (tensor(27.7643, device='cuda:0'))\n",
            "     | > current_lr: 1.15e-05 \n",
            "     | > step_time: 0.3523  (0.40323156279486577)\n",
            "     | > loader_time: 0.0026  (0.006053483163988268)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.775244951248169 \u001b[0m(+0.24748754501342773)\n",
            "     | > avg_loss:\u001b[92m 0.7278146147727966 \u001b[0m(-0.04335594177246094)\n",
            "     | > avg_log_mle:\u001b[92m -0.07578134536743164 \u001b[0m(-0.03992033004760742)\n",
            "     | > avg_loss_dur:\u001b[92m 0.8035959601402283 \u001b[0m(-0.0034356117248535156)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.775244951248169 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7278146147727966 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.07578134536743164 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.8035959601402283 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3807.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 47/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:36:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:36:56 -- STEP: 18/81 -- GLOBAL_STEP: 3825\u001b[0m\n",
            "     | > loss: 0.667186439037323  (0.7169978850417666)\n",
            "     | > log_mle: 0.1598483920097351  (0.04948449465963575)\n",
            "     | > loss_dur: 0.5073380470275879  (0.6675133887264464)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(1.8482, device='cuda:0')  (tensor(14.7200, device='cuda:0'))\n",
            "     | > current_lr: 1.1750000000000001e-05 \n",
            "     | > step_time: 0.2949  (0.39707175890604657)\n",
            "     | > loader_time: 0.0027  (0.005422406726413303)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:37:04 -- STEP: 43/81 -- GLOBAL_STEP: 3850\u001b[0m\n",
            "     | > loss: 0.6819785833358765  (0.7261935624965402)\n",
            "     | > log_mle: 0.1715107560157776  (0.018458272135534946)\n",
            "     | > loss_dur: 0.5104678273200989  (0.7077352882817735)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(2.2890, device='cuda:0')  (tensor(17.5711, device='cuda:0'))\n",
            "     | > current_lr: 1.1750000000000001e-05 \n",
            "     | > step_time: 0.4474  (0.3466651883236198)\n",
            "     | > loader_time: 0.0029  (0.004739838977192725)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:37:16 -- STEP: 68/81 -- GLOBAL_STEP: 3875\u001b[0m\n",
            "     | > loss: 0.6268773674964905  (0.7160819479647804)\n",
            "     | > log_mle: 0.021371126174926758  (0.013083919882774348)\n",
            "     | > loss_dur: 0.6055062413215637  (0.7029980267671978)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(14.7944, device='cuda:0')  (tensor(21.6394, device='cuda:0'))\n",
            "     | > current_lr: 1.1750000000000001e-05 \n",
            "     | > step_time: 0.29  (0.38632241066764383)\n",
            "     | > loader_time: 0.0054  (0.00663217726875754)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5763800144195557 \u001b[0m(-0.19886493682861328)\n",
            "     | > avg_loss:\u001b[92m 0.7069516777992249 \u001b[0m(-0.020862936973571777)\n",
            "     | > avg_log_mle:\u001b[92m -0.08913564682006836 \u001b[0m(-0.013354301452636719)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7960873246192932 \u001b[0m(-0.007508635520935059)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5763800144195557 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7069516777992249 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.08913564682006836 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7960873246192932 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_3888.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 48/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:37:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:37:52 -- STEP: 12/81 -- GLOBAL_STEP: 3900\u001b[0m\n",
            "     | > loss: 0.6975818872451782  (0.6884847929080328)\n",
            "     | > log_mle: -0.1565399169921875  (0.028130720059076946)\n",
            "     | > loss_dur: 0.8541218042373657  (0.6603540703654289)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(31.9369, device='cuda:0')  (tensor(21.1099, device='cuda:0'))\n",
            "     | > current_lr: 1.2e-05 \n",
            "     | > step_time: 0.4468  (0.4092426300048828)\n",
            "     | > loader_time: 0.0027  (0.004571239153544108)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:38:03 -- STEP: 37/81 -- GLOBAL_STEP: 3925\u001b[0m\n",
            "     | > loss: 0.7184701561927795  (0.7071929477356577)\n",
            "     | > log_mle: -0.08873915672302246  (0.007331140943475672)\n",
            "     | > loss_dur: 0.807209312915802  (0.6998618059867138)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(44.2130, device='cuda:0')  (tensor(20.7200, device='cuda:0'))\n",
            "     | > current_lr: 1.2e-05 \n",
            "     | > step_time: 0.2894  (0.4113189529728245)\n",
            "     | > loader_time: 0.0028  (0.003939622157328838)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:38:11 -- STEP: 62/81 -- GLOBAL_STEP: 3950\u001b[0m\n",
            "     | > loss: 0.6262997984886169  (0.7097739558066091)\n",
            "     | > log_mle: 0.05747288465499878  (0.005125156333369592)\n",
            "     | > loss_dur: 0.5688269138336182  (0.704648798992557)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(3.0735, device='cuda:0')  (tensor(20.0536, device='cuda:0'))\n",
            "     | > current_lr: 1.2e-05 \n",
            "     | > step_time: 0.4049  (0.3678210089283605)\n",
            "     | > loader_time: 0.0027  (0.004097461700439453)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7979273796081543 \u001b[0m(+0.22154736518859863)\n",
            "     | > avg_loss:\u001b[91m 0.7151796221733093 \u001b[0m(+0.008227944374084473)\n",
            "     | > avg_log_mle:\u001b[91m -0.07949554920196533 \u001b[0m(+0.009640097618103027)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7946751713752747 \u001b[0m(-0.0014121532440185547)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7979273796081543 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7151796221733093 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.07949554920196533 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7946751713752747 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 49/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:38:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:38:39 -- STEP: 6/81 -- GLOBAL_STEP: 3975\u001b[0m\n",
            "     | > loss: 0.7446227073669434  (0.7071520388126373)\n",
            "     | > log_mle: -0.022464394569396973  (0.025899489720662434)\n",
            "     | > loss_dur: 0.7670871019363403  (0.6812525490919749)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(10.0953, device='cuda:0')  (tensor(15.1791, device='cuda:0'))\n",
            "     | > current_lr: 1.225e-05 \n",
            "     | > step_time: 0.4401  (0.4748195807139079)\n",
            "     | > loader_time: 0.0166  (0.011702219645182291)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:38:49 -- STEP: 31/81 -- GLOBAL_STEP: 4000\u001b[0m\n",
            "     | > loss: 0.7185670733451843  (0.7015534927768092)\n",
            "     | > log_mle: 0.0712767243385315  (0.0067766058829522935)\n",
            "     | > loss_dur: 0.6472903490066528  (0.6947768868938569)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(10.2750, device='cuda:0')  (tensor(19.7098, device='cuda:0'))\n",
            "     | > current_lr: 1.225e-05 \n",
            "     | > step_time: 0.292  (0.39592694467113865)\n",
            "     | > loader_time: 0.0032  (0.0059779920885639805)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_4000.pth\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:39:07 -- STEP: 56/81 -- GLOBAL_STEP: 4025\u001b[0m\n",
            "     | > loss: 0.6516579985618591  (0.7083054674523217)\n",
            "     | > log_mle: -0.0991356372833252  (-0.0015439912676811199)\n",
            "     | > loss_dur: 0.7507936358451843  (0.7098494587200028)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(134.6837, device='cuda:0')  (tensor(26.0829, device='cuda:0'))\n",
            "     | > current_lr: 1.225e-05 \n",
            "     | > step_time: 0.3113  (0.41444926602499826)\n",
            "     | > loader_time: 0.0041  (0.006016543933323452)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.528449296951294 \u001b[0m(-0.26947808265686035)\n",
            "     | > avg_loss:\u001b[92m 0.7052165269851685 \u001b[0m(-0.00996309518814087)\n",
            "     | > avg_log_mle:\u001b[92m -0.08579576015472412 \u001b[0m(-0.006300210952758789)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7910122871398926 \u001b[0m(-0.00366288423538208)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.528449296951294 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7052165269851685 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.08579576015472412 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7910122871398926 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_4050.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 50/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:39:36) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:39:38 -- STEP: 0/81 -- GLOBAL_STEP: 4050\u001b[0m\n",
            "     | > loss: 0.6840004324913025  (0.6840004324913025)\n",
            "     | > log_mle: 0.1477442979812622  (0.1477442979812622)\n",
            "     | > loss_dur: 0.5362561345100403  (0.5362561345100403)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(1.9384, device='cuda:0')  (tensor(1.9384, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-05 \n",
            "     | > step_time: 0.8113  (0.8113250732421875)\n",
            "     | > loader_time: 1.0536  (1.0535838603973389)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:39:56 -- STEP: 25/81 -- GLOBAL_STEP: 4075\u001b[0m\n",
            "     | > loss: 0.6116187572479248  (0.6762134599685669)\n",
            "     | > log_mle: -0.017035603523254395  (0.005373635292053225)\n",
            "     | > loss_dur: 0.6286543607711792  (0.6708398246765137)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(31.5217, device='cuda:0')  (tensor(12.4321, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-05 \n",
            "     | > step_time: 0.4712  (0.7070817470550537)\n",
            "     | > loader_time: 0.0033  (0.0078061866760253925)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:40:10 -- STEP: 50/81 -- GLOBAL_STEP: 4100\u001b[0m\n",
            "     | > loss: 0.9591505527496338  (0.7001268923282623)\n",
            "     | > log_mle: -0.10944855213165283  (-0.006067670583724975)\n",
            "     | > loss_dur: 1.0685991048812866  (0.706194562911987)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(59.6811, device='cuda:0')  (tensor(17.0573, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-05 \n",
            "     | > step_time: 0.4581  (0.6191391420364379)\n",
            "     | > loader_time: 0.0029  (0.007708306312561036)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:40:20 -- STEP: 75/81 -- GLOBAL_STEP: 4125\u001b[0m\n",
            "     | > loss: 0.49682170152664185  (0.6882894015312195)\n",
            "     | > log_mle: -0.027541816234588623  (-0.014625680446624757)\n",
            "     | > loss_dur: 0.5243635177612305  (0.7029150819778444)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(41.2080, device='cuda:0')  (tensor(22.5358, device='cuda:0'))\n",
            "     | > current_lr: 1.2499999999999999e-05 \n",
            "     | > step_time: 0.2548  (0.5408124923706056)\n",
            "     | > loader_time: 0.0023  (0.007794993718465169)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5408551692962646 \u001b[0m(+0.012405872344970703)\n",
            "     | > avg_loss:\u001b[91m 0.7247803211212158 \u001b[0m(+0.019563794136047363)\n",
            "     | > avg_log_mle:\u001b[91m -0.062089383602142334 \u001b[0m(+0.023706376552581787)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7868697047233582 \u001b[0m(-0.004142582416534424)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5408551692962646 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7247803211212158 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.062089383602142334 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7868697047233582 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 51/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:40:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:40:47 -- STEP: 19/81 -- GLOBAL_STEP: 4150\u001b[0m\n",
            "     | > loss: 0.5860543251037598  (0.6721766496959486)\n",
            "     | > log_mle: -0.009519338607788086  (0.01993899282656218)\n",
            "     | > loss_dur: 0.5955736637115479  (0.6522376568693864)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(19.8156, device='cuda:0')  (tensor(20.7047, device='cuda:0'))\n",
            "     | > current_lr: 1.275e-05 \n",
            "     | > step_time: 0.2909  (0.2997962048179225)\n",
            "     | > loader_time: 0.0023  (0.003051632329037315)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:40:58 -- STEP: 44/81 -- GLOBAL_STEP: 4175\u001b[0m\n",
            "     | > loss: 0.7061709761619568  (0.6871039921587163)\n",
            "     | > log_mle: -0.0011854171752929688  (-0.009463023055683483)\n",
            "     | > loss_dur: 0.7073563933372498  (0.6965670138597488)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(8.9816, device='cuda:0')  (tensor(21.1100, device='cuda:0'))\n",
            "     | > current_lr: 1.275e-05 \n",
            "     | > step_time: 0.4448  (0.3836107145656239)\n",
            "     | > loader_time: 0.006  (0.004283233122392133)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:41:07 -- STEP: 69/81 -- GLOBAL_STEP: 4200\u001b[0m\n",
            "     | > loss: 0.6561420559883118  (0.6790029881657034)\n",
            "     | > log_mle: -0.23226380348205566  (-0.018128286237302033)\n",
            "     | > loss_dur: 0.8884058594703674  (0.6971312735391699)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(128.4134, device='cuda:0')  (tensor(26.4907, device='cuda:0'))\n",
            "     | > current_lr: 1.275e-05 \n",
            "     | > step_time: 0.3107  (0.36766299994095514)\n",
            "     | > loader_time: 0.003  (0.004398598187211631)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6642682552337646 \u001b[0m(+0.1234130859375)\n",
            "     | > avg_loss:\u001b[91m 0.7512310147285461 \u001b[0m(+0.026450693607330322)\n",
            "     | > avg_log_mle:\u001b[91m -0.04681718349456787 \u001b[0m(+0.015272200107574463)\n",
            "     | > avg_loss_dur:\u001b[91m 0.798048198223114 \u001b[0m(+0.01117849349975586)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.6642682552337646 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.7512310147285461 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.04681718349456787 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.798048198223114 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 52/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:41:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:41:32 -- STEP: 13/81 -- GLOBAL_STEP: 4225\u001b[0m\n",
            "     | > loss: 0.6631365418434143  (0.6592212044275724)\n",
            "     | > log_mle: 0.017299413681030273  (-0.0023157321489774263)\n",
            "     | > loss_dur: 0.645837128162384  (0.6615369365765498)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(7.6540, device='cuda:0')  (tensor(17.7739, device='cuda:0'))\n",
            "     | > current_lr: 1.3e-05 \n",
            "     | > step_time: 0.2991  (0.2974565029144287)\n",
            "     | > loader_time: 0.005  (0.004115104675292968)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:41:43 -- STEP: 38/81 -- GLOBAL_STEP: 4250\u001b[0m\n",
            "     | > loss: 0.828156054019928  (0.6808517857601768)\n",
            "     | > log_mle: -0.011721253395080566  (-0.023594879790356283)\n",
            "     | > loss_dur: 0.8398773074150085  (0.7044466639819899)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(17.4651, device='cuda:0')  (tensor(19.1334, device='cuda:0'))\n",
            "     | > current_lr: 1.3e-05 \n",
            "     | > step_time: 0.508  (0.3923886261488262)\n",
            "     | > loader_time: 0.005  (0.005921677539223118)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:41:52 -- STEP: 63/81 -- GLOBAL_STEP: 4275\u001b[0m\n",
            "     | > loss: 0.6354358792304993  (0.6772613459163241)\n",
            "     | > log_mle: -0.09869825839996338  (-0.025267468558417425)\n",
            "     | > loss_dur: 0.7341341376304626  (0.702528813528636)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(146.3240, device='cuda:0')  (tensor(26.0839, device='cuda:0'))\n",
            "     | > current_lr: 1.3e-05 \n",
            "     | > step_time: 0.5517  (0.367920992866395)\n",
            "     | > loader_time: 0.0052  (0.005737482555328852)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.827150821685791 \u001b[0m(+0.16288256645202637)\n",
            "     | > avg_loss:\u001b[92m 0.6704043745994568 \u001b[0m(-0.08082664012908936)\n",
            "     | > avg_log_mle:\u001b[92m -0.11884629726409912 \u001b[0m(-0.07202911376953125)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7892506718635559 \u001b[0m(-0.008797526359558105)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.827150821685791 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6704043745994568 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.11884629726409912 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7892506718635559 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_4293.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 53/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:42:17) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:42:23 -- STEP: 7/81 -- GLOBAL_STEP: 4300\u001b[0m\n",
            "     | > loss: 0.6672309041023254  (0.6764295612062726)\n",
            "     | > log_mle: 0.03406554460525513  (0.0010533417974199568)\n",
            "     | > loss_dur: 0.6331653594970703  (0.6753762194088527)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(4.0184, device='cuda:0')  (tensor(18.7059, device='cuda:0'))\n",
            "     | > current_lr: 1.325e-05 \n",
            "     | > step_time: 0.4611  (0.4780980178288051)\n",
            "     | > loader_time: 0.0103  (0.012223141533987862)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:42:32 -- STEP: 32/81 -- GLOBAL_STEP: 4325\u001b[0m\n",
            "     | > loss: 0.5526367425918579  (0.6640388388186694)\n",
            "     | > log_mle: -0.18121349811553955  (-0.0287658479064703)\n",
            "     | > loss_dur: 0.7338502407073975  (0.6928046867251396)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(26.0739, device='cuda:0')  (tensor(21.2721, device='cuda:0'))\n",
            "     | > current_lr: 1.325e-05 \n",
            "     | > step_time: 0.2946  (0.37810898572206497)\n",
            "     | > loader_time: 0.0035  (0.007487207651138302)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:42:41 -- STEP: 57/81 -- GLOBAL_STEP: 4350\u001b[0m\n",
            "     | > loss: 0.5219927430152893  (0.6692119972747669)\n",
            "     | > log_mle: -0.2832822799682617  (-0.03872683173731754)\n",
            "     | > loss_dur: 0.805275022983551  (0.7079388290120844)\n",
            "     | > amp_scaler: 4096.0  (2551.0175438596493)\n",
            "     | > grad_norm: tensor(142.6333, device='cuda:0')  (tensor(24.9165, device='cuda:0'))\n",
            "     | > current_lr: 1.325e-05 \n",
            "     | > step_time: 0.461  (0.36415261553044903)\n",
            "     | > loader_time: 0.0088  (0.005887341081050402)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5150284767150879 \u001b[0m(-0.3121223449707031)\n",
            "     | > avg_loss:\u001b[91m 0.6743574738502502 \u001b[0m(+0.003953099250793457)\n",
            "     | > avg_log_mle:\u001b[91m -0.08157384395599365 \u001b[0m(+0.03727245330810547)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7559313178062439 \u001b[0m(-0.03331935405731201)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5150284767150879 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6743574738502502 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.08157384395599365 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7559313178062439 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 54/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:43:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:43:08 -- STEP: 1/81 -- GLOBAL_STEP: 4375\u001b[0m\n",
            "     | > loss: 0.581524133682251  (0.581524133682251)\n",
            "     | > log_mle: -0.04656398296356201  (-0.04656398296356201)\n",
            "     | > loss_dur: 0.628088116645813  (0.628088116645813)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(48.5731, device='cuda:0')  (tensor(48.5731, device='cuda:0'))\n",
            "     | > current_lr: 1.35e-05 \n",
            "     | > step_time: 0.5209  (0.5208888053894043)\n",
            "     | > loader_time: 0.0106  (0.010634660720825195)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:43:17 -- STEP: 26/81 -- GLOBAL_STEP: 4400\u001b[0m\n",
            "     | > loss: 0.5131865739822388  (0.6371554869871873)\n",
            "     | > log_mle: -0.1799396276473999  (-0.02998769054046044)\n",
            "     | > loss_dur: 0.6931262016296387  (0.6671431775276477)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(44.9591, device='cuda:0')  (tensor(18.7885, device='cuda:0'))\n",
            "     | > current_lr: 1.35e-05 \n",
            "     | > step_time: 0.2889  (0.34810475202707136)\n",
            "     | > loader_time: 0.003  (0.004964663432194639)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:43:26 -- STEP: 51/81 -- GLOBAL_STEP: 4425\u001b[0m\n",
            "     | > loss: 0.5990848541259766  (0.6600572981086432)\n",
            "     | > log_mle: -0.0984959602355957  (-0.03726508103164973)\n",
            "     | > loss_dur: 0.6975808143615723  (0.6973223791402929)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.9429, device='cuda:0')  (tensor(21.6437, device='cuda:0'))\n",
            "     | > current_lr: 1.35e-05 \n",
            "     | > step_time: 0.4843  (0.35440931600682873)\n",
            "     | > loader_time: 0.0036  (0.004778151418648516)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:43:36 -- STEP: 76/81 -- GLOBAL_STEP: 4450\u001b[0m\n",
            "     | > loss: 0.617986261844635  (0.649972845849238)\n",
            "     | > log_mle: -0.15745055675506592  (-0.04478941073543148)\n",
            "     | > loss_dur: 0.7754368185997009  (0.6947622565846694)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(27.3753, device='cuda:0')  (tensor(26.6594, device='cuda:0'))\n",
            "     | > current_lr: 1.35e-05 \n",
            "     | > step_time: 0.2702  (0.36316741767682525)\n",
            "     | > loader_time: 0.0027  (0.005240132934168766)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.530893087387085 \u001b[0m(+0.01586461067199707)\n",
            "     | > avg_loss:\u001b[92m 0.6345276236534119 \u001b[0m(-0.03982985019683838)\n",
            "     | > avg_log_mle:\u001b[92m -0.12637925148010254 \u001b[0m(-0.04480540752410889)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7609068751335144 \u001b[0m(+0.004975557327270508)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.530893087387085 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6345276236534119 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.12637925148010254 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7609068751335144 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_4455.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 55/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:44:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:44:20 -- STEP: 20/81 -- GLOBAL_STEP: 4475\u001b[0m\n",
            "     | > loss: 0.7747913599014282  (0.6505338907241821)\n",
            "     | > log_mle: -0.014735102653503418  (-0.01168113648891449)\n",
            "     | > loss_dur: 0.7895264625549316  (0.6622150272130967)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(9.1550, device='cuda:0')  (tensor(13.7600, device='cuda:0'))\n",
            "     | > current_lr: 1.375e-05 \n",
            "     | > step_time: 0.4253  (0.5567241668701172)\n",
            "     | > loader_time: 0.012  (0.010785353183746339)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:44:28 -- STEP: 45/81 -- GLOBAL_STEP: 4500\u001b[0m\n",
            "     | > loss: 0.740746021270752  (0.6571813186009726)\n",
            "     | > log_mle: 0.06950485706329346  (-0.038475973076290554)\n",
            "     | > loss_dur: 0.6712411642074585  (0.695657291677263)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(9.2552, device='cuda:0')  (tensor(15.7314, device='cuda:0'))\n",
            "     | > current_lr: 1.375e-05 \n",
            "     | > step_time: 0.3029  (0.42750555144415947)\n",
            "     | > loader_time: 0.004  (0.007535001966688367)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:44:38 -- STEP: 70/81 -- GLOBAL_STEP: 4525\u001b[0m\n",
            "     | > loss: 0.6561169624328613  (0.6449124761990139)\n",
            "     | > log_mle: 0.09195840358734131  (-0.04808466689927238)\n",
            "     | > loss_dur: 0.56415855884552  (0.6929971430982862)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(4.1544, device='cuda:0')  (tensor(20.2480, device='cuda:0'))\n",
            "     | > current_lr: 1.375e-05 \n",
            "     | > step_time: 0.4856  (0.4077009882245744)\n",
            "     | > loader_time: 0.0032  (0.006063832555498395)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8917813301086426 \u001b[0m(+0.3608882427215576)\n",
            "     | > avg_loss:\u001b[91m 0.6628484129905701 \u001b[0m(+0.028320789337158203)\n",
            "     | > avg_log_mle:\u001b[91m -0.09888064861297607 \u001b[0m(+0.027498602867126465)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7617290616035461 \u001b[0m(+0.0008221864700317383)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8917813301086426 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6628484129905701 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.09888064861297607 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7617290616035461 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 56/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:44:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:45:04 -- STEP: 14/81 -- GLOBAL_STEP: 4550\u001b[0m\n",
            "     | > loss: 0.7679097056388855  (0.6388196860040937)\n",
            "     | > log_mle: 0.12057650089263916  (-0.01822715997695923)\n",
            "     | > loss_dur: 0.6473332047462463  (0.6570468459810529)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(1.9401, device='cuda:0')  (tensor(20.8093, device='cuda:0'))\n",
            "     | > current_lr: 1.4e-05 \n",
            "     | > step_time: 0.5046  (0.48738910470690044)\n",
            "     | > loader_time: 0.0034  (0.0037368365696498324)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:45:12 -- STEP: 39/81 -- GLOBAL_STEP: 4575\u001b[0m\n",
            "     | > loss: 0.5745922923088074  (0.6448734142841437)\n",
            "     | > log_mle: -0.13778769969940186  (-0.05377960663575392)\n",
            "     | > loss_dur: 0.7123799920082092  (0.6986530209198977)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(29.5788, device='cuda:0')  (tensor(23.5626, device='cuda:0'))\n",
            "     | > current_lr: 1.4e-05 \n",
            "     | > step_time: 0.3144  (0.3736845102065649)\n",
            "     | > loader_time: 0.0057  (0.004169977628267729)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:45:23 -- STEP: 64/81 -- GLOBAL_STEP: 4600\u001b[0m\n",
            "     | > loss: 0.6061130166053772  (0.6415752153843644)\n",
            "     | > log_mle: -0.0407404899597168  (-0.05605171620845795)\n",
            "     | > loss_dur: 0.646853506565094  (0.6976269315928222)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(19.3976, device='cuda:0')  (tensor(22.6390, device='cuda:0'))\n",
            "     | > current_lr: 1.4e-05 \n",
            "     | > step_time: 0.5447  (0.38361436501145363)\n",
            "     | > loader_time: 0.0126  (0.004916392266750336)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5580625534057617 \u001b[0m(-0.33371877670288086)\n",
            "     | > avg_loss:\u001b[92m 0.644299328327179 \u001b[0m(-0.018549084663391113)\n",
            "     | > avg_log_mle:\u001b[92m -0.12326180934906006 \u001b[0m(-0.024381160736083984)\n",
            "     | > avg_loss_dur:\u001b[91m 0.767561137676239 \u001b[0m(+0.005832076072692871)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5580625534057617 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.644299328327179 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.12326180934906006 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.767561137676239 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 57/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:45:42) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:45:48 -- STEP: 8/81 -- GLOBAL_STEP: 4625\u001b[0m\n",
            "     | > loss: 0.5816660523414612  (0.6321334838867188)\n",
            "     | > log_mle: -0.0043198466300964355  (-0.02496407926082611)\n",
            "     | > loss_dur: 0.5859858989715576  (0.6570975631475449)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.2272, device='cuda:0')  (tensor(18.4333, device='cuda:0'))\n",
            "     | > current_lr: 1.425e-05 \n",
            "     | > step_time: 0.4962  (0.47794556617736816)\n",
            "     | > loader_time: 0.004  (0.00845983624458313)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:45:56 -- STEP: 33/81 -- GLOBAL_STEP: 4650\u001b[0m\n",
            "     | > loss: 0.6427574157714844  (0.6281030774116516)\n",
            "     | > log_mle: -0.06026977300643921  (-0.0579451322555542)\n",
            "     | > loss_dur: 0.7030271887779236  (0.6860482096672056)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(27.7748, device='cuda:0')  (tensor(23.2695, device='cuda:0'))\n",
            "     | > current_lr: 1.425e-05 \n",
            "     | > step_time: 0.2889  (0.35099390781286993)\n",
            "     | > loader_time: 0.0048  (0.005046064203435724)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:46:06 -- STEP: 58/81 -- GLOBAL_STEP: 4675\u001b[0m\n",
            "     | > loss: 0.7117131948471069  (0.6358833251328304)\n",
            "     | > log_mle: -0.023699283599853516  (-0.06519119492892561)\n",
            "     | > loss_dur: 0.7354124784469604  (0.701074520061756)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(10.9295, device='cuda:0')  (tensor(25.5656, device='cuda:0'))\n",
            "     | > current_lr: 1.425e-05 \n",
            "     | > step_time: 0.4915  (0.37254415298330373)\n",
            "     | > loader_time: 0.0035  (0.005139667412330366)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6198618412017822 \u001b[0m(+0.06179928779602051)\n",
            "     | > avg_loss:\u001b[92m 0.6433525681495667 \u001b[0m(-0.0009467601776123047)\n",
            "     | > avg_log_mle:\u001b[92m -0.12955379486083984 \u001b[0m(-0.006291985511779785)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7729063630104065 \u001b[0m(+0.0053452253341674805)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.6198618412017822 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6433525681495667 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.12955379486083984 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7729063630104065 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 58/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:46:31) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:46:34 -- STEP: 2/81 -- GLOBAL_STEP: 4700\u001b[0m\n",
            "     | > loss: 0.7129235863685608  (0.6544503569602966)\n",
            "     | > log_mle: 0.1012163758277893  (0.014034777879714966)\n",
            "     | > loss_dur: 0.6117072105407715  (0.6404155790805817)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(1.9035, device='cuda:0')  (tensor(19.7369, device='cuda:0'))\n",
            "     | > current_lr: 1.45e-05 \n",
            "     | > step_time: 0.2874  (0.29183077812194824)\n",
            "     | > loader_time: 0.0035  (0.0034444332122802734)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:46:42 -- STEP: 27/81 -- GLOBAL_STEP: 4725\u001b[0m\n",
            "     | > loss: 0.5930934548377991  (0.6096328496932983)\n",
            "     | > log_mle: -0.20709550380706787  (-0.06418339411417644)\n",
            "     | > loss_dur: 0.8001889586448669  (0.6738162438074747)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(32.7368, device='cuda:0')  (tensor(17.9325, device='cuda:0'))\n",
            "     | > current_lr: 1.45e-05 \n",
            "     | > step_time: 0.3066  (0.30282830308984826)\n",
            "     | > loader_time: 0.0031  (0.0040986449630172166)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:46:53 -- STEP: 52/81 -- GLOBAL_STEP: 4750\u001b[0m\n",
            "     | > loss: 0.5200054049491882  (0.6298065827443051)\n",
            "     | > log_mle: -0.044845521450042725  (-0.06570210823645958)\n",
            "     | > loss_dur: 0.564850926399231  (0.6955086909807645)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(3.5390, device='cuda:0')  (tensor(17.5608, device='cuda:0'))\n",
            "     | > current_lr: 1.45e-05 \n",
            "     | > step_time: 0.4494  (0.36827565614993757)\n",
            "     | > loader_time: 0.0135  (0.006562439294961784)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:47:01 -- STEP: 77/81 -- GLOBAL_STEP: 4775\u001b[0m\n",
            "     | > loss: 0.536457359790802  (0.6185575638498579)\n",
            "     | > log_mle: 0.045827627182006836  (-0.07388492528494302)\n",
            "     | > loss_dur: 0.49062973260879517  (0.692442489134801)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(8.0348, device='cuda:0')  (tensor(22.2486, device='cuda:0'))\n",
            "     | > current_lr: 1.45e-05 \n",
            "     | > step_time: 0.2432  (0.3470783760021258)\n",
            "     | > loader_time: 0.0028  (0.0058979709427078066)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5553641319274902 \u001b[0m(-0.06449770927429199)\n",
            "     | > avg_loss:\u001b[92m 0.5892101526260376 \u001b[0m(-0.05414241552352905)\n",
            "     | > avg_log_mle:\u001b[92m -0.16279339790344238 \u001b[0m(-0.03323960304260254)\n",
            "     | > avg_loss_dur:\u001b[92m 0.75200355052948 \u001b[0m(-0.020902812480926514)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5553641319274902 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5892101526260376 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.16279339790344238 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.75200355052948 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_4779.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 59/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:47:23) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:47:34 -- STEP: 21/81 -- GLOBAL_STEP: 4800\u001b[0m\n",
            "     | > loss: 0.5911415815353394  (0.6223645948228382)\n",
            "     | > log_mle: -0.095664381980896  (-0.04009095827738444)\n",
            "     | > loss_dur: 0.6868059635162354  (0.6624555531002226)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(15.6988, device='cuda:0')  (tensor(18.1959, device='cuda:0'))\n",
            "     | > current_lr: 1.475e-05 \n",
            "     | > step_time: 0.4828  (0.46090930984133766)\n",
            "     | > loader_time: 0.0031  (0.0038911274501255582)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:47:43 -- STEP: 46/81 -- GLOBAL_STEP: 4825\u001b[0m\n",
            "     | > loss: 0.827896773815155  (0.6329820000607033)\n",
            "     | > log_mle: 0.09618926048278809  (-0.06231402962104135)\n",
            "     | > loss_dur: 0.7317075133323669  (0.6952960296817448)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(7.1649, device='cuda:0')  (tensor(18.5602, device='cuda:0'))\n",
            "     | > current_lr: 1.475e-05 \n",
            "     | > step_time: 0.3016  (0.3990537498308265)\n",
            "     | > loader_time: 0.0053  (0.004056287848431134)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:47:53 -- STEP: 71/81 -- GLOBAL_STEP: 4850\u001b[0m\n",
            "     | > loss: 0.4935559034347534  (0.6164295832875747)\n",
            "     | > log_mle: -0.14718127250671387  (-0.07634815783567832)\n",
            "     | > loss_dur: 0.6407371759414673  (0.6927777411232532)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(32.1655, device='cuda:0')  (tensor(22.1046, device='cuda:0'))\n",
            "     | > current_lr: 1.475e-05 \n",
            "     | > step_time: 0.4806  (0.39159100156434823)\n",
            "     | > loader_time: 0.0119  (0.004625162608186966)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8387820720672607 \u001b[0m(+0.2834179401397705)\n",
            "     | > avg_loss:\u001b[91m 0.6058369278907776 \u001b[0m(+0.01662677526473999)\n",
            "     | > avg_log_mle:\u001b[91m -0.15210485458374023 \u001b[0m(+0.010688543319702148)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7579417824745178 \u001b[0m(+0.005938231945037842)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8387820720672607 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6058369278907776 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.15210485458374023 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7579417824745178 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 60/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:48:09) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:48:21 -- STEP: 15/81 -- GLOBAL_STEP: 4875\u001b[0m\n",
            "     | > loss: 0.6204678416252136  (0.6039564450581868)\n",
            "     | > log_mle: 0.007787168025970459  (-0.04670311609903972)\n",
            "     | > loss_dur: 0.6126806735992432  (0.6506595611572266)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(7.3282, device='cuda:0')  (tensor(14.6383, device='cuda:0'))\n",
            "     | > current_lr: 1.4999999999999999e-05 \n",
            "     | > step_time: 0.5326  (0.5679041067759196)\n",
            "     | > loader_time: 0.0104  (0.009274148941040039)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:48:33 -- STEP: 40/81 -- GLOBAL_STEP: 4900\u001b[0m\n",
            "     | > loss: 0.845201313495636  (0.6194401219487191)\n",
            "     | > log_mle: 0.06801944971084595  (-0.0818777397274971)\n",
            "     | > loss_dur: 0.77718186378479  (0.7013178616762161)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(2.2245, device='cuda:0')  (tensor(20.8640, device='cuda:0'))\n",
            "     | > current_lr: 1.4999999999999999e-05 \n",
            "     | > step_time: 0.3106  (0.5181370973587037)\n",
            "     | > loader_time: 0.0041  (0.0068033933639526385)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:48:44 -- STEP: 65/81 -- GLOBAL_STEP: 4925\u001b[0m\n",
            "     | > loss: 0.49172788858413696  (0.6091383613072909)\n",
            "     | > log_mle: -0.03397369384765625  (-0.08422901538702159)\n",
            "     | > loss_dur: 0.5257015824317932  (0.6933673766943125)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(10.4110, device='cuda:0')  (tensor(25.1973, device='cuda:0'))\n",
            "     | > current_lr: 1.4999999999999999e-05 \n",
            "     | > step_time: 0.5099  (0.48276175719041103)\n",
            "     | > loader_time: 0.0043  (0.005972950275127705)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5320103168487549 \u001b[0m(-0.30677175521850586)\n",
            "     | > avg_loss:\u001b[91m 0.6173964142799377 \u001b[0m(+0.011559486389160156)\n",
            "     | > avg_log_mle:\u001b[91m -0.13462674617767334 \u001b[0m(+0.017478108406066895)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7520231604576111 \u001b[0m(-0.005918622016906738)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5320103168487549 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.6173964142799377 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.13462674617767334 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7520231604576111 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 61/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:49:05) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:49:10 -- STEP: 9/81 -- GLOBAL_STEP: 4950\u001b[0m\n",
            "     | > loss: 0.6447850465774536  (0.6003727912902832)\n",
            "     | > log_mle: 0.032083213329315186  (-0.04247542884614733)\n",
            "     | > loss_dur: 0.6127018332481384  (0.6428482201364305)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.4921, device='cuda:0')  (tensor(16.4016, device='cuda:0'))\n",
            "     | > current_lr: 1.525e-05 \n",
            "     | > step_time: 0.2924  (0.39217209815979004)\n",
            "     | > loader_time: 0.0023  (0.006559345457288954)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:49:18 -- STEP: 34/81 -- GLOBAL_STEP: 4975\u001b[0m\n",
            "     | > loss: 0.5011704564094543  (0.5940520780927993)\n",
            "     | > log_mle: -0.033420562744140625  (-0.08173215564559488)\n",
            "     | > loss_dur: 0.534591019153595  (0.6757842337383944)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(5.0664, device='cuda:0')  (tensor(19.9952, device='cuda:0'))\n",
            "     | > current_lr: 1.525e-05 \n",
            "     | > step_time: 0.3104  (0.31985972208135266)\n",
            "     | > loader_time: 0.0031  (0.004964456838719985)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:49:29 -- STEP: 59/81 -- GLOBAL_STEP: 5000\u001b[0m\n",
            "     | > loss: 0.5153907537460327  (0.6016356035814444)\n",
            "     | > log_mle: -0.1730191707611084  (-0.09530008142277346)\n",
            "     | > loss_dur: 0.6884099245071411  (0.6969356850042181)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(16.1650, device='cuda:0')  (tensor(22.6952, device='cuda:0'))\n",
            "     | > current_lr: 1.525e-05 \n",
            "     | > step_time: 0.4827  (0.3694863885135974)\n",
            "     | > loader_time: 0.0127  (0.005578667430554406)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_5000.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8242998123168945 \u001b[0m(+0.29228949546813965)\n",
            "     | > avg_loss:\u001b[92m 0.5684966444969177 \u001b[0m(-0.04889976978302002)\n",
            "     | > avg_log_mle:\u001b[92m -0.166856050491333 \u001b[0m(-0.03222930431365967)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7353526949882507 \u001b[0m(-0.01667046546936035)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8242998123168945 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5684966444969177 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.166856050491333 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7353526949882507 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5022.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 62/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:50:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:50:10 -- STEP: 3/81 -- GLOBAL_STEP: 5025\u001b[0m\n",
            "     | > loss: 0.518302321434021  (0.578302264213562)\n",
            "     | > log_mle: -0.07136529684066772  (-0.030064165592193604)\n",
            "     | > loss_dur: 0.5896676182746887  (0.6083664298057556)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(10.2751, device='cuda:0')  (tensor(17.9205, device='cuda:0'))\n",
            "     | > current_lr: 1.55e-05 \n",
            "     | > step_time: 0.5355  (0.4847533702850342)\n",
            "     | > loader_time: 0.0026  (0.0030471483866373696)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:50:18 -- STEP: 28/81 -- GLOBAL_STEP: 5050\u001b[0m\n",
            "     | > loss: 0.5910247564315796  (0.5810773606811251)\n",
            "     | > log_mle: -0.06326591968536377  (-0.08843133705002922)\n",
            "     | > loss_dur: 0.6542906761169434  (0.6695086977311543)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(11.1503, device='cuda:0')  (tensor(18.1247, device='cuda:0'))\n",
            "     | > current_lr: 1.55e-05 \n",
            "     | > step_time: 0.305  (0.33896906886781963)\n",
            "     | > loader_time: 0.0077  (0.004975089005061558)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:50:28 -- STEP: 53/81 -- GLOBAL_STEP: 5075\u001b[0m\n",
            "     | > loss: 0.4504556655883789  (0.5988282358871317)\n",
            "     | > log_mle: -0.26883065700531006  (-0.09538402872265508)\n",
            "     | > loss_dur: 0.719286322593689  (0.6942122646097867)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(87.3920, device='cuda:0')  (tensor(20.3456, device='cuda:0'))\n",
            "     | > current_lr: 1.55e-05 \n",
            "     | > step_time: 0.4801  (0.3553526221581225)\n",
            "     | > loader_time: 0.0028  (0.00513440707944474)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:50:40 -- STEP: 78/81 -- GLOBAL_STEP: 5100\u001b[0m\n",
            "     | > loss: 0.49037349224090576  (0.5871177170521175)\n",
            "     | > log_mle: -0.4396333694458008  (-0.10428857879760937)\n",
            "     | > loss_dur: 0.9300068616867065  (0.6914062962318079)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(104.1886, device='cuda:0')  (tensor(24.8949, device='cuda:0'))\n",
            "     | > current_lr: 1.55e-05 \n",
            "     | > step_time: 0.5808  (0.3966379685279651)\n",
            "     | > loader_time: 0.0031  (0.005358035747821513)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9484102725982666 \u001b[0m(+0.12411046028137207)\n",
            "     | > avg_loss:\u001b[91m 0.5783194303512573 \u001b[0m(+0.0098227858543396)\n",
            "     | > avg_log_mle:\u001b[92m -0.1681675910949707 \u001b[0m(-0.0013115406036376953)\n",
            "     | > avg_loss_dur:\u001b[91m 0.746487021446228 \u001b[0m(+0.011134326457977295)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.9484102725982666 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5783194303512573 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.1681675910949707 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.746487021446228 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 63/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:50:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:51:07 -- STEP: 22/81 -- GLOBAL_STEP: 5125\u001b[0m\n",
            "     | > loss: 0.6607736349105835  (0.586484968662262)\n",
            "     | > log_mle: -0.17042112350463867  (-0.07340609756383028)\n",
            "     | > loss_dur: 0.8311947584152222  (0.6598910662260922)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.8115, device='cuda:0')  (tensor(19.9386, device='cuda:0'))\n",
            "     | > current_lr: 1.575e-05 \n",
            "     | > step_time: 0.4404  (0.333415302363309)\n",
            "     | > loader_time: 0.0088  (0.004101168025623668)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:51:18 -- STEP: 47/81 -- GLOBAL_STEP: 5150\u001b[0m\n",
            "     | > loss: 0.5710736513137817  (0.6019068652010979)\n",
            "     | > log_mle: -0.17056262493133545  (-0.08934076415731552)\n",
            "     | > loss_dur: 0.7416362762451172  (0.6912476293584136)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(70.5130, device='cuda:0')  (tensor(22.0925, device='cuda:0'))\n",
            "     | > current_lr: 1.575e-05 \n",
            "     | > step_time: 0.3029  (0.38248004811875363)\n",
            "     | > loader_time: 0.003  (0.004341024033566736)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:51:26 -- STEP: 72/81 -- GLOBAL_STEP: 5175\u001b[0m\n",
            "     | > loss: 0.5536949634552002  (0.5855530806713634)\n",
            "     | > log_mle: -0.1342829465866089  (-0.09916223171684477)\n",
            "     | > loss_dur: 0.6879779100418091  (0.6847153123882083)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(11.9440, device='cuda:0')  (tensor(25.2112, device='cuda:0'))\n",
            "     | > current_lr: 1.575e-05 \n",
            "     | > step_time: 0.2999  (0.3512575560145908)\n",
            "     | > loader_time: 0.0056  (0.004343519608179727)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.7660083770751953 \u001b[0m(-0.1824018955230713)\n",
            "     | > avg_loss:\u001b[92m 0.5643776655197144 \u001b[0m(-0.013941764831542969)\n",
            "     | > avg_log_mle:\u001b[91m -0.1670217514038086 \u001b[0m(+0.0011458396911621094)\n",
            "     | > avg_loss_dur:\u001b[92m 0.731399416923523 \u001b[0m(-0.015087604522705078)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7660083770751953 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5643776655197144 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.1670217514038086 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.731399416923523 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5184.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 64/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:51:49) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:51:59 -- STEP: 16/81 -- GLOBAL_STEP: 5200\u001b[0m\n",
            "     | > loss: 0.6087416410446167  (0.5802631750702858)\n",
            "     | > log_mle: -0.18211734294891357  (-0.07486725971102715)\n",
            "     | > loss_dur: 0.7908589839935303  (0.6551304347813129)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.6979, device='cuda:0')  (tensor(16.9006, device='cuda:0'))\n",
            "     | > current_lr: 1.6e-05 \n",
            "     | > step_time: 0.2945  (0.43284471333026886)\n",
            "     | > loader_time: 0.003  (0.005878329277038574)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:52:07 -- STEP: 41/81 -- GLOBAL_STEP: 5225\u001b[0m\n",
            "     | > loss: 0.515129804611206  (0.5889602041826015)\n",
            "     | > log_mle: -0.1612386703491211  (-0.10600665429743325)\n",
            "     | > loss_dur: 0.6763684749603271  (0.6949668584800348)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(32.2587, device='cuda:0')  (tensor(17.9032, device='cuda:0'))\n",
            "     | > current_lr: 1.6e-05 \n",
            "     | > step_time: 0.2973  (0.35126760529308787)\n",
            "     | > loader_time: 0.0028  (0.004523137720619761)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:52:18 -- STEP: 66/81 -- GLOBAL_STEP: 5250\u001b[0m\n",
            "     | > loss: 0.6283077597618103  (0.5847612005291563)\n",
            "     | > log_mle: -0.012520313262939453  (-0.10572278138363)\n",
            "     | > loss_dur: 0.6408280730247498  (0.6904839823643366)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(14.5640, device='cuda:0')  (tensor(21.1999, device='cuda:0'))\n",
            "     | > current_lr: 1.6e-05 \n",
            "     | > step_time: 0.5597  (0.39057739214463666)\n",
            "     | > loader_time: 0.007  (0.005576585278366551)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9190702438354492 \u001b[0m(+0.1530618667602539)\n",
            "     | > avg_loss:\u001b[92m 0.5401356816291809 \u001b[0m(-0.024241983890533447)\n",
            "     | > avg_log_mle:\u001b[92m -0.1721184253692627 \u001b[0m(-0.0050966739654541016)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7122541069984436 \u001b[0m(-0.019145309925079346)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.9190702438354492 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5401356816291809 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.1721184253692627 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7122541069984436 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5265.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 65/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:52:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:52:55 -- STEP: 10/81 -- GLOBAL_STEP: 5275\u001b[0m\n",
            "     | > loss: 0.4719995856285095  (0.5722383677959442)\n",
            "     | > log_mle: -0.20306718349456787  (-0.07942715287208557)\n",
            "     | > loss_dur: 0.6750667691230774  (0.6516655206680297)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.0641, device='cuda:0')  (tensor(18.5600, device='cuda:0'))\n",
            "     | > current_lr: 1.625e-05 \n",
            "     | > step_time: 0.4542  (0.3626224517822266)\n",
            "     | > loader_time: 0.0035  (0.00439302921295166)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:53:06 -- STEP: 35/81 -- GLOBAL_STEP: 5300\u001b[0m\n",
            "     | > loss: 0.56950443983078  (0.5741465125765117)\n",
            "     | > log_mle: -0.10474395751953125  (-0.10560270547866821)\n",
            "     | > loss_dur: 0.6742483973503113  (0.6797492180551802)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.6153, device='cuda:0')  (tensor(19.7313, device='cuda:0'))\n",
            "     | > current_lr: 1.625e-05 \n",
            "     | > step_time: 0.2949  (0.4259312084742955)\n",
            "     | > loader_time: 0.0049  (0.005189071382795061)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:53:14 -- STEP: 60/81 -- GLOBAL_STEP: 5325\u001b[0m\n",
            "     | > loss: 0.577325701713562  (0.579792174696922)\n",
            "     | > log_mle: 0.06184697151184082  (-0.11487948894500732)\n",
            "     | > loss_dur: 0.5154787302017212  (0.6946716636419297)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(4.6337, device='cuda:0')  (tensor(22.3734, device='cuda:0'))\n",
            "     | > current_lr: 1.625e-05 \n",
            "     | > step_time: 0.3025  (0.3737377683321635)\n",
            "     | > loader_time: 0.0033  (0.004971476395924887)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.9450421333312988 \u001b[0m(+0.02597188949584961)\n",
            "     | > avg_loss:\u001b[91m 0.5768210291862488 \u001b[0m(+0.03668534755706787)\n",
            "     | > avg_log_mle:\u001b[92m -0.18103551864624023 \u001b[0m(-0.008917093276977539)\n",
            "     | > avg_loss_dur:\u001b[91m 0.757856547832489 \u001b[0m(+0.04560244083404541)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.9450421333312988 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5768210291862488 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.18103551864624023 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.757856547832489 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 66/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:53:35) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:53:39 -- STEP: 4/81 -- GLOBAL_STEP: 5350\u001b[0m\n",
            "     | > loss: 0.5672686100006104  (0.579367533326149)\n",
            "     | > log_mle: -0.1777207851409912  (-0.08443135023117065)\n",
            "     | > loss_dur: 0.7449893951416016  (0.6637988835573196)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(25.5455, device='cuda:0')  (tensor(24.1491, device='cuda:0'))\n",
            "     | > current_lr: 1.65e-05 \n",
            "     | > step_time: 0.4249  (0.4478849172592163)\n",
            "     | > loader_time: 0.0037  (0.007772266864776611)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:53:50 -- STEP: 29/81 -- GLOBAL_STEP: 5375\u001b[0m\n",
            "     | > loss: 0.846616268157959  (0.56701090212526)\n",
            "     | > log_mle: -0.15223407745361328  (-0.1138499584691278)\n",
            "     | > loss_dur: 0.9988503456115723  (0.6808608605943877)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(31.8021, device='cuda:0')  (tensor(19.6942, device='cuda:0'))\n",
            "     | > current_lr: 1.65e-05 \n",
            "     | > step_time: 0.3004  (0.4337350582254344)\n",
            "     | > loader_time: 0.0026  (0.005210934014155947)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:53:57 -- STEP: 54/81 -- GLOBAL_STEP: 5400\u001b[0m\n",
            "     | > loss: 0.8069792985916138  (0.5770352493833611)\n",
            "     | > log_mle: -0.2152402400970459  (-0.1199092533853319)\n",
            "     | > loss_dur: 1.0222195386886597  (0.696944503320588)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(69.8504, device='cuda:0')  (tensor(21.6886, device='cuda:0'))\n",
            "     | > current_lr: 1.65e-05 \n",
            "     | > step_time: 0.2897  (0.37093206246693927)\n",
            "     | > loader_time: 0.003  (0.004824457345185455)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:54:08 -- STEP: 79/81 -- GLOBAL_STEP: 5425\u001b[0m\n",
            "     | > loss: 0.4944818615913391  (0.5603269504595406)\n",
            "     | > log_mle: -0.20034468173980713  (-0.12805564494072635)\n",
            "     | > loss_dur: 0.6948265433311462  (0.6883825957775117)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(23.8274, device='cuda:0')  (tensor(24.6679, device='cuda:0'))\n",
            "     | > current_lr: 1.65e-05 \n",
            "     | > step_time: 0.3867  (0.38982866383806064)\n",
            "     | > loader_time: 0.0039  (0.005105552794058112)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.6532309055328369 \u001b[0m(-0.2918112277984619)\n",
            "     | > avg_loss:\u001b[92m 0.5108160376548767 \u001b[0m(-0.06600499153137207)\n",
            "     | > avg_log_mle:\u001b[92m -0.2172762155532837 \u001b[0m(-0.03624069690704346)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7280922532081604 \u001b[0m(-0.029764294624328613)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.6532309055328369 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5108160376548767 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2172762155532837 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7280922532081604 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5427.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 67/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:54:28) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:54:37 -- STEP: 23/81 -- GLOBAL_STEP: 5450\u001b[0m\n",
            "     | > loss: 0.35635656118392944  (0.5550979427669358)\n",
            "     | > log_mle: -0.24476373195648193  (-0.10329817170682161)\n",
            "     | > loss_dur: 0.6011202931404114  (0.6583961144737575)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(52.3660, device='cuda:0')  (tensor(21.3533, device='cuda:0'))\n",
            "     | > current_lr: 1.675e-05 \n",
            "     | > step_time: 0.2998  (0.2939337232838507)\n",
            "     | > loader_time: 0.0055  (0.003703469815461532)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:54:48 -- STEP: 48/81 -- GLOBAL_STEP: 5475\u001b[0m\n",
            "     | > loss: 0.402188241481781  (0.571566908309857)\n",
            "     | > log_mle: -0.20807266235351562  (-0.11560864249865214)\n",
            "     | > loss_dur: 0.6102609038352966  (0.6871755508085092)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(51.4203, device='cuda:0')  (tensor(22.0352, device='cuda:0'))\n",
            "     | > current_lr: 1.675e-05 \n",
            "     | > step_time: 0.4815  (0.3506168425083162)\n",
            "     | > loader_time: 0.003  (0.004818086822827655)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:55:00 -- STEP: 73/81 -- GLOBAL_STEP: 5500\u001b[0m\n",
            "     | > loss: 0.8683421611785889  (0.5602954552598196)\n",
            "     | > log_mle: -0.2388160228729248  (-0.12768740686651778)\n",
            "     | > loss_dur: 1.1071581840515137  (0.6879828621263373)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(27.0208, device='cuda:0')  (tensor(23.8177, device='cuda:0'))\n",
            "     | > current_lr: 1.675e-05 \n",
            "     | > step_time: 0.5952  (0.397090644052584)\n",
            "     | > loader_time: 0.0056  (0.004785622635932817)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1164875030517578 \u001b[0m(+0.4632565975189209)\n",
            "     | > avg_loss:\u001b[91m 0.5344715118408203 \u001b[0m(+0.023655474185943604)\n",
            "     | > avg_log_mle:\u001b[91m -0.20869243144989014 \u001b[0m(+0.008583784103393555)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7431639432907104 \u001b[0m(+0.015071690082550049)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.1164875030517578 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5344715118408203 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.20869243144989014 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7431639432907104 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 68/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:55:19) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:55:27 -- STEP: 17/81 -- GLOBAL_STEP: 5525\u001b[0m\n",
            "     | > loss: 0.548923134803772  (0.5495947914965011)\n",
            "     | > log_mle: -0.115578293800354  (-0.10024633828331442)\n",
            "     | > loss_dur: 0.664501428604126  (0.6498411297798157)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(8.6794, device='cuda:0')  (tensor(19.5104, device='cuda:0'))\n",
            "     | > current_lr: 1.7e-05 \n",
            "     | > step_time: 0.4273  (0.3808427137487075)\n",
            "     | > loader_time: 0.0043  (0.0038300261777990006)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:55:38 -- STEP: 42/81 -- GLOBAL_STEP: 5550\u001b[0m\n",
            "     | > loss: 0.5629193186759949  (0.5625126957893372)\n",
            "     | > log_mle: -0.0897982120513916  (-0.12772950104304723)\n",
            "     | > loss_dur: 0.6527175307273865  (0.6902421968323842)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(15.6031, device='cuda:0')  (tensor(20.0821, device='cuda:0'))\n",
            "     | > current_lr: 1.7e-05 \n",
            "     | > step_time: 0.307  (0.39435875983465285)\n",
            "     | > loader_time: 0.0034  (0.005938439142136346)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:55:46 -- STEP: 67/81 -- GLOBAL_STEP: 5575\u001b[0m\n",
            "     | > loss: 0.524020254611969  (0.5553383889482983)\n",
            "     | > log_mle: -0.13025951385498047  (-0.12959570582233257)\n",
            "     | > loss_dur: 0.6542797684669495  (0.6849340947706307)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(9.7159, device='cuda:0')  (tensor(21.7135, device='cuda:0'))\n",
            "     | > current_lr: 1.7e-05 \n",
            "     | > step_time: 0.4244  (0.3622162840259609)\n",
            "     | > loader_time: 0.0033  (0.00523693170120467)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.828113317489624 \u001b[0m(-0.2883741855621338)\n",
            "     | > avg_loss:\u001b[91m 0.5391901135444641 \u001b[0m(+0.004718601703643799)\n",
            "     | > avg_log_mle:\u001b[91m -0.19158673286437988 \u001b[0m(+0.017105698585510254)\n",
            "     | > avg_loss_dur:\u001b[92m 0.730776846408844 \u001b[0m(-0.012387096881866455)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.828113317489624 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5391901135444641 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.19158673286437988 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.730776846408844 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 69/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:56:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:56:11 -- STEP: 11/81 -- GLOBAL_STEP: 5600\u001b[0m\n",
            "     | > loss: 0.4695875644683838  (0.5350064635276794)\n",
            "     | > log_mle: -0.021361947059631348  (-0.09408177029002797)\n",
            "     | > loss_dur: 0.49094951152801514  (0.6290882338177074)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(33.1751, device='cuda:0')  (tensor(21.9467, device='cuda:0'))\n",
            "     | > current_lr: 1.725e-05 \n",
            "     | > step_time: 0.5064  (0.42881720716303046)\n",
            "     | > loader_time: 0.0027  (0.0038498748432506213)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:56:22 -- STEP: 36/81 -- GLOBAL_STEP: 5625\u001b[0m\n",
            "     | > loss: 0.7054256796836853  (0.5527504450745052)\n",
            "     | > log_mle: -0.1930936574935913  (-0.1296110732687844)\n",
            "     | > loss_dur: 0.8985193371772766  (0.6823615183432897)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(32.1216, device='cuda:0')  (tensor(20.0309, device='cuda:0'))\n",
            "     | > current_lr: 1.725e-05 \n",
            "     | > step_time: 0.4543  (0.42800021833843654)\n",
            "     | > loader_time: 0.0156  (0.004055453671349419)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:56:35 -- STEP: 61/81 -- GLOBAL_STEP: 5650\u001b[0m\n",
            "     | > loss: 0.56646728515625  (0.5574888308517266)\n",
            "     | > log_mle: 0.0026202797889709473  (-0.13381264541969923)\n",
            "     | > loss_dur: 0.563847005367279  (0.6913014762714262)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(4.7509, device='cuda:0')  (tensor(24.0495, device='cuda:0'))\n",
            "     | > current_lr: 1.725e-05 \n",
            "     | > step_time: 0.459  (0.4623602765505431)\n",
            "     | > loader_time: 0.0048  (0.005492597329811972)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5202746391296387 \u001b[0m(-0.30783867835998535)\n",
            "     | > avg_loss:\u001b[92m 0.5091606974601746 \u001b[0m(-0.03002941608428955)\n",
            "     | > avg_log_mle:\u001b[92m -0.20513713359832764 \u001b[0m(-0.013550400733947754)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7142978310585022 \u001b[0m(-0.016479015350341797)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5202746391296387 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5091606974601746 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.20513713359832764 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7142978310585022 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5670.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 70/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:57:02) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:57:06 -- STEP: 5/81 -- GLOBAL_STEP: 5675\u001b[0m\n",
            "     | > loss: 0.5467806458473206  (0.5478243350982666)\n",
            "     | > log_mle: -0.08124983310699463  (-0.1036413311958313)\n",
            "     | > loss_dur: 0.6280304789543152  (0.6514656662940979)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(11.1325, device='cuda:0')  (tensor(19.2274, device='cuda:0'))\n",
            "     | > current_lr: 1.7500000000000002e-05 \n",
            "     | > step_time: 0.5026  (0.3536111354827881)\n",
            "     | > loader_time: 0.0054  (0.0038596153259277343)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:57:17 -- STEP: 30/81 -- GLOBAL_STEP: 5700\u001b[0m\n",
            "     | > loss: 0.6562453508377075  (0.5450623075167337)\n",
            "     | > log_mle: -0.11730039119720459  (-0.13563378055890402)\n",
            "     | > loss_dur: 0.7735457420349121  (0.6806960880756379)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(19.8738, device='cuda:0')  (tensor(21.9621, device='cuda:0'))\n",
            "     | > current_lr: 1.7500000000000002e-05 \n",
            "     | > step_time: 0.4507  (0.4358431180318197)\n",
            "     | > loader_time: 0.0046  (0.004259506861368814)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:57:28 -- STEP: 55/81 -- GLOBAL_STEP: 5725\u001b[0m\n",
            "     | > loss: 0.48919880390167236  (0.5515107442032207)\n",
            "     | > log_mle: -0.058395981788635254  (-0.14014013463800598)\n",
            "     | > loss_dur: 0.5475947856903076  (0.6916508788412268)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(6.7628, device='cuda:0')  (tensor(23.3437, device='cuda:0'))\n",
            "     | > current_lr: 1.7500000000000002e-05 \n",
            "     | > step_time: 0.3069  (0.42403045134110884)\n",
            "     | > loader_time: 0.0039  (0.004479828747836027)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:57:35 -- STEP: 80/81 -- GLOBAL_STEP: 5750\u001b[0m\n",
            "     | > loss: 0.5220768451690674  (0.53838308788836)\n",
            "     | > log_mle: -0.39379072189331055  (-0.15226574316620825)\n",
            "     | > loss_dur: 0.9158675670623779  (0.6906488310545684)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(25.5484, device='cuda:0')  (tensor(24.7469, device='cuda:0'))\n",
            "     | > current_lr: 1.7500000000000002e-05 \n",
            "     | > step_time: 0.2354  (0.3807892262935638)\n",
            "     | > loader_time: 0.0023  (0.004137295484542847)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8489115238189697 \u001b[0m(+0.32863688468933105)\n",
            "     | > avg_loss:\u001b[92m 0.5003061890602112 \u001b[0m(-0.008854508399963379)\n",
            "     | > avg_log_mle:\u001b[92m -0.2320423126220703 \u001b[0m(-0.026905179023742676)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7323485016822815 \u001b[0m(+0.018050670623779297)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8489115238189697 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5003061890602112 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2320423126220703 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7323485016822815 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5751.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 71/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:57:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:58:11 -- STEP: 24/81 -- GLOBAL_STEP: 5775\u001b[0m\n",
            "     | > loss: 0.5965808033943176  (0.5270132770140965)\n",
            "     | > log_mle: -0.1861039400100708  (-0.128380519648393)\n",
            "     | > loss_dur: 0.7826847434043884  (0.6553937966624895)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(20.0675, device='cuda:0')  (tensor(17.2395, device='cuda:0'))\n",
            "     | > current_lr: 1.775e-05 \n",
            "     | > step_time: 0.2965  (0.43465685844421387)\n",
            "     | > loader_time: 0.0041  (0.0038809974988301596)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:58:18 -- STEP: 49/81 -- GLOBAL_STEP: 5800\u001b[0m\n",
            "     | > loss: 0.40881019830703735  (0.542617569164354)\n",
            "     | > log_mle: -0.1694021224975586  (-0.1397707620445563)\n",
            "     | > loss_dur: 0.578212320804596  (0.6823883318171211)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(37.0060, device='cuda:0')  (tensor(21.0419, device='cuda:0'))\n",
            "     | > current_lr: 1.775e-05 \n",
            "     | > step_time: 0.29  (0.36756965092250277)\n",
            "     | > loader_time: 0.0037  (0.003789274059996313)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:58:30 -- STEP: 74/81 -- GLOBAL_STEP: 5825\u001b[0m\n",
            "     | > loss: 0.3738810420036316  (0.5359674136380892)\n",
            "     | > log_mle: -0.19404709339141846  (-0.1508498046849225)\n",
            "     | > loss_dur: 0.56792813539505  (0.6868172187257459)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(25.4768, device='cuda:0')  (tensor(24.1261, device='cuda:0'))\n",
            "     | > current_lr: 1.775e-05 \n",
            "     | > step_time: 0.4239  (0.39930845595694875)\n",
            "     | > loader_time: 0.0026  (0.004804401784329801)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.617762565612793 \u001b[0m(-0.23114895820617676)\n",
            "     | > avg_loss:\u001b[92m 0.4882205128669739 \u001b[0m(-0.012085676193237305)\n",
            "     | > avg_log_mle:\u001b[91m -0.2215946912765503 \u001b[0m(+0.01044762134552002)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7098152041435242 \u001b[0m(-0.022533297538757324)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.617762565612793 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4882205128669739 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2215946912765503 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7098152041435242 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5832.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 72/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:58:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:59:04 -- STEP: 18/81 -- GLOBAL_STEP: 5850\u001b[0m\n",
            "     | > loss: 0.5362695455551147  (0.526292535993788)\n",
            "     | > log_mle: -0.006116211414337158  (-0.117672065893809)\n",
            "     | > loss_dur: 0.5423857569694519  (0.643964601887597)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(2.4583, device='cuda:0')  (tensor(16.1756, device='cuda:0'))\n",
            "     | > current_lr: 1.8e-05 \n",
            "     | > step_time: 0.4945  (0.35085394647386337)\n",
            "     | > loader_time: 0.0037  (0.00423884391784668)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:59:16 -- STEP: 43/81 -- GLOBAL_STEP: 5875\u001b[0m\n",
            "     | > loss: 0.4893226623535156  (0.5405786744383879)\n",
            "     | > log_mle: 0.006566405296325684  (-0.14515529954156212)\n",
            "     | > loss_dur: 0.48275625705718994  (0.68573397397995)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(6.0951, device='cuda:0')  (tensor(20.6010, device='cuda:0'))\n",
            "     | > current_lr: 1.8e-05 \n",
            "     | > step_time: 0.5446  (0.4286921190661053)\n",
            "     | > loader_time: 0.0055  (0.006193920623424442)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 12:59:30 -- STEP: 68/81 -- GLOBAL_STEP: 5900\u001b[0m\n",
            "     | > loss: 0.4634379744529724  (0.5373995365465388)\n",
            "     | > log_mle: -0.14416980743408203  (-0.14785593485130982)\n",
            "     | > loss_dur: 0.6076077818870544  (0.6852554713978487)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(21.8318, device='cuda:0')  (tensor(24.9133, device='cuda:0'))\n",
            "     | > current_lr: 1.8e-05 \n",
            "     | > step_time: 0.508  (0.4779438060872695)\n",
            "     | > loader_time: 0.0043  (0.006457837188945097)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6827025413513184 \u001b[0m(+0.06493997573852539)\n",
            "     | > avg_loss:\u001b[92m 0.46156543493270874 \u001b[0m(-0.026655077934265137)\n",
            "     | > avg_log_mle:\u001b[92m -0.2406548261642456 \u001b[0m(-0.019060134887695312)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7022202610969543 \u001b[0m(-0.007594943046569824)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.6827025413513184 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.46156543493270874 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2406548261642456 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7022202610969543 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_5913.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 73/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 12:59:57) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:00:02 -- STEP: 12/81 -- GLOBAL_STEP: 5925\u001b[0m\n",
            "     | > loss: 0.4358418583869934  (0.5083202968041102)\n",
            "     | > log_mle: -0.3324911594390869  (-0.1398172676563263)\n",
            "     | > loss_dur: 0.7683330178260803  (0.6481375644604365)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(67.9485, device='cuda:0')  (tensor(19.4822, device='cuda:0'))\n",
            "     | > current_lr: 1.825e-05 \n",
            "     | > step_time: 0.3107  (0.3008013168970744)\n",
            "     | > loader_time: 0.0042  (0.0036350488662719727)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:00:11 -- STEP: 37/81 -- GLOBAL_STEP: 5950\u001b[0m\n",
            "     | > loss: 0.5502529740333557  (0.52891271984255)\n",
            "     | > log_mle: -0.2579606771469116  (-0.1581419335829245)\n",
            "     | > loss_dur: 0.8082136511802673  (0.6870546534254744)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.1587, device='cuda:0')  (tensor(21.0772, device='cuda:0'))\n",
            "     | > current_lr: 1.825e-05 \n",
            "     | > step_time: 0.4641  (0.33625421008548223)\n",
            "     | > loader_time: 0.0041  (0.0038212634421683645)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:00:22 -- STEP: 62/81 -- GLOBAL_STEP: 5975\u001b[0m\n",
            "     | > loss: 0.48769813776016235  (0.533053123181866)\n",
            "     | > log_mle: -0.11626529693603516  (-0.1574798428243206)\n",
            "     | > loss_dur: 0.6039634346961975  (0.6905329660061867)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(15.0575, device='cuda:0')  (tensor(23.8308, device='cuda:0'))\n",
            "     | > current_lr: 1.825e-05 \n",
            "     | > step_time: 0.3093  (0.36791942581053705)\n",
            "     | > loader_time: 0.0031  (0.004662179177807225)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5730867385864258 \u001b[0m(-0.10961580276489258)\n",
            "     | > avg_loss:\u001b[91m 0.5126859545707703 \u001b[0m(+0.05112051963806152)\n",
            "     | > avg_log_mle:\u001b[91m -0.22962450981140137 \u001b[0m(+0.011030316352844238)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7423104643821716 \u001b[0m(+0.040090203285217285)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5730867385864258 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.5126859545707703 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.22962450981140137 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7423104643821716 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 74/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:00:46) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:00:50 -- STEP: 6/81 -- GLOBAL_STEP: 6000\u001b[0m\n",
            "     | > loss: 0.5252236127853394  (0.530604898929596)\n",
            "     | > log_mle: -0.17595314979553223  (-0.1286189059416453)\n",
            "     | > loss_dur: 0.7011767625808716  (0.6592238048712412)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(16.7131, device='cuda:0')  (tensor(19.5995, device='cuda:0'))\n",
            "     | > current_lr: 1.8500000000000002e-05 \n",
            "     | > step_time: 0.2908  (0.2961108684539795)\n",
            "     | > loader_time: 0.0029  (0.0033479928970336914)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_6000.pth\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:01:05 -- STEP: 31/81 -- GLOBAL_STEP: 6025\u001b[0m\n",
            "     | > loss: 0.5507819056510925  (0.5262175663825005)\n",
            "     | > log_mle: -0.08832645416259766  (-0.1517474516745537)\n",
            "     | > loss_dur: 0.6391083598136902  (0.6779650180570541)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(13.4247, device='cuda:0')  (tensor(20.7139, device='cuda:0'))\n",
            "     | > current_lr: 1.8500000000000002e-05 \n",
            "     | > step_time: 0.4595  (0.40353808864470453)\n",
            "     | > loader_time: 0.0049  (0.004810317870109312)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:01:14 -- STEP: 56/81 -- GLOBAL_STEP: 6050\u001b[0m\n",
            "     | > loss: 0.4595528244972229  (0.5282024373965608)\n",
            "     | > log_mle: -0.28703129291534424  (-0.16160863850797927)\n",
            "     | > loss_dur: 0.7465841174125671  (0.6898110759045395)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(30.1815, device='cuda:0')  (tensor(23.6930, device='cuda:0'))\n",
            "     | > current_lr: 1.8500000000000002e-05 \n",
            "     | > step_time: 0.2978  (0.37113119448934284)\n",
            "     | > loader_time: 0.0048  (0.004534861871174405)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8096208572387695 \u001b[0m(+0.23653411865234375)\n",
            "     | > avg_loss:\u001b[92m 0.4779788851737976 \u001b[0m(-0.034707069396972656)\n",
            "     | > avg_log_mle:\u001b[92m -0.23819351196289062 \u001b[0m(-0.008569002151489258)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7161723971366882 \u001b[0m(-0.0261380672454834)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8096208572387695 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4779788851737976 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.23819351196289062 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7161723971366882 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 75/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:01:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:01:42 -- STEP: 0/81 -- GLOBAL_STEP: 6075\u001b[0m\n",
            "     | > loss: 0.557645857334137  (0.557645857334137)\n",
            "     | > log_mle: -0.004896879196166992  (-0.004896879196166992)\n",
            "     | > loss_dur: 0.562542736530304  (0.562542736530304)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(4.8859, device='cuda:0')  (tensor(4.8859, device='cuda:0'))\n",
            "     | > current_lr: 1.875e-05 \n",
            "     | > step_time: 0.8712  (0.871196985244751)\n",
            "     | > loader_time: 1.46  (1.459963321685791)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:01:53 -- STEP: 25/81 -- GLOBAL_STEP: 6100\u001b[0m\n",
            "     | > loss: 0.4494989514350891  (0.5058609199523926)\n",
            "     | > log_mle: -0.16335082054138184  (-0.1495474672317505)\n",
            "     | > loss_dur: 0.612849771976471  (0.6554083871841431)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(19.3356, device='cuda:0')  (tensor(19.9269, device='cuda:0'))\n",
            "     | > current_lr: 1.875e-05 \n",
            "     | > step_time: 0.2963  (0.43362113952636716)\n",
            "     | > loader_time: 0.0037  (0.004332056045532226)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:02:01 -- STEP: 50/81 -- GLOBAL_STEP: 6125\u001b[0m\n",
            "     | > loss: 0.6940327286720276  (0.5282204848527907)\n",
            "     | > log_mle: -0.24766898155212402  (-0.16017263174057006)\n",
            "     | > loss_dur: 0.9417017102241516  (0.6883931165933609)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(30.7905, device='cuda:0')  (tensor(20.8572, device='cuda:0'))\n",
            "     | > current_lr: 1.875e-05 \n",
            "     | > step_time: 0.2952  (0.3654640817642212)\n",
            "     | > loader_time: 0.003  (0.00444911479949951)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:02:12 -- STEP: 75/81 -- GLOBAL_STEP: 6150\u001b[0m\n",
            "     | > loss: 0.39842450618743896  (0.5132106657822927)\n",
            "     | > log_mle: -0.1709752082824707  (-0.17092478513717652)\n",
            "     | > loss_dur: 0.5693997144699097  (0.6841354509194691)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(20.4536, device='cuda:0')  (tensor(23.2778, device='cuda:0'))\n",
            "     | > current_lr: 1.875e-05 \n",
            "     | > step_time: 0.4184  (0.3892169539133708)\n",
            "     | > loader_time: 0.0031  (0.004863042831420896)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5980184078216553 \u001b[0m(-0.21160244941711426)\n",
            "     | > avg_loss:\u001b[91m 0.48650288581848145 \u001b[0m(+0.008524000644683838)\n",
            "     | > avg_log_mle:\u001b[91m -0.23606181144714355 \u001b[0m(+0.0021317005157470703)\n",
            "     | > avg_loss_dur:\u001b[91m 0.722564697265625 \u001b[0m(+0.006392300128936768)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5980184078216553 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.48650288581848145 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.23606181144714355 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.722564697265625 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 76/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:02:26) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:02:40 -- STEP: 19/81 -- GLOBAL_STEP: 6175\u001b[0m\n",
            "     | > loss: 0.43008315563201904  (0.5004406006712663)\n",
            "     | > log_mle: -0.16100668907165527  (-0.14073548818889417)\n",
            "     | > loss_dur: 0.5910898447036743  (0.6411760888601603)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(26.2677, device='cuda:0')  (tensor(16.8591, device='cuda:0'))\n",
            "     | > current_lr: 1.8999999999999998e-05 \n",
            "     | > step_time: 0.2912  (0.40000462532043457)\n",
            "     | > loader_time: 0.0036  (0.007263221238788806)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:02:48 -- STEP: 44/81 -- GLOBAL_STEP: 6200\u001b[0m\n",
            "     | > loss: 0.5606496334075928  (0.5209721008485014)\n",
            "     | > log_mle: -0.14071524143218994  (-0.16477641327814616)\n",
            "     | > loss_dur: 0.7013648748397827  (0.6857485141266475)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.6744, device='cuda:0')  (tensor(21.4335, device='cuda:0'))\n",
            "     | > current_lr: 1.8999999999999998e-05 \n",
            "     | > step_time: 0.4004  (0.3602322285825556)\n",
            "     | > loader_time: 0.0032  (0.005726012316617099)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:02:59 -- STEP: 69/81 -- GLOBAL_STEP: 6225\u001b[0m\n",
            "     | > loss: 0.45257025957107544  (0.5132926387199458)\n",
            "     | > log_mle: -0.3967103958129883  (-0.1734023491541544)\n",
            "     | > loss_dur: 0.8492806553840637  (0.6866949878741002)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(32.7291, device='cuda:0')  (tensor(22.2759, device='cuda:0'))\n",
            "     | > current_lr: 1.8999999999999998e-05 \n",
            "     | > step_time: 0.3199  (0.38758068844891974)\n",
            "     | > loader_time: 0.0047  (0.005524431449779566)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5823802947998047 \u001b[0m(-0.015638113021850586)\n",
            "     | > avg_loss:\u001b[92m 0.4849185347557068 \u001b[0m(-0.0015843510627746582)\n",
            "     | > avg_log_mle:\u001b[92m -0.2406705617904663 \u001b[0m(-0.004608750343322754)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7255890965461731 \u001b[0m(+0.0030243992805480957)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5823802947998047 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4849185347557068 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2406705617904663 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7255890965461731 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 77/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:03:18) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:03:24 -- STEP: 13/81 -- GLOBAL_STEP: 6250\u001b[0m\n",
            "     | > loss: 0.48529958724975586  (0.489693650832543)\n",
            "     | > log_mle: -0.14047348499298096  (-0.1550261011490455)\n",
            "     | > loss_dur: 0.6257730722427368  (0.6447197519815885)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.0953, device='cuda:0')  (tensor(20.6849, device='cuda:0'))\n",
            "     | > current_lr: 1.925e-05 \n",
            "     | > step_time: 0.3049  (0.295882536814763)\n",
            "     | > loader_time: 0.004  (0.003750782746535081)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:03:33 -- STEP: 38/81 -- GLOBAL_STEP: 6275\u001b[0m\n",
            "     | > loss: 0.5921537280082703  (0.5131681483042868)\n",
            "     | > log_mle: -0.17773950099945068  (-0.17531439034562363)\n",
            "     | > loss_dur: 0.769893229007721  (0.6884825386499104)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(16.6696, device='cuda:0')  (tensor(21.2798, device='cuda:0'))\n",
            "     | > current_lr: 1.925e-05 \n",
            "     | > step_time: 0.4338  (0.32179717013710424)\n",
            "     | > loader_time: 0.0049  (0.004960160506399054)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:03:45 -- STEP: 63/81 -- GLOBAL_STEP: 6300\u001b[0m\n",
            "     | > loss: 0.41122472286224365  (0.5088608279114678)\n",
            "     | > log_mle: -0.26556313037872314  (-0.1783889446939741)\n",
            "     | > loss_dur: 0.6767878532409668  (0.6872497726054418)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(35.9072, device='cuda:0')  (tensor(22.1599, device='cuda:0'))\n",
            "     | > current_lr: 1.925e-05 \n",
            "     | > step_time: 0.2944  (0.37960195541381836)\n",
            "     | > loader_time: 0.0032  (0.005190266503228081)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5691027641296387 \u001b[0m(-0.013277530670166016)\n",
            "     | > avg_loss:\u001b[92m 0.46708840131759644 \u001b[0m(-0.01783013343811035)\n",
            "     | > avg_log_mle:\u001b[92m -0.2575129270553589 \u001b[0m(-0.016842365264892578)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7246013283729553 \u001b[0m(-0.0009877681732177734)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5691027641296387 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.46708840131759644 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2575129270553589 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7246013283729553 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 78/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:04:06) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:04:09 -- STEP: 7/81 -- GLOBAL_STEP: 6325\u001b[0m\n",
            "     | > loss: 0.4652789831161499  (0.505459189414978)\n",
            "     | > log_mle: -0.12246406078338623  (-0.14690823214394705)\n",
            "     | > loss_dur: 0.5877430438995361  (0.6523674215589251)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(11.0230, device='cuda:0')  (tensor(21.1445, device='cuda:0'))\n",
            "     | > current_lr: 1.95e-05 \n",
            "     | > step_time: 0.2872  (0.3011829512459891)\n",
            "     | > loader_time: 0.0034  (0.003611189978463309)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:04:19 -- STEP: 32/81 -- GLOBAL_STEP: 6350\u001b[0m\n",
            "     | > loss: 0.4057871699333191  (0.4920396711677313)\n",
            "     | > log_mle: -0.3109550476074219  (-0.17645209655165672)\n",
            "     | > loss_dur: 0.716742217540741  (0.668491767719388)\n",
            "     | > amp_scaler: 8192.0  (5888.0)\n",
            "     | > grad_norm: tensor(37.5252, device='cuda:0')  (tensor(23.6579, device='cuda:0'))\n",
            "     | > current_lr: 1.95e-05 \n",
            "     | > step_time: 0.4345  (0.3569868579506874)\n",
            "     | > loader_time: 0.0053  (0.004722259938716888)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:04:29 -- STEP: 57/81 -- GLOBAL_STEP: 6375\u001b[0m\n",
            "     | > loss: 0.32968056201934814  (0.5015299131995754)\n",
            "     | > log_mle: -0.4550734758377075  (-0.18683729569117236)\n",
            "     | > loss_dur: 0.7847540378570557  (0.6883672088907473)\n",
            "     | > amp_scaler: 8192.0  (6898.526315789473)\n",
            "     | > grad_norm: tensor(51.9016, device='cuda:0')  (tensor(24.1277, device='cuda:0'))\n",
            "     | > current_lr: 1.95e-05 \n",
            "     | > step_time: 0.2946  (0.3753519434677927)\n",
            "     | > loader_time: 0.0025  (0.005256268016079016)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.880413293838501 \u001b[0m(+0.3113105297088623)\n",
            "     | > avg_loss:\u001b[92m 0.45935922861099243 \u001b[0m(-0.007729172706604004)\n",
            "     | > avg_log_mle:\u001b[92m -0.26331865787506104 \u001b[0m(-0.0058057308197021484)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7226778864860535 \u001b[0m(-0.0019234418869018555)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.880413293838501 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.45935922861099243 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.26331865787506104 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7226778864860535 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_6399.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 79/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:05:03) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:05:06 -- STEP: 1/81 -- GLOBAL_STEP: 6400\u001b[0m\n",
            "     | > loss: 0.4778430461883545  (0.4778430461883545)\n",
            "     | > log_mle: -0.1826397180557251  (-0.1826397180557251)\n",
            "     | > loss_dur: 0.6604827642440796  (0.6604827642440796)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(27.0417, device='cuda:0')  (tensor(27.0417, device='cuda:0'))\n",
            "     | > current_lr: 1.975e-05 \n",
            "     | > step_time: 0.4632  (0.4632091522216797)\n",
            "     | > loader_time: 0.0058  (0.005816221237182617)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:05:16 -- STEP: 26/81 -- GLOBAL_STEP: 6425\u001b[0m\n",
            "     | > loss: 0.4169541001319885  (0.48347306136901563)\n",
            "     | > log_mle: -0.3276728391647339  (-0.17441691343600935)\n",
            "     | > loss_dur: 0.7446269392967224  (0.657889974805025)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(42.2873, device='cuda:0')  (tensor(19.4613, device='cuda:0'))\n",
            "     | > current_lr: 1.975e-05 \n",
            "     | > step_time: 0.2839  (0.391426288164579)\n",
            "     | > loader_time: 0.0029  (0.0053250697942880485)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:05:24 -- STEP: 51/81 -- GLOBAL_STEP: 6450\u001b[0m\n",
            "     | > loss: 0.39909523725509644  (0.500030045415841)\n",
            "     | > log_mle: -0.25552642345428467  (-0.18336033236746693)\n",
            "     | > loss_dur: 0.6546216607093811  (0.6833903777833078)\n",
            "     | > amp_scaler: 8192.0  (8192.0)\n",
            "     | > grad_norm: tensor(20.3154, device='cuda:0')  (tensor(19.9725, device='cuda:0'))\n",
            "     | > current_lr: 1.975e-05 \n",
            "     | > step_time: 0.4445  (0.35480621281792135)\n",
            "     | > loader_time: 0.0158  (0.0049130262113085)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:05:35 -- STEP: 76/81 -- GLOBAL_STEP: 6475\u001b[0m\n",
            "     | > loss: 0.462396502494812  (0.4894994658074881)\n",
            "     | > log_mle: -0.29669785499572754  (-0.19061650492643054)\n",
            "     | > loss_dur: 0.7590943574905396  (0.6801159707339187)\n",
            "     | > amp_scaler: 4096.0  (7114.105263157895)\n",
            "     | > grad_norm: tensor(60.4389, device='cuda:0')  (tensor(24.0262, device='cuda:0'))\n",
            "     | > current_lr: 1.975e-05 \n",
            "     | > step_time: 0.2285  (0.375419767279374)\n",
            "     | > loader_time: 0.0026  (0.005905957598435253)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5987939834594727 \u001b[0m(-0.2816193103790283)\n",
            "     | > avg_loss:\u001b[92m 0.4308900237083435 \u001b[0m(-0.028469204902648926)\n",
            "     | > avg_log_mle:\u001b[92m -0.2664400339126587 \u001b[0m(-0.0031213760375976562)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6973300576210022 \u001b[0m(-0.02534782886505127)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5987939834594727 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4308900237083435 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2664400339126587 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.6973300576210022 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_6480.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 80/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:05:58) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:06:06 -- STEP: 20/81 -- GLOBAL_STEP: 6500\u001b[0m\n",
            "     | > loss: 0.5839070081710815  (0.48234237134456637)\n",
            "     | > log_mle: -0.15420937538146973  (-0.15444134473800658)\n",
            "     | > loss_dur: 0.7381163835525513  (0.6367837160825729)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(16.3874, device='cuda:0')  (tensor(19.4776, device='cuda:0'))\n",
            "     | > current_lr: 1.9999999999999998e-05 \n",
            "     | > step_time: 0.3463  (0.29816092252731324)\n",
            "     | > loader_time: 0.0029  (0.003831362724304199)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:06:18 -- STEP: 45/81 -- GLOBAL_STEP: 6525\u001b[0m\n",
            "     | > loss: 0.6165473461151123  (0.4963841246234046)\n",
            "     | > log_mle: -0.08235907554626465  (-0.1788840201165941)\n",
            "     | > loss_dur: 0.698906421661377  (0.6752681447399987)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(9.5983, device='cuda:0')  (tensor(22.3358, device='cuda:0'))\n",
            "     | > current_lr: 1.9999999999999998e-05 \n",
            "     | > step_time: 0.2931  (0.38491600884331606)\n",
            "     | > loader_time: 0.003  (0.004896921581692165)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:06:25 -- STEP: 70/81 -- GLOBAL_STEP: 6550\u001b[0m\n",
            "     | > loss: 0.4878884553909302  (0.4863313892057964)\n",
            "     | > log_mle: -0.05990302562713623  (-0.189100353206907)\n",
            "     | > loss_dur: 0.5477914810180664  (0.6754317424127034)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(5.0132, device='cuda:0')  (tensor(23.7460, device='cuda:0'))\n",
            "     | > current_lr: 1.9999999999999998e-05 \n",
            "     | > step_time: 0.2892  (0.3519400051661901)\n",
            "     | > loader_time: 0.0042  (0.0046297141483851835)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7684690952301025 \u001b[0m(+0.16967511177062988)\n",
            "     | > avg_loss:\u001b[91m 0.45394718647003174 \u001b[0m(+0.023057162761688232)\n",
            "     | > avg_log_mle:\u001b[91m -0.25498735904693604 \u001b[0m(+0.011452674865722656)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7089345455169678 \u001b[0m(+0.011604487895965576)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7684690952301025 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.45394718647003174 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.25498735904693604 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7089345455169678 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 81/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:06:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:06:50 -- STEP: 14/81 -- GLOBAL_STEP: 6575\u001b[0m\n",
            "     | > loss: 0.5865172743797302  (0.47448394554001944)\n",
            "     | > log_mle: -0.011715173721313477  (-0.1609803863934108)\n",
            "     | > loss_dur: 0.5982324481010437  (0.6354643319334302)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(3.0694, device='cuda:0')  (tensor(23.6351, device='cuda:0'))\n",
            "     | > current_lr: 2.025e-05 \n",
            "     | > step_time: 0.4752  (0.32994469574519564)\n",
            "     | > loader_time: 0.0049  (0.005272558757237026)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:07:01 -- STEP: 39/81 -- GLOBAL_STEP: 6600\u001b[0m\n",
            "     | > loss: 0.39062196016311646  (0.48445746990350574)\n",
            "     | > log_mle: -0.2798182964324951  (-0.19536087757501847)\n",
            "     | > loss_dur: 0.6704402565956116  (0.6798183474785242)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(22.8887, device='cuda:0')  (tensor(24.0517, device='cuda:0'))\n",
            "     | > current_lr: 2.025e-05 \n",
            "     | > step_time: 0.2818  (0.3964679974776048)\n",
            "     | > loader_time: 0.0041  (0.006967306137084958)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:07:08 -- STEP: 64/81 -- GLOBAL_STEP: 6625\u001b[0m\n",
            "     | > loss: 0.4513670802116394  (0.48500771913677454)\n",
            "     | > log_mle: -0.165053129196167  (-0.19559693802148104)\n",
            "     | > loss_dur: 0.6164202094078064  (0.6806046571582555)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.4212, device='cuda:0')  (tensor(25.8773, device='cuda:0'))\n",
            "     | > current_lr: 2.025e-05 \n",
            "     | > step_time: 0.2943  (0.3570888862013817)\n",
            "     | > loader_time: 0.0064  (0.005963403731584547)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.8509125709533691 \u001b[0m(+0.0824434757232666)\n",
            "     | > avg_loss:\u001b[92m 0.43242913484573364 \u001b[0m(-0.021518051624298096)\n",
            "     | > avg_log_mle:\u001b[92m -0.27129971981048584 \u001b[0m(-0.016312360763549805)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7037288546562195 \u001b[0m(-0.005205690860748291)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8509125709533691 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.43242913484573364 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.27129971981048584 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7037288546562195 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 82/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:07:28) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:07:32 -- STEP: 8/81 -- GLOBAL_STEP: 6650\u001b[0m\n",
            "     | > loss: 0.422421395778656  (0.47860967367887497)\n",
            "     | > log_mle: -0.14524781703948975  (-0.1652742326259613)\n",
            "     | > loss_dur: 0.5676692128181458  (0.6438839063048363)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(11.3612, device='cuda:0')  (tensor(16.5542, device='cuda:0'))\n",
            "     | > current_lr: 2.05e-05 \n",
            "     | > step_time: 0.4516  (0.36138609051704407)\n",
            "     | > loader_time: 0.0025  (0.003144592046737671)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:07:43 -- STEP: 33/81 -- GLOBAL_STEP: 6675\u001b[0m\n",
            "     | > loss: 0.5144765973091125  (0.47548023679039697)\n",
            "     | > log_mle: -0.19244873523712158  (-0.19753295002561627)\n",
            "     | > loss_dur: 0.7069253325462341  (0.6730131868160133)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(26.1110, device='cuda:0')  (tensor(22.2549, device='cuda:0'))\n",
            "     | > current_lr: 2.05e-05 \n",
            "     | > step_time: 0.2927  (0.41289229104013153)\n",
            "     | > loader_time: 0.0026  (0.005155173214999113)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:07:51 -- STEP: 58/81 -- GLOBAL_STEP: 6700\u001b[0m\n",
            "     | > loss: 0.5279111862182617  (0.48004417172793684)\n",
            "     | > log_mle: -0.1682189702987671  (-0.2079231595170909)\n",
            "     | > loss_dur: 0.6961301565170288  (0.6879673312450277)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(18.2402, device='cuda:0')  (tensor(26.1267, device='cuda:0'))\n",
            "     | > current_lr: 2.05e-05 \n",
            "     | > step_time: 0.2864  (0.3615586099953487)\n",
            "     | > loader_time: 0.0038  (0.004721242806007121)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.117353916168213 \u001b[0m(+0.26644134521484375)\n",
            "     | > avg_loss:\u001b[91m 0.449001669883728 \u001b[0m(+0.016572535037994385)\n",
            "     | > avg_log_mle:\u001b[91m -0.2627671957015991 \u001b[0m(+0.008532524108886719)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7117688655853271 \u001b[0m(+0.008040010929107666)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.117353916168213 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.449001669883728 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2627671957015991 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7117688655853271 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 83/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:08:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:08:19 -- STEP: 2/81 -- GLOBAL_STEP: 6725\u001b[0m\n",
            "     | > loss: 0.544690728187561  (0.5192901790142059)\n",
            "     | > log_mle: -0.04171568155288696  (-0.11727938055992126)\n",
            "     | > loss_dur: 0.586406409740448  (0.6365695595741272)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(4.4598, device='cuda:0')  (tensor(24.4505, device='cuda:0'))\n",
            "     | > current_lr: 2.075e-05 \n",
            "     | > step_time: 0.4385  (0.4581352472305298)\n",
            "     | > loader_time: 0.0033  (0.0035588741302490234)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:08:29 -- STEP: 27/81 -- GLOBAL_STEP: 6750\u001b[0m\n",
            "     | > loss: 0.4144803285598755  (0.45563937226931256)\n",
            "     | > log_mle: -0.3431049585342407  (-0.19650242946766042)\n",
            "     | > loss_dur: 0.7575852870941162  (0.652141801736973)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(25.7945, device='cuda:0')  (tensor(22.0968, device='cuda:0'))\n",
            "     | > current_lr: 2.075e-05 \n",
            "     | > step_time: 0.3061  (0.39661034831294306)\n",
            "     | > loader_time: 0.0073  (0.00584386013172291)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:08:37 -- STEP: 52/81 -- GLOBAL_STEP: 6775\u001b[0m\n",
            "     | > loss: 0.3849549889564514  (0.4758035901647348)\n",
            "     | > log_mle: -0.18913698196411133  (-0.19972502153653365)\n",
            "     | > loss_dur: 0.5740919709205627  (0.6755286117012684)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(8.3885, device='cuda:0')  (tensor(21.2705, device='cuda:0'))\n",
            "     | > current_lr: 2.075e-05 \n",
            "     | > step_time: 0.4476  (0.35742220053305995)\n",
            "     | > loader_time: 0.0031  (0.005150840832636906)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:08:50 -- STEP: 77/81 -- GLOBAL_STEP: 6800\u001b[0m\n",
            "     | > loss: 0.3927341401576996  (0.4682962519007844)\n",
            "     | > log_mle: -0.10012495517730713  (-0.2075833051235645)\n",
            "     | > loss_dur: 0.4928590953350067  (0.6758795570243489)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(7.7881, device='cuda:0')  (tensor(23.6844, device='cuda:0'))\n",
            "     | > current_lr: 2.075e-05 \n",
            "     | > step_time: 0.3362  (0.3968891633021367)\n",
            "     | > loader_time: 0.003  (0.005753086758898449)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8845841884613037 \u001b[0m(-0.23276972770690918)\n",
            "     | > avg_loss:\u001b[92m 0.4450787901878357 \u001b[0m(-0.003922879695892334)\n",
            "     | > avg_log_mle:\u001b[92m -0.2730107307434082 \u001b[0m(-0.010243535041809082)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7180895209312439 \u001b[0m(+0.006320655345916748)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8845841884613037 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4450787901878357 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2730107307434082 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7180895209312439 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 84/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:09:08) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:09:17 -- STEP: 21/81 -- GLOBAL_STEP: 6825\u001b[0m\n",
            "     | > loss: 0.46920740604400635  (0.4551034995487758)\n",
            "     | > log_mle: -0.22939908504486084  (-0.18048439423243204)\n",
            "     | > loss_dur: 0.6986064910888672  (0.6355878937812078)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(15.1005, device='cuda:0')  (tensor(16.9264, device='cuda:0'))\n",
            "     | > current_lr: 2.1e-05 \n",
            "     | > step_time: 0.2853  (0.29822007815043133)\n",
            "     | > loader_time: 0.0044  (0.003401517868041992)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:09:26 -- STEP: 46/81 -- GLOBAL_STEP: 6850\u001b[0m\n",
            "     | > loss: 0.6837072372436523  (0.4732663054829058)\n",
            "     | > log_mle: -0.02872699499130249  (-0.2001753138459247)\n",
            "     | > loss_dur: 0.7124342322349548  (0.6734416193288305)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(13.2915, device='cuda:0')  (tensor(22.1372, device='cuda:0'))\n",
            "     | > current_lr: 2.1e-05 \n",
            "     | > step_time: 0.4905  (0.3332506314567899)\n",
            "     | > loader_time: 0.0038  (0.003961879274119502)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:09:36 -- STEP: 71/81 -- GLOBAL_STEP: 6875\u001b[0m\n",
            "     | > loss: 0.3649529814720154  (0.4613555438921485)\n",
            "     | > log_mle: -0.2725214958190918  (-0.2116906945134552)\n",
            "     | > loss_dur: 0.6374744772911072  (0.6730462384056037)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(53.2065, device='cuda:0')  (tensor(27.9743, device='cuda:0'))\n",
            "     | > current_lr: 2.1e-05 \n",
            "     | > step_time: 0.3052  (0.35099253855960477)\n",
            "     | > loader_time: 0.0032  (0.00420362177029462)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5262258052825928 \u001b[0m(-0.35835838317871094)\n",
            "     | > avg_loss:\u001b[92m 0.43364208936691284 \u001b[0m(-0.011436700820922852)\n",
            "     | > avg_log_mle:\u001b[92m -0.27538514137268066 \u001b[0m(-0.002374410629272461)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7090272307395935 \u001b[0m(-0.00906229019165039)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5262258052825928 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.43364208936691284 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.27538514137268066 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7090272307395935 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 85/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:09:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:10:01 -- STEP: 15/81 -- GLOBAL_STEP: 6900\u001b[0m\n",
            "     | > loss: 0.43802136182785034  (0.4538830439249674)\n",
            "     | > log_mle: -0.12200474739074707  (-0.1800985058148702)\n",
            "     | > loss_dur: 0.5600261092185974  (0.6339815497398377)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(11.0908, device='cuda:0')  (tensor(17.5470, device='cuda:0'))\n",
            "     | > current_lr: 2.125e-05 \n",
            "     | > step_time: 0.2979  (0.29609662691752103)\n",
            "     | > loader_time: 0.0039  (0.003843291600545247)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:10:11 -- STEP: 40/81 -- GLOBAL_STEP: 6925\u001b[0m\n",
            "     | > loss: 0.6748330593109131  (0.470077183842659)\n",
            "     | > log_mle: -0.07553380727767944  (-0.20927894115447998)\n",
            "     | > loss_dur: 0.7503668665885925  (0.6793561249971389)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(3.9605, device='cuda:0')  (tensor(21.5897, device='cuda:0'))\n",
            "     | > current_lr: 2.125e-05 \n",
            "     | > step_time: 0.6909  (0.37409953474998464)\n",
            "     | > loader_time: 0.0142  (0.004851675033569337)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:10:21 -- STEP: 65/81 -- GLOBAL_STEP: 6950\u001b[0m\n",
            "     | > loss: 0.3597791790962219  (0.45899339180726273)\n",
            "     | > log_mle: -0.15742433071136475  (-0.2143497347831726)\n",
            "     | > loss_dur: 0.5172035098075867  (0.6733431265904353)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.2116, device='cuda:0')  (tensor(23.4834, device='cuda:0'))\n",
            "     | > current_lr: 2.125e-05 \n",
            "     | > step_time: 0.2965  (0.3746734619140624)\n",
            "     | > loader_time: 0.0034  (0.005470899435190054)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5250334739685059 \u001b[0m(-0.001192331314086914)\n",
            "     | > avg_loss:\u001b[92m 0.41783732175827026 \u001b[0m(-0.015804767608642578)\n",
            "     | > avg_log_mle:\u001b[92m -0.2758435010910034 \u001b[0m(-0.0004583597183227539)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6936808228492737 \u001b[0m(-0.015346407890319824)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5250334739685059 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.41783732175827026 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2758435010910034 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.6936808228492737 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_6966.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 86/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:10:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:10:54 -- STEP: 9/81 -- GLOBAL_STEP: 6975\u001b[0m\n",
            "     | > loss: 0.4763844609260559  (0.4409540560510423)\n",
            "     | > log_mle: -0.09439468383789062  (-0.17817686001459757)\n",
            "     | > loss_dur: 0.5707791447639465  (0.61913091606564)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(20.7134, device='cuda:0')  (tensor(18.4860, device='cuda:0'))\n",
            "     | > current_lr: 2.15e-05 \n",
            "     | > step_time: 0.4944  (0.4602108531528049)\n",
            "     | > loader_time: 0.0033  (0.006339920891655816)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:11:04 -- STEP: 34/81 -- GLOBAL_STEP: 7000\u001b[0m\n",
            "     | > loss: 0.38264936208724976  (0.4457576046971714)\n",
            "     | > log_mle: -0.15854227542877197  (-0.21447102111928604)\n",
            "     | > loss_dur: 0.5411916375160217  (0.6602286258164574)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(14.3625, device='cuda:0')  (tensor(24.9990, device='cuda:0'))\n",
            "     | > current_lr: 2.15e-05 \n",
            "     | > step_time: 0.2837  (0.40715250548194437)\n",
            "     | > loader_time: 0.0047  (0.0051949935800888955)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_7000.pth\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:11:21 -- STEP: 59/81 -- GLOBAL_STEP: 7025\u001b[0m\n",
            "     | > loss: 0.4096065163612366  (0.45134666056956274)\n",
            "     | > log_mle: -0.30489444732666016  (-0.22708339711367076)\n",
            "     | > loss_dur: 0.7145009636878967  (0.6784300576832335)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(25.9296, device='cuda:0')  (tensor(26.4585, device='cuda:0'))\n",
            "     | > current_lr: 2.15e-05 \n",
            "     | > step_time: 0.4969  (0.42487092745506155)\n",
            "     | > loader_time: 0.0136  (0.0059584318581274)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5237364768981934 \u001b[0m(-0.0012969970703125)\n",
            "     | > avg_loss:\u001b[91m 0.4222266674041748 \u001b[0m(+0.004389345645904541)\n",
            "     | > avg_log_mle:\u001b[92m -0.2928459644317627 \u001b[0m(-0.017002463340759277)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7150726318359375 \u001b[0m(+0.02139180898666382)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5237364768981934 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4222266674041748 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2928459644317627 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7150726318359375 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 87/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:11:43) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:11:46 -- STEP: 3/81 -- GLOBAL_STEP: 7050\u001b[0m\n",
            "     | > loss: 0.37961941957473755  (0.4464668035507202)\n",
            "     | > log_mle: -0.200109601020813  (-0.1595716873804728)\n",
            "     | > loss_dur: 0.5797290205955505  (0.606038490931193)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(15.3086, device='cuda:0')  (tensor(24.2783, device='cuda:0'))\n",
            "     | > current_lr: 2.175e-05 \n",
            "     | > step_time: 0.3075  (0.29906002680460614)\n",
            "     | > loader_time: 0.003  (0.0029261112213134766)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:11:53 -- STEP: 28/81 -- GLOBAL_STEP: 7075\u001b[0m\n",
            "     | > loss: 0.4412146210670471  (0.4270090428846223)\n",
            "     | > log_mle: -0.19132709503173828  (-0.21742291109902517)\n",
            "     | > loss_dur: 0.6325417160987854  (0.6444319539836476)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(15.2126, device='cuda:0')  (tensor(21.8665, device='cuda:0'))\n",
            "     | > current_lr: 2.175e-05 \n",
            "     | > step_time: 0.2751  (0.2931626864842006)\n",
            "     | > loader_time: 0.0041  (0.0032676117760794504)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:12:05 -- STEP: 53/81 -- GLOBAL_STEP: 7100\u001b[0m\n",
            "     | > loss: 0.30280596017837524  (0.4468589852441032)\n",
            "     | > log_mle: -0.39398396015167236  (-0.2228654589293138)\n",
            "     | > loss_dur: 0.6967899203300476  (0.6697244441734171)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(80.1707, device='cuda:0')  (tensor(23.0338, device='cuda:0'))\n",
            "     | > current_lr: 2.175e-05 \n",
            "     | > step_time: 0.5008  (0.38070321982761607)\n",
            "     | > loader_time: 0.0043  (0.004561158846009453)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:12:13 -- STEP: 78/81 -- GLOBAL_STEP: 7125\u001b[0m\n",
            "     | > loss: 0.37777429819107056  (0.440825933447251)\n",
            "     | > log_mle: -0.5876617431640625  (-0.23307554462017158)\n",
            "     | > loss_dur: 0.9654360413551331  (0.6739014780674228)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(83.6757, device='cuda:0')  (tensor(25.6019, device='cuda:0'))\n",
            "     | > current_lr: 2.175e-05 \n",
            "     | > step_time: 0.2464  (0.34860474941058034)\n",
            "     | > loader_time: 0.003  (0.004274395795968862)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5553507804870605 \u001b[0m(+0.03161430358886719)\n",
            "     | > avg_loss:\u001b[92m 0.4018446207046509 \u001b[0m(-0.020382046699523926)\n",
            "     | > avg_log_mle:\u001b[92m -0.3097182512283325 \u001b[0m(-0.016872286796569824)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7115628719329834 \u001b[0m(-0.0035097599029541016)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5553507804870605 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4018446207046509 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.3097182512283325 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7115628719329834 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_7128.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 88/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:12:40) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:12:52 -- STEP: 22/81 -- GLOBAL_STEP: 7150\u001b[0m\n",
            "     | > loss: 0.541081964969635  (0.44045521454377606)\n",
            "     | > log_mle: -0.28158342838287354  (-0.1998971700668335)\n",
            "     | > loss_dur: 0.8226653933525085  (0.6403523846106096)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(39.0287, device='cuda:0')  (tensor(23.2927, device='cuda:0'))\n",
            "     | > current_lr: 2.2e-05 \n",
            "     | > step_time: 0.2987  (0.42613998326388275)\n",
            "     | > loader_time: 0.004  (0.00596121224490079)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:13:02 -- STEP: 47/81 -- GLOBAL_STEP: 7175\u001b[0m\n",
            "     | > loss: 0.46929872035980225  (0.4546004146971601)\n",
            "     | > log_mle: -0.2988409996032715  (-0.21514533174798844)\n",
            "     | > loss_dur: 0.7681397199630737  (0.6697457464451484)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(85.5983, device='cuda:0')  (tensor(27.2648, device='cuda:0'))\n",
            "     | > current_lr: 2.2e-05 \n",
            "     | > step_time: 0.5976  (0.41621524729627246)\n",
            "     | > loader_time: 0.0099  (0.005227733165659803)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:13:15 -- STEP: 72/81 -- GLOBAL_STEP: 7200\u001b[0m\n",
            "     | > loss: 0.40895360708236694  (0.4395280136830277)\n",
            "     | > log_mle: -0.26430296897888184  (-0.22732862416240904)\n",
            "     | > loss_dur: 0.6732565760612488  (0.6668566378454367)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(25.8131, device='cuda:0')  (tensor(28.2883, device='cuda:0'))\n",
            "     | > current_lr: 2.2e-05 \n",
            "     | > step_time: 0.3264  (0.4440040952629513)\n",
            "     | > loader_time: 0.005  (0.005676716566085815)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.6175990104675293 \u001b[0m(+0.06224822998046875)\n",
            "     | > avg_loss:\u001b[91m 0.43170368671417236 \u001b[0m(+0.029859066009521484)\n",
            "     | > avg_log_mle:\u001b[91m -0.2835181951522827 \u001b[0m(+0.026200056076049805)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7152218818664551 \u001b[0m(+0.0036590099334716797)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.6175990104675293 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.43170368671417236 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2835181951522827 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7152218818664551 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 89/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:13:30) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:13:39 -- STEP: 16/81 -- GLOBAL_STEP: 7225\u001b[0m\n",
            "     | > loss: 0.4349339008331299  (0.4248333126306534)\n",
            "     | > log_mle: -0.3038325309753418  (-0.19792618602514267)\n",
            "     | > loss_dur: 0.7387664318084717  (0.622759498655796)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(31.8699, device='cuda:0')  (tensor(21.0058, device='cuda:0'))\n",
            "     | > current_lr: 2.2250000000000002e-05 \n",
            "     | > step_time: 0.2815  (0.3883921205997467)\n",
            "     | > loader_time: 0.0058  (0.0058564692735672)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:13:47 -- STEP: 41/81 -- GLOBAL_STEP: 7250\u001b[0m\n",
            "     | > loss: 0.3927156329154968  (0.4438750126012942)\n",
            "     | > log_mle: -0.28234124183654785  (-0.22252222532179297)\n",
            "     | > loss_dur: 0.6750568747520447  (0.6663972379230869)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(30.2576, device='cuda:0')  (tensor(23.7512, device='cuda:0'))\n",
            "     | > current_lr: 2.2250000000000002e-05 \n",
            "     | > step_time: 0.2941  (0.32968410631505457)\n",
            "     | > loader_time: 0.0027  (0.004713948180035847)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:13:58 -- STEP: 66/81 -- GLOBAL_STEP: 7275\u001b[0m\n",
            "     | > loss: 0.5259159803390503  (0.44002805334148987)\n",
            "     | > log_mle: -0.12341248989105225  (-0.2248508839896231)\n",
            "     | > loss_dur: 0.6493284702301025  (0.6648789373311126)\n",
            "     | > amp_scaler: 4096.0  (4096.0)\n",
            "     | > grad_norm: tensor(17.9984, device='cuda:0')  (tensor(26.9011, device='cuda:0'))\n",
            "     | > current_lr: 2.2250000000000002e-05 \n",
            "     | > step_time: 0.4718  (0.37792422193469427)\n",
            "     | > loader_time: 0.003  (0.00470312436421712)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1563129425048828 \u001b[0m(+0.5387139320373535)\n",
            "     | > avg_loss:\u001b[92m 0.3743836283683777 \u001b[0m(-0.05732005834579468)\n",
            "     | > avg_log_mle:\u001b[92m -0.29080891609191895 \u001b[0m(-0.0072907209396362305)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6651925444602966 \u001b[0m(-0.05002933740615845)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.1563129425048828 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.3743836283683777 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.29080891609191895 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.6651925444602966 \u001b[0m(+0.0)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/best_model_7290.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 90/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:14:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:14:31 -- STEP: 10/81 -- GLOBAL_STEP: 7300\u001b[0m\n",
            "     | > loss: 0.3600108027458191  (0.4174753189086914)\n",
            "     | > log_mle: -0.32132256031036377  (-0.2028528034687042)\n",
            "     | > loss_dur: 0.6813333630561829  (0.6203281223773957)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(32.8330, device='cuda:0')  (tensor(19.7517, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-05 \n",
            "     | > step_time: 0.9856  (0.4697586536407471)\n",
            "     | > loader_time: 0.0179  (0.006724023818969726)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:14:45 -- STEP: 35/81 -- GLOBAL_STEP: 7325\u001b[0m\n",
            "     | > loss: 0.3990049362182617  (0.42564333506992885)\n",
            "     | > log_mle: -0.22672533988952637  (-0.22752773250852312)\n",
            "     | > loss_dur: 0.6257302761077881  (0.653171067578452)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(28.9312, device='cuda:0')  (tensor(24.7270, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-05 \n",
            "     | > step_time: 0.2904  (0.5200172151838031)\n",
            "     | > loader_time: 0.0038  (0.006900051661900112)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:14:53 -- STEP: 60/81 -- GLOBAL_STEP: 7350\u001b[0m\n",
            "     | > loss: 0.4061228334903717  (0.43390569438536963)\n",
            "     | > log_mle: -0.06842845678329468  (-0.2361520012219747)\n",
            "     | > loss_dur: 0.4745512902736664  (0.6700576956073442)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(3.6171, device='cuda:0')  (tensor(26.4944, device='cuda:0'))\n",
            "     | > current_lr: 2.25e-05 \n",
            "     | > step_time: 0.2993  (0.4250380357106527)\n",
            "     | > loader_time: 0.0063  (0.005760471026102702)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.8671605587005615 \u001b[0m(-0.2891523838043213)\n",
            "     | > avg_loss:\u001b[91m 0.4317314028739929 \u001b[0m(+0.057347774505615234)\n",
            "     | > avg_log_mle:\u001b[92m -0.30313003063201904 \u001b[0m(-0.012321114540100098)\n",
            "     | > avg_loss_dur:\u001b[91m 0.734861433506012 \u001b[0m(+0.06966888904571533)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.8671605587005615 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4317314028739929 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.30313003063201904 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.734861433506012 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 91/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:15:14) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:15:17 -- STEP: 4/81 -- GLOBAL_STEP: 7375\u001b[0m\n",
            "     | > loss: 0.4660811424255371  (0.43658506870269775)\n",
            "     | > log_mle: -0.30041396617889404  (-0.20760953426361084)\n",
            "     | > loss_dur: 0.7664951086044312  (0.6441946029663086)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(29.4700, device='cuda:0')  (tensor(18.9072, device='cuda:0'))\n",
            "     | > current_lr: 2.275e-05 \n",
            "     | > step_time: 0.4364  (0.4512152075767517)\n",
            "     | > loader_time: 0.0124  (0.015027403831481934)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:15:28 -- STEP: 29/81 -- GLOBAL_STEP: 7400\u001b[0m\n",
            "     | > loss: 0.6786070466041565  (0.4161320821992282)\n",
            "     | > log_mle: -0.2744925022125244  (-0.23399904267541294)\n",
            "     | > loss_dur: 0.9530995488166809  (0.6501311248746411)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(36.4321, device='cuda:0')  (tensor(22.2444, device='cuda:0'))\n",
            "     | > current_lr: 2.275e-05 \n",
            "     | > step_time: 0.307  (0.4239802360534668)\n",
            "     | > loader_time: 0.005  (0.007652710224020068)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:15:36 -- STEP: 54/81 -- GLOBAL_STEP: 7425\u001b[0m\n",
            "     | > loss: 0.692312479019165  (0.43294053552327333)\n",
            "     | > log_mle: -0.34043169021606445  (-0.2400323936232814)\n",
            "     | > loss_dur: 1.0327441692352295  (0.6729729291465547)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(68.2713, device='cuda:0')  (tensor(24.4411, device='cuda:0'))\n",
            "     | > current_lr: 2.275e-05 \n",
            "     | > step_time: 0.4307  (0.36650558754249857)\n",
            "     | > loader_time: 0.004  (0.006098376380072697)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:15:47 -- STEP: 79/81 -- GLOBAL_STEP: 7450\u001b[0m\n",
            "     | > loss: 0.3993379473686218  (0.4233521464504773)\n",
            "     | > log_mle: -0.3190009593963623  (-0.24860385550728328)\n",
            "     | > loss_dur: 0.7183389067649841  (0.6719560019577606)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(26.8177, device='cuda:0')  (tensor(26.3261, device='cuda:0'))\n",
            "     | > current_lr: 2.275e-05 \n",
            "     | > step_time: 0.2363  (0.38961213449888593)\n",
            "     | > loader_time: 0.002  (0.005866355533841289)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5560839176177979 \u001b[0m(-0.31107664108276367)\n",
            "     | > avg_loss:\u001b[91m 0.47906023263931274 \u001b[0m(+0.047328829765319824)\n",
            "     | > avg_log_mle:\u001b[91m -0.2911893129348755 \u001b[0m(+0.011940717697143555)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7702495455741882 \u001b[0m(+0.03538811206817627)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5560839176177979 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.47906023263931274 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2911893129348755 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7702495455741882 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 92/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:16:00) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:16:12 -- STEP: 23/81 -- GLOBAL_STEP: 7475\u001b[0m\n",
            "     | > loss: 0.19783824682235718  (0.3979094533816628)\n",
            "     | > log_mle: -0.3734738826751709  (-0.22478678433791452)\n",
            "     | > loss_dur: 0.5713121294975281  (0.6226962377195774)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(38.3422, device='cuda:0')  (tensor(23.7168, device='cuda:0'))\n",
            "     | > current_lr: 2.3e-05 \n",
            "     | > step_time: 0.2879  (0.39140264884285303)\n",
            "     | > loader_time: 0.0047  (0.009054712627245031)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:16:20 -- STEP: 48/81 -- GLOBAL_STEP: 7500\u001b[0m\n",
            "     | > loss: 0.2276688814163208  (0.4245347796628873)\n",
            "     | > log_mle: -0.33177411556243896  (-0.23591610665122667)\n",
            "     | > loss_dur: 0.5594429969787598  (0.6604508863141142)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(50.5384, device='cuda:0')  (tensor(24.8404, device='cuda:0'))\n",
            "     | > current_lr: 2.3e-05 \n",
            "     | > step_time: 0.4241  (0.3492877632379532)\n",
            "     | > loader_time: 0.0034  (0.006780942281087239)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:16:31 -- STEP: 73/81 -- GLOBAL_STEP: 7525\u001b[0m\n",
            "     | > loss: 0.749667763710022  (0.41917099079040626)\n",
            "     | > log_mle: -0.3625199794769287  (-0.246470716718125)\n",
            "     | > loss_dur: 1.1121877431869507  (0.6656417075085317)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(44.0544, device='cuda:0')  (tensor(26.5431, device='cuda:0'))\n",
            "     | > current_lr: 2.3e-05 \n",
            "     | > step_time: 0.2362  (0.3797189405519668)\n",
            "     | > loader_time: 0.003  (0.006604841310683995)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5450315475463867 \u001b[0m(-0.011052370071411133)\n",
            "     | > avg_loss:\u001b[91m 0.4859852194786072 \u001b[0m(+0.006924986839294434)\n",
            "     | > avg_log_mle:\u001b[92m -0.2957574129104614 \u001b[0m(-0.0045680999755859375)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7817426323890686 \u001b[0m(+0.011493086814880371)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5450315475463867 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4859852194786072 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.2957574129104614 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7817426323890686 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 93/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:16:48) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:16:56 -- STEP: 17/81 -- GLOBAL_STEP: 7550\u001b[0m\n",
            "     | > loss: 0.38024473190307617  (0.3968646684113671)\n",
            "     | > log_mle: -0.23234736919403076  (-0.2181844571057488)\n",
            "     | > loss_dur: 0.6125921010971069  (0.6150491255171159)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(16.4143, device='cuda:0')  (tensor(19.8935, device='cuda:0'))\n",
            "     | > current_lr: 2.3250000000000003e-05 \n",
            "     | > step_time: 0.2907  (0.3547519936281092)\n",
            "     | > loader_time: 0.0046  (0.004527947481940775)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:17:06 -- STEP: 42/81 -- GLOBAL_STEP: 7575\u001b[0m\n",
            "     | > loss: 0.4366456866264343  (0.42227519480955034)\n",
            "     | > log_mle: -0.20221209526062012  (-0.24046105430239723)\n",
            "     | > loss_dur: 0.6388577818870544  (0.6627362491119475)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(17.0949, device='cuda:0')  (tensor(24.9757, device='cuda:0'))\n",
            "     | > current_lr: 2.3250000000000003e-05 \n",
            "     | > step_time: 0.5437  (0.3671016295750936)\n",
            "     | > loader_time: 0.0046  (0.0049886930556524356)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:17:19 -- STEP: 67/81 -- GLOBAL_STEP: 7600\u001b[0m\n",
            "     | > loss: 0.3784538507461548  (0.41623611503572605)\n",
            "     | > log_mle: -0.2467048168182373  (-0.24300531131118092)\n",
            "     | > loss_dur: 0.6251586675643921  (0.659241426346907)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(12.3298, device='cuda:0')  (tensor(25.3188, device='cuda:0'))\n",
            "     | > current_lr: 2.3250000000000003e-05 \n",
            "     | > step_time: 0.4406  (0.42037795906636255)\n",
            "     | > loader_time: 0.0047  (0.006294798495164557)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.518852710723877 \u001b[0m(-0.026178836822509766)\n",
            "     | > avg_loss:\u001b[92m 0.3896659016609192 \u001b[0m(-0.09631931781768799)\n",
            "     | > avg_log_mle:\u001b[92m -0.32399070262908936 \u001b[0m(-0.02823328971862793)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7136566042900085 \u001b[0m(-0.06808602809906006)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.518852710723877 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.3896659016609192 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.32399070262908936 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7136566042900085 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 94/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:17:37) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:17:43 -- STEP: 11/81 -- GLOBAL_STEP: 7625\u001b[0m\n",
            "     | > loss: 0.35748499631881714  (0.3956883116201921)\n",
            "     | > log_mle: -0.14437615871429443  (-0.21152244914661755)\n",
            "     | > loss_dur: 0.5018611550331116  (0.6072107607668097)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(19.4797, device='cuda:0')  (tensor(21.8230, device='cuda:0'))\n",
            "     | > current_lr: 2.3500000000000002e-05 \n",
            "     | > step_time: 0.2991  (0.376192569732666)\n",
            "     | > loader_time: 0.003  (0.0045406384901566935)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:17:51 -- STEP: 36/81 -- GLOBAL_STEP: 7650\u001b[0m\n",
            "     | > loss: 0.5062651634216309  (0.41445012390613556)\n",
            "     | > log_mle: -0.3066216707229614  (-0.24281386037667593)\n",
            "     | > loss_dur: 0.8128868341445923  (0.6572639842828114)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(29.0745, device='cuda:0')  (tensor(24.4685, device='cuda:0'))\n",
            "     | > current_lr: 2.3500000000000002e-05 \n",
            "     | > step_time: 0.2952  (0.3185507655143738)\n",
            "     | > loader_time: 0.0029  (0.004291415214538574)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:18:02 -- STEP: 61/81 -- GLOBAL_STEP: 7675\u001b[0m\n",
            "     | > loss: 0.3774062395095825  (0.41419683323531853)\n",
            "     | > log_mle: -0.12069809436798096  (-0.2512705208825284)\n",
            "     | > loss_dur: 0.4981043338775635  (0.6654673541178469)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(7.2921, device='cuda:0')  (tensor(26.2386, device='cuda:0'))\n",
            "     | > current_lr: 2.3500000000000002e-05 \n",
            "     | > step_time: 0.4843  (0.3700889954801466)\n",
            "     | > loader_time: 0.0035  (0.004372545930205801)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.5612525939941406 \u001b[0m(+0.04239988327026367)\n",
            "     | > avg_loss:\u001b[92m 0.38860809803009033 \u001b[0m(-0.0010578036308288574)\n",
            "     | > avg_log_mle:\u001b[91m -0.31053829193115234 \u001b[0m(+0.013452410697937012)\n",
            "     | > avg_loss_dur:\u001b[92m 0.6991463899612427 \u001b[0m(-0.01451021432876587)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5612525939941406 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.38860809803009033 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.31053829193115234 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.6991463899612427 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 95/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:18:23) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:18:27 -- STEP: 5/81 -- GLOBAL_STEP: 7700\u001b[0m\n",
            "     | > loss: 0.4132746458053589  (0.41194947957992556)\n",
            "     | > log_mle: -0.19644606113433838  (-0.2112407684326172)\n",
            "     | > loss_dur: 0.6097207069396973  (0.6231902480125427)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(16.5039, device='cuda:0')  (tensor(26.5152, device='cuda:0'))\n",
            "     | > current_lr: 2.375e-05 \n",
            "     | > step_time: 0.2826  (0.3133730888366699)\n",
            "     | > loader_time: 0.0049  (0.005166387557983399)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:18:34 -- STEP: 30/81 -- GLOBAL_STEP: 7725\u001b[0m\n",
            "     | > loss: 0.5573490858078003  (0.40575255354245504)\n",
            "     | > log_mle: -0.22740709781646729  (-0.2416292945543925)\n",
            "     | > loss_dur: 0.7847561836242676  (0.6473818480968475)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(23.9180, device='cuda:0')  (tensor(25.8069, device='cuda:0'))\n",
            "     | > current_lr: 2.375e-05 \n",
            "     | > step_time: 0.2793  (0.29873678684234617)\n",
            "     | > loader_time: 0.0047  (0.004261024792989095)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:18:45 -- STEP: 55/81 -- GLOBAL_STEP: 7750\u001b[0m\n",
            "     | > loss: 0.3018820583820343  (0.41650138172236356)\n",
            "     | > log_mle: -0.17795324325561523  (-0.24715410362590443)\n",
            "     | > loss_dur: 0.47983530163764954  (0.663655485348268)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(13.0904, device='cuda:0')  (tensor(28.0767, device='cuda:0'))\n",
            "     | > current_lr: 2.375e-05 \n",
            "     | > step_time: 0.4327  (0.356075516614047)\n",
            "     | > loader_time: 0.0134  (0.004969302090731534)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:18:54 -- STEP: 80/81 -- GLOBAL_STEP: 7775\u001b[0m\n",
            "     | > loss: 0.40548133850097656  (0.40660231485962867)\n",
            "     | > log_mle: -0.5076555013656616  (-0.26057608425617224)\n",
            "     | > loss_dur: 0.9131368398666382  (0.6671783991158007)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(35.2052, device='cuda:0')  (tensor(28.4545, device='cuda:0'))\n",
            "     | > current_lr: 2.375e-05 \n",
            "     | > step_time: 0.3056  (0.3514770984649659)\n",
            "     | > loader_time: 0.0034  (0.005036559700965881)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7049164772033691 \u001b[0m(+0.14366388320922852)\n",
            "     | > avg_loss:\u001b[91m 0.41756385564804077 \u001b[0m(+0.02895575761795044)\n",
            "     | > avg_log_mle:\u001b[92m -0.3293241262435913 \u001b[0m(-0.018785834312438965)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7468879818916321 \u001b[0m(+0.047741591930389404)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7049164772033691 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.41756385564804077 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.3293241262435913 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7468879818916321 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 96/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:19:10) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:19:18 -- STEP: 24/81 -- GLOBAL_STEP: 7800\u001b[0m\n",
            "     | > loss: 0.44257164001464844  (0.3845101209978263)\n",
            "     | > log_mle: -0.2901970148086548  (-0.24222062031428018)\n",
            "     | > loss_dur: 0.7327686548233032  (0.6267307413121065)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(19.3201, device='cuda:0')  (tensor(17.4354, device='cuda:0'))\n",
            "     | > current_lr: 2.4e-05 \n",
            "     | > step_time: 0.2812  (0.2884262104829152)\n",
            "     | > loader_time: 0.0032  (0.0034021039803822837)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:19:30 -- STEP: 49/81 -- GLOBAL_STEP: 7825\u001b[0m\n",
            "     | > loss: 0.27077215909957886  (0.40348728274812506)\n",
            "     | > log_mle: -0.2777903079986572  (-0.251480123218225)\n",
            "     | > loss_dur: 0.5485624670982361  (0.6549674059663501)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(15.6753, device='cuda:0')  (tensor(22.9848, device='cuda:0'))\n",
            "     | > current_lr: 2.4e-05 \n",
            "     | > step_time: 0.4987  (0.36517200178029585)\n",
            "     | > loader_time: 0.0048  (0.003962195649438975)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:19:38 -- STEP: 74/81 -- GLOBAL_STEP: 7850\u001b[0m\n",
            "     | > loss: 0.28626883029937744  (0.39777636809928996)\n",
            "     | > log_mle: -0.3000648021697998  (-0.26285455436319916)\n",
            "     | > loss_dur: 0.5863336324691772  (0.6606309224624891)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(27.6421, device='cuda:0')  (tensor(27.2755, device='cuda:0'))\n",
            "     | > current_lr: 2.4e-05 \n",
            "     | > step_time: 0.2474  (0.3520602503338376)\n",
            "     | > loader_time: 0.002  (0.0038697751792701523)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.7401690483093262 \u001b[0m(+0.03525257110595703)\n",
            "     | > avg_loss:\u001b[92m 0.37701737880706787 \u001b[0m(-0.0405464768409729)\n",
            "     | > avg_log_mle:\u001b[92m -0.3315260410308838 \u001b[0m(-0.0022019147872924805)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7085434198379517 \u001b[0m(-0.03834456205368042)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.7401690483093262 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.37701737880706787 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.3315260410308838 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7085434198379517 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 97/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:19:55) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:20:02 -- STEP: 18/81 -- GLOBAL_STEP: 7875\u001b[0m\n",
            "     | > loss: 0.31554919481277466  (0.37975574533144635)\n",
            "     | > log_mle: -0.12751305103302002  (-0.2271307177013821)\n",
            "     | > loss_dur: 0.4430622458457947  (0.6068864630328284)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(5.6258, device='cuda:0')  (tensor(20.7150, device='cuda:0'))\n",
            "     | > current_lr: 2.425e-05 \n",
            "     | > step_time: 0.3996  (0.3179223934809367)\n",
            "     | > loader_time: 0.0029  (0.0032507446077134875)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:20:14 -- STEP: 43/81 -- GLOBAL_STEP: 7900\u001b[0m\n",
            "     | > loss: 0.3341987133026123  (0.3982192596723867)\n",
            "     | > log_mle: -0.1075434684753418  (-0.25612838323726217)\n",
            "     | > loss_dur: 0.4417421817779541  (0.6543476429096491)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(13.1797, device='cuda:0')  (tensor(23.1398, device='cuda:0'))\n",
            "     | > current_lr: 2.425e-05 \n",
            "     | > step_time: 0.2911  (0.3892932936202648)\n",
            "     | > loader_time: 0.0029  (0.004438566607098247)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:20:21 -- STEP: 68/81 -- GLOBAL_STEP: 7925\u001b[0m\n",
            "     | > loss: 0.29829567670822144  (0.3958303814425188)\n",
            "     | > log_mle: -0.24746310710906982  (-0.2596868522026961)\n",
            "     | > loss_dur: 0.5457587838172913  (0.6555172336452149)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(37.2298, device='cuda:0')  (tensor(25.4183, device='cuda:0'))\n",
            "     | > current_lr: 2.425e-05 \n",
            "     | > step_time: 0.289  (0.35292233789668365)\n",
            "     | > loader_time: 0.0074  (0.004665756926817052)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.823115348815918 \u001b[0m(+0.0829463005065918)\n",
            "     | > avg_loss:\u001b[91m 0.4102109670639038 \u001b[0m(+0.03319358825683594)\n",
            "     | > avg_log_mle:\u001b[92m -0.334578275680542 \u001b[0m(-0.003052234649658203)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7447892427444458 \u001b[0m(+0.03624582290649414)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.823115348815918 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.4102109670639038 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.334578275680542 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7447892427444458 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 98/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:20:39) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:20:45 -- STEP: 12/81 -- GLOBAL_STEP: 7950\u001b[0m\n",
            "     | > loss: 0.3650522828102112  (0.3731430321931839)\n",
            "     | > log_mle: -0.43858802318573  (-0.23978906869888306)\n",
            "     | > loss_dur: 0.8036403059959412  (0.612932100892067)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(40.3485, device='cuda:0')  (tensor(24.8095, device='cuda:0'))\n",
            "     | > current_lr: 2.45e-05 \n",
            "     | > step_time: 0.4169  (0.3185145656267802)\n",
            "     | > loader_time: 0.0024  (0.004258990287780762)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:20:56 -- STEP: 37/81 -- GLOBAL_STEP: 7975\u001b[0m\n",
            "     | > loss: 0.4594743251800537  (0.38920891043302175)\n",
            "     | > log_mle: -0.3633608818054199  (-0.2617791440035846)\n",
            "     | > loss_dur: 0.8228352069854736  (0.6509880544366063)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(26.2541, device='cuda:0')  (tensor(24.9048, device='cuda:0'))\n",
            "     | > current_lr: 2.45e-05 \n",
            "     | > step_time: 0.3012  (0.4007436906969225)\n",
            "     | > loader_time: 0.0074  (0.005267600755433779)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:21:05 -- STEP: 62/81 -- GLOBAL_STEP: 8000\u001b[0m\n",
            "     | > loss: 0.3875148296356201  (0.39589237493853413)\n",
            "     | > log_mle: -0.21442246437072754  (-0.2643433597780042)\n",
            "     | > loss_dur: 0.6019372940063477  (0.6602357347165382)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(14.9445, device='cuda:0')  (tensor(24.9782, device='cuda:0'))\n",
            "     | > current_lr: 2.45e-05 \n",
            "     | > step_time: 0.2866  (0.37409112530369915)\n",
            "     | > loader_time: 0.0042  (0.004948677555207283)\n",
            "\n",
            "\n",
            " > CHECKPOINT : /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_8000.pth\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 1.1614336967468262 \u001b[0m(+0.3383183479309082)\n",
            "     | > avg_loss:\u001b[92m 0.38588905334472656 \u001b[0m(-0.024321913719177246)\n",
            "     | > avg_log_mle:\u001b[92m -0.336086630821228 \u001b[0m(-0.0015083551406860352)\n",
            "     | > avg_loss_dur:\u001b[92m 0.7219756841659546 \u001b[0m(-0.02281355857849121)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.1614336967468262 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.38588905334472656 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.336086630821228 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7219756841659546 \u001b[0m(+0.0)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 99/100\u001b[0m\n",
            " --> /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-19 13:21:41) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:21:44 -- STEP: 6/81 -- GLOBAL_STEP: 8025\u001b[0m\n",
            "     | > loss: 0.34938544034957886  (0.39233118295669556)\n",
            "     | > log_mle: -0.2996816635131836  (-0.24230130513509116)\n",
            "     | > loss_dur: 0.6490671038627625  (0.6346324880917867)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(17.3520, device='cuda:0')  (tensor(20.0284, device='cuda:0'))\n",
            "     | > current_lr: 2.475e-05 \n",
            "     | > step_time: 0.2884  (0.29272274176279706)\n",
            "     | > loader_time: 0.0029  (0.0037941932678222656)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:21:53 -- STEP: 31/81 -- GLOBAL_STEP: 8050\u001b[0m\n",
            "     | > loss: 0.42893266677856445  (0.38440632243310247)\n",
            "     | > log_mle: -0.20434939861297607  (-0.26064338607172816)\n",
            "     | > loss_dur: 0.6332820653915405  (0.6450497085048308)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(19.2069, device='cuda:0')  (tensor(24.6690, device='cuda:0'))\n",
            "     | > current_lr: 2.475e-05 \n",
            "     | > step_time: 0.4163  (0.3223270062477358)\n",
            "     | > loader_time: 0.0032  (0.004959291027438256)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-19 13:22:03 -- STEP: 56/81 -- GLOBAL_STEP: 8075\u001b[0m\n",
            "     | > loss: 0.34919804334640503  (0.3919385905776705)\n",
            "     | > log_mle: -0.37472498416900635  (-0.2707667563642775)\n",
            "     | > loss_dur: 0.7239230275154114  (0.6627053469419482)\n",
            "     | > amp_scaler: 2048.0  (2048.0)\n",
            "     | > grad_norm: tensor(56.9924, device='cuda:0')  (tensor(27.5640, device='cuda:0'))\n",
            "     | > current_lr: 2.475e-05 \n",
            "     | > step_time: 0.2863  (0.3678403454167502)\n",
            "     | > loader_time: 0.0038  (0.005326156105313983)\n",
            "\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.5410037040710449 \u001b[0m(-0.6204299926757812)\n",
            "     | > avg_loss:\u001b[91m 0.3985443115234375 \u001b[0m(+0.012655258178710938)\n",
            "     | > avg_log_mle:\u001b[91m -0.3307391405105591 \u001b[0m(+0.005347490310668945)\n",
            "     | > avg_loss_dur:\u001b[91m 0.7292834520339966 \u001b[0m(+0.007307767868041992)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Synthesizing test sentences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.5410037040710449 \u001b[0m(+0.0)\n",
            "     | > avg_loss: 0.3985443115234375 \u001b[0m(+0.0)\n",
            "     | > avg_log_mle: -0.3307391405105591 \u001b[0m(+0.0)\n",
            "     | > avg_loss_dur: 0.7292834520339966 \u001b[0m(+0.0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "ze97iyZTxi2G"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "N6sbEnHErXN2"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorboard\n",
        "# !tensorboard --logdir=output_patha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mvqN3cXSr-bc"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "output_path = \"/content/drive/MyDrive/dataset/cloned\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZfYKlzgPsD3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6fb3e9-7906-45eb-8f51-52a5f82f1b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Using model: glow_tts\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Text: How are you?\n",
            " > Text splitted to sentences.\n",
            "['How are you?']\n",
            " > Processing time: 0.755673885345459\n",
            " > Real-time factor: 0.8788295976723296\n",
            " > Saving output to out.wav\n"
          ]
        }
      ],
      "source": [
        " !tts --text \"How are you?\" \\\n",
        "      --model_path  /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/checkpoint_8000.pth \\\n",
        "      --config_path /content/drive/MyDrive/dataset/cloned/run-July-19-2023_11+56AM-0000000/config.json \\\n",
        "      --out_path out.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "MLhFWJdPsEWr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "d33159fa-283c-4cfe-964a-b0fdaaa7d18e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Cr-vnpTx07A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgMUNk4z++n4X+pCU6qBQf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b142ae5439d4e0788b2d14793265d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_892051cab6e24834bdda277c1fd6901f",
              "IPY_MODEL_9686db22f81b499facd75e7942c4e2c7",
              "IPY_MODEL_d17fad708e874f93a8e9b9eb9e0ceb2a"
            ],
            "layout": "IPY_MODEL_52bffd98efc3483f98e3e3ec3135226d"
          }
        },
        "892051cab6e24834bdda277c1fd6901f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf472fa68224433d951db9528053f737",
            "placeholder": "​",
            "style": "IPY_MODEL_e4d53b1e384f4581b51ce64b15da68e3",
            "value": "Map:   0%"
          }
        },
        "9686db22f81b499facd75e7942c4e2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ee8faef59cd498693184a59903fb8b8",
            "max": 82,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a08a0fd13ae4ea994e8f732c103d7ba",
            "value": 82
          }
        },
        "d17fad708e874f93a8e9b9eb9e0ceb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748e1d70a6f34d69bacc681113ed85bd",
            "placeholder": "​",
            "style": "IPY_MODEL_ed05ac9b712d42b694b557217664c333",
            "value": " 0/82 [00:00&lt;?, ? examples/s]"
          }
        },
        "52bffd98efc3483f98e3e3ec3135226d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bf472fa68224433d951db9528053f737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d53b1e384f4581b51ce64b15da68e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ee8faef59cd498693184a59903fb8b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a08a0fd13ae4ea994e8f732c103d7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "748e1d70a6f34d69bacc681113ed85bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed05ac9b712d42b694b557217664c333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}